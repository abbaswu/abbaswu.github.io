<!DOCTYPE html><html lang="en" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Jifeng Wu"><meta name="keywords" content=""><meta name="description" content="NOTE: The terms “language” and “word” are used metaphorically in this document. A “language” often has many “words”, and the frequency of each “word” varies. If a “language” $X$ has a total of $n$ “wo"><meta property="og:type" content="article"><meta property="og:title" content="Understanding the Formulation of Information Entropy"><meta property="og:url" content="https://abbaswu.github.io/2022/09/16/Understanding-the-Formulation-of-Information-Entropy/index.html"><meta property="og:site_name" content="Jifeng Wu&#39;s Personal Website"><meta property="og:description" content="NOTE: The terms “language” and “word” are used metaphorically in this document. A “language” often has many “words”, and the frequency of each “word” varies. If a “language” $X$ has a total of $n$ “wo"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/b/b5/International_Morse_Code.svg"><meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/0/04/Kraft_inequality_example.png"><meta property="og:image" content="https://raw.githubusercontent.com/abbaswu/abbaswu.github.io-images/main/Value_ranges_of_a_1_a_2.png"><meta property="article:published_time" content="2022-09-16T07:00:00.000Z"><meta property="article:modified_time" content="2023-02-26T16:53:22.089Z"><meta property="article:author" content="Jifeng Wu"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://upload.wikimedia.org/wikipedia/commons/b/b5/International_Morse_Code.svg"><title>Understanding the Formulation of Information Entropy - Jifeng Wu&#39;s Personal Website</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"abbaswu.github.io",root:"/",version:"1.9.3",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Jifeng Wu's Personal Website" type="application/atom+xml">
</head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Jifeng Wu</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> Home</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> Categories</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> Archives</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/mountains-fog-aerial-view-clouds-sky-blue.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Understanding the Formulation of Information Entropy"></span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> Jifeng Wu </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-09-16 03:00" pubdate>September 16, 2022</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 6.9k words </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 58 mins</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Understanding the Formulation of Information Entropy</h1><div class="markdown-body"><p>NOTE: The terms “language” and “word” are used metaphorically in this document.</p><p>A “language” often has many “words”, and the frequency of each “word” varies.</p><p>If a “language” $X$ has a total of $n$ “words”, then we can encode a word with $\log_{2}{n}$ binary bits. <strong>But when transmitting the words, we want to keep the encoding of each “word” as short as possible. A common practice is that for those high-frequency “words”, we can use shorter encodings, and for those “words” that we use less frequently, we can allow longer encodings.</strong> An example is the Morse code encoding for a “language” consisting of 36 “words” - 26 Latin letters and 10 Arabic numerals.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/b/b5/International_Morse_Code.svg" srcset="/img/loading.gif" lazyload alt="Morse code. The &quot;word&quot; &quot;e&quot; occurs frequently, hence a short code"></p><p>So, under some optimal encoding, what limit can the weighted average encoding length of all “words” achieve?</p><p>Suppose our “language” has $n$ “words”, $x_1, x_2, \dots, x_n$, and their probability of occurrence is $p(x_1), p(x_2), \dots, p(x_n)$ (known quantities).</p><p>Assuming that the lengths of the encodings of these “words” are $L(x_1), L(x_2), \dots, L(x_n)$ respectively, the weighted average encoding length of each “word” is:</p><p>$\bar{L} &#x3D; p(x_1) L(x_1) + \dots + p(x_n) L(x_n)$</p><p>How do we find the minimum value of $\bar{L}$?</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints"></a>Constraints</h2><p>Obviously, the encoded length of all “words” is greater than 0. But beyond that, there is a hidden constraint.</p><p><strong>We do not allow one encoding to be a prefix of another encoding, otherwise there will be ambiguity during decoding</strong>. For example, assuming that the three “words” of “A”, “B”, and “C” in the alphabet are encoded as “0”, “1”, and “01” respectively, then for For a code like “001”, should we decode it as “AAB” or “AC”?</p><p>We call a type of code which requires that there is no whole code word in the system that is a prefix of any other code word in the system as a <strong>prefix code</strong>.</p><p>This means that if we assign a shorter encoding to a “word”, it will squeeze a lot of resources out of the encoding space. For example, suppose the “word” “A” is encoded as “0”, then it would “squeeze out” “00”, “01”, etc. from the codewords.</p><p>Suppose the maximum value in $L(x_1), L(x_2), \dots, L(x_n)$ is $L_{max}$. <strong>Then the encoding of all “words” are nodes on a full binary tree with a height of $L_{max}$, and the full binary subtrees below each node have no intersection (otherwise violating the properties of the prefix code), as shown below</strong>.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/0/04/Kraft_inequality_example.png" srcset="/img/loading.gif" lazyload alt="The encoding of all &quot;words&quot; are nodes on a full binary tree with a height of $L_{max}$, and the full binary subtrees below each node have no intersection"></p><p>It is obvious that, <strong>all the full binary subtrees below each node, at most cover all the leaves of the full binary tree with height $L_{max}$.</strong></p><p>For a “word” $x_i, i \in {1, 2, \dots, n}$, the height of the full binary subtree below it is $L_{max} - L(x_i)$, and it covers $2^{L_{max} - L(x_i)}$ leaves.</p><p>As the full binary tree with height $L_{max}$ has a total of $2^{L_{max}}$, we have:</p><p>$2^{L_{max} - L(x_1)} + 2^{L_{max} - L(x_2)} + \dots + 2^{L_{max} - L(x_n)} \le 2^{L_{max}}$</p><p>This simplifies to:</p><p>$2^{- L(x_1)} + 2^{- L(x_2)} + \dots + 2^{- L(x_n)} \le 1$</p><p>This is the Kraft-McMillan inequality.</p><h2 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h2><p>Therefore, our overall optimization objective is:</p><p>$\bar{L} &#x3D; p(x_1) L(x_1) + \dots + p(x_n) L(x_n)$</p><p>Subject to:</p><ul><li>$p(x_i) \in (0, 1), i \in {1, 2, \dots, n}$ are constants</li><li>$p(x_1) + p(x_2) + \dots + p(x_n) &#x3D; 1$</li><li>$L(x_i) &gt; 0, i \in {1, 2, \dots, n}$ are independent variables</li><li>$2^{- L(x_1)} + 2^{- L(x_2)} + \dots + 2^{- L(x_n)} \le 1$</li></ul><hr><p><strong>We can analyze the problem for the case where there are only two words $x_1, x_2$</strong>. At this point, we have:</p><p>$\bar{L} &#x3D; p(x_1) L(x_1) + p(x_2) L(x_2)$</p><p>Equivalently:</p><p>$\bar{L} &#x3D; p(x_1) L(x_1) + (1 - p(x_1)) L(x_2)$</p><p>Subject to:</p><ul><li>$p(x_1) \in (0, 1)$ is a constant</li><li>$L(x_i) &gt; 0, i \in {1, 2}$ are independent variables</li><li>$2^{- L(x_1)} + 2^{- L(x_2)} \le 1$</li></ul><p>Define $a_1 &#x3D; 2^{- L(x_1)}, a_2 &#x3D; 2^{- L(x_2)}$. Now we have:</p><p>$\bar{L} &#x3D; - p(x_1) \log_2{a_1} - (1 - p(x_1)) \log_2{a_2}$</p><p>Subject to:</p><ul><li>$p(x_1) \in (0, 1)$ is a constant</li><li>$0 &lt; a_i &lt;1, i \in {1, 2}$ are independent variables</li><li>$a_1 + a_2 \le 1$</li></ul><p>At this point, $\bar{L}$ can be regarded as a binary function whose independent variables are $a_1, a_2$, and the value ranges of the independent variables $a_1, a_2$ are as follows:</p><p><img src="https://raw.githubusercontent.com/abbaswu/abbaswu.github.io-images/main/Value_ranges_of_a_1_a_2.png" srcset="/img/loading.gif" lazyload alt="Value ranges of $a_1, a_2$"></p><p>We want to find the minimum value of $\bar{L}(a_1, a_2)$ within this range of values.</p><p>The gradient of $\bar{L}(a_1, a_2)$ is as follows:</p><p>$\nabla\bar{L}(a_1, a_2) &#x3D; {(-p(x_1) \log{2} \frac{1}{a_1}, -(1 - p(x_1)) \log{2} \frac{1}{a_2})}^T$</p><p>Within the value range of the independent variables $a_1, a_2$, $\nabla\bar{L}(a_1, a_2)$ is always less than 0, which means that <strong>with the growth of $a_1, a_2$, $\bar{L}(a_1, a_2)$ decreases</strong>. Therefore, the maximum value of <strong>$\bar{L}(a_1, a_2)$ must occur when $(a_1, a_2)$ is on the boundary line $a_1 + a_2 &#x3D; 1$</strong>.</p><p>Substituting the boundary line $a_1 + a_2 &#x3D; 1$ into $\bar{L}(a_1, a_2)$, you can get a unary function:</p><p>$\bar{L}(a_1) &#x3D; - p(x_1) \log_2{a_1} - (1 - p(x_1)) \log_2{(1 - a_1)}$</p><p>The constraints include:</p><ul><li>$p(x_1) \in (0, 1)$, constant</li><li>$0 &lt; a_1 &lt; 1$</li></ul><p>The derivative of $\bar{L}(a_1)$ is as follows:</p><p>$\frac{d \bar{L}(a_1)}{d a_1} &#x3D; \frac{\log{2} (a_1 - p(x_1))}{a_1 (1 - a_1)}$</p><p>The constraints include:</p><ul><li>$p(x_1) \in (0, 1)$ is a constant</li><li>$0 &lt; a_1 &lt; 1$</li></ul><p>When $0 &lt; a_1 &lt; p(x_1)$, $\frac{d \bar{L}(a_1)}{d a_1} &lt; 0$, $\bar{L}(a_1)$ monotonically decreases, and when $p(x_1) &lt; a_1 &lt; 1$, $\frac{d \bar{L}(a_1)}{d a_1} &gt; 0$, $\bar{L}(a_1)$ monotonically increases. Therefore, when $a_1 &#x3D; p(x_1)$, $\bar{L}(a_1)$ obtains the minimum value.</p><p>As $a_1 &#x3D; 2^{- L(x_1)}, a_2 &#x3D; 2^{- L(x_2)}$, this means that, for:</p><p>$\bar{L} &#x3D; p(x_1) L(x_1) + (1 - p(x_1)) L(x_2)$</p><p>Subject to:</p><ul><li>$p(x_1) \in (0, 1)$ is a constant</li><li>$L(x_i) &gt; 0, i \in {1, 2}$ are independent variables</li><li>$2^{- L(x_1)} + 2^{- L(x_2)} \le 1$</li></ul><p><strong>$\bar{L}$’s minima occurs when $L(x_1) &#x3D; -\log_2{p(x_1)}, L(x_2) &#x3D; -\log_2{p(x_2)}$, and the minima is $- p(x_1) \log_2{p(x_1)} - p(x_2) \log_2{p(x_2)}$</strong>.</p><hr><p>Going back to the multivariate optimization problem:</p><p>$\bar{L} &#x3D; p(x_1) L(x_1) + \dots + p(x_n) L(x_n)$</p><p>Subject to:</p><ul><li>$p(x_i) \in (0, 1), i \in {1, 2, \dots, n}$ are constants</li><li>$p(x_1) + p(x_2) + \dots + p(x_n) &#x3D; 1$</li><li>$L(x_i) &gt; 0, i \in {1, 2, \dots, n}$ are independent variables</li><li>$2^{- L(x_1)} + 2^{- L(x_2)} + \dots + 2^{- L(x_n)} \le 1$</li></ul><p><strong>$\bar{L}$’s minima occurs when $L(x_i) &#x3D; -\log_2{p(x_i)}, i \in {1, 2, \dots, n}$, and the minima is $- p(x_1) \log_2{p(x_1)} - \dots - p(x_n) \log_2{p(x_n)}$</strong>.</p><h2 id="Definition-of-Information-Entropy"><a href="#Definition-of-Information-Entropy" class="headerlink" title="Definition of Information Entropy"></a>Definition of Information Entropy</h2><p>If a language “language” $X$ has $n$ “words”, $x_1, x_2, \dots, x_n$, the probability of their occurrence is $p(x_1), p(x_2), \dots, p(x_n)$, then <strong>all “words” under a certain optimal encoding, the previously calculated minimum weighted average encoding length</strong>, $- p(x_1) \log_2{p(x_1)} - \dots - p (x_n) \log_2{p(x_n)}$, is called the <strong>information entropy</strong> of the “language”, denoted as $H(X)$.</p><p>The reason why it is called “information entropy” is mainly due to the following reasons:</p><ul><li>From von Neumann’s naming suggestion for Shannon: My greatest concern was what to call it. I thought of calling it ‘information,’ but the word was overly used, so I decided to call it ‘uncertainty.’ When I discussed it with John von Neumann, he had a better idea. Von Neumann told me, ‘You should call it entropy, for two reasons. <strong>In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name. In the second place, and more important, no one really knows what entropy really is, so in a debate you will always have the advantage.</strong></li><li>In a sense, it does reflect the frequency distribution of the “words” of “language” $X$, just as entropy in thermodynamics reflects the distribution of microscopic particles. <strong>The lower $H(X)$ is, the more the case that only a few words are used frequently in $X$; the higher $H(X)$ is, the more the case that all words in $X$ are used frequency.</strong></li></ul><h2 id="Links-to-Explanations-of-Related-Concepts"><a href="#Links-to-Explanations-of-Related-Concepts" class="headerlink" title="Links to Explanations of Related Concepts"></a>Links to Explanations of Related Concepts</h2><ul><li><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/#cross-entropy">Cross Entropy</a></li><li><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/#entropy-and-multiple-variables">Joint Entropy</a></li><li><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/#mutual-information">Mutual Information</a></li></ul><h2 id="How-These-Concept-are-Applied-in-Practice"><a href="#How-These-Concept-are-Applied-in-Practice" class="headerlink" title="How These Concept are Applied in Practice"></a>How These Concept are Applied in Practice</h2><p><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/#conclusion">https://colah.github.io/posts/2015-09-Visual-Information/#conclusion</a></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/">https://colah.github.io/posts/2015-09-Visual-Information/</a></li><li><a target="_blank" rel="noopener" href="https://mbernste.github.io/posts/sourcecoding/">https://mbernste.github.io/posts/sourcecoding/</a></li><li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kraft%E2%80%93McMillan_inequality">https://en.wikipedia.org/wiki/Kraft–McMillan_inequality</a></li><li><a target="_blank" rel="noopener" href="https://mathoverflow.net/questions/403036/john-von-neumanns-remark-on-entropy">https://mathoverflow.net/questions/403036/john-von-neumanns-remark-on-entropy</a></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/Mathematics/" class="category-chain-item">Mathematics</a></span></span></div></div><div class="license-box my-3"><div class="license-title"><div>Understanding the Formulation of Information Entropy</div><div>https://abbaswu.github.io/2022/09/16/Understanding-the-Formulation-of-Information-Entropy/</div></div><div class="license-meta"><div class="license-meta-item"><div>Author</div><div>Jifeng Wu</div></div><div class="license-meta-item license-meta-date"><div>Posted on</div><div>September 16, 2022</div></div><div class="license-meta-item"><div>Licensed under</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - Attribution"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2022/09/19/Paper-Review-How-Effective-Developers-Investigate-Source-Code-An-Exploratory-Study/" title="Paper Review: How Effective Developers Investigate Source Code: An Exploratory Study"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Paper Review: How Effective Developers Investigate Source Code: An Exploratory Study</span> <span class="visible-mobile">Previous</span></a></article><article class="post-next col-6"><a href="/2022/09/14/Paper-Review-Asking-and-Answering-Questions-during-a-Programming-Change-Task/" title="Paper Review: Asking and Answering Questions during a Programming Change Task"><span class="hidden-mobile">Paper Review: Asking and Answering Questions during a Programming Change Task</span> <span class="visible-mobile">Next</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t=document.documentElement.getAttribute("data-user-color-scheme");t="dark"===t?"github-dark":"github-light",window.UtterancesThemeLight="github-light",window.UtterancesThemeDark="github-dark";var e=document.createElement("script");e.setAttribute("src","https://utteranc.es/client.js"),e.setAttribute("repo","abbaswu/utterances"),e.setAttribute("issue-term","pathname"),e.setAttribute("label","utterances"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(e)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><script>Fluid.utils.createScript("https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js",(function(){mermaid.initialize({theme:"default"}),Fluid.events.registerRefreshCallback((function(){"mermaid"in window&&mermaid.init()}))}))</script><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">Search</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">Keyword</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">Blog works best with JavaScript enabled</div></noscript></body></html>