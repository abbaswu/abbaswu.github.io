<!DOCTYPE html><html lang="en" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Jifeng Wu"><meta name="keywords" content=""><meta name="description" content="NOTE: The terms &quot;language&quot; and &quot;word&quot; are used metaphorically in this document. A &quot;language&quot; often has many &quot;words&quot;, and the frequency of each &quot;word&quot; varies. If a &quot;language&quot; \(X\) has a total of \(n\)"><meta property="og:type" content="article"><meta property="og:title" content="Understanding the Formulation of Information Entropy"><meta property="og:url" content="https://abbaswu.github.io/2022/09/16/Understanding-the-Formulation-of-Information-Entropy/index.html"><meta property="og:site_name" content="Jifeng Wu&#39;s Personal Website"><meta property="og:description" content="NOTE: The terms &quot;language&quot; and &quot;word&quot; are used metaphorically in this document. A &quot;language&quot; often has many &quot;words&quot;, and the frequency of each &quot;word&quot; varies. If a &quot;language&quot; \(X\) has a total of \(n\)"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/b/b5/International_Morse_Code.svg"><meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/0/04/Kraft_inequality_example.png"><meta property="og:image" content="https://raw.githubusercontent.com/abbaswu/abbaswu.github.io-images/main/Value_ranges_of_a_1_a_2.png"><meta property="article:published_time" content="2022-09-16T07:00:00.000Z"><meta property="article:modified_time" content="2023-11-06T07:31:36.169Z"><meta property="article:author" content="Jifeng Wu"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://upload.wikimedia.org/wikipedia/commons/b/b5/International_Morse_Code.svg"><title>Understanding the Formulation of Information Entropy - Jifeng Wu&#39;s Personal Website</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"abbaswu.github.io",root:"/",version:"1.9.3",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Jifeng Wu's Personal Website" type="application/atom+xml">
</head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Jifeng Wu</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> Home</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> Categories</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> Archives</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/mountains-fog-aerial-view-clouds-sky-blue.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Understanding the Formulation of Information Entropy"></span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> Jifeng Wu </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-09-16 00:00" pubdate>September 16, 2022</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 7.2k words </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 61 mins</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Understanding the Formulation of Information Entropy</h1><div class="markdown-body"><p>NOTE: The terms "language" and "word" are used metaphorically in this document.</p><p>A "language" often has many "words", and the frequency of each "word" varies.</p><p>If a "language" <span class="math inline">\(X\)</span> has a total of <span class="math inline">\(n\)</span> "words", then we can encode a word with <span class="math inline">\(\log_{2}{n}\)</span> binary bits. <strong>But when transmitting the words, we want to keep the encoding of each "word" as short as possible. A common practice is that for those high-frequency "words", we can use shorter encodings, and for those "words" that we use less frequently, we can allow longer encodings.</strong> An example is the Morse code encoding for a "language" consisting of 36 "words" - 26 Latin letters and 10 Arabic numerals.</p><figure><img src="https://upload.wikimedia.org/wikipedia/commons/b/b5/International_Morse_Code.svg" srcset="/img/loading.gif" lazyload alt=""><figcaption>Morse code. The "word" "e" occurs frequently, hence a short code</figcaption></figure><p>So, under some optimal encoding, what limit can the weighted average encoding length of all "words" achieve?</p><p>Suppose our "language" has <span class="math inline">\(n\)</span> "words", <span class="math inline">\(x_1, x_2, \dots, x_n\)</span>, and their probability of occurrence is <span class="math inline">\(p(x_1), p(x_2), \dots, p(x_n)\)</span> (known quantities).</p><p>Assuming that the lengths of the encodings of these "words" are <span class="math inline">\(L(x_1), L(x_2), \dots, L(x_n)\)</span> respectively, the weighted average encoding length of each "word" is:</p><p><span class="math inline">\(\bar{L} = p(x_1) L(x_1) + \dots + p(x_n) L(x_n)\)</span></p><p>How do we find the minimum value of <span class="math inline">\(\bar{L}\)</span>?</p><h2 id="constraints">Constraints</h2><p>Obviously, the encoded length of all "words" is greater than 0. But beyond that, there is a hidden constraint.</p><p><strong>We do not allow one encoding to be a prefix of another encoding, otherwise there will be ambiguity during decoding</strong>. For example, assuming that the three "words" of "A", "B", and "C" in the alphabet are encoded as "0", "1", and "01" respectively, then for For a code like "001", should we decode it as "AAB" or "AC"?</p><p>We call a type of code which requires that there is no whole code word in the system that is a prefix of any other code word in the system as a <strong>prefix code</strong>.</p><p>This means that if we assign a shorter encoding to a "word", it will squeeze a lot of resources out of the encoding space. For example, suppose the "word" "A" is encoded as "0", then it would "squeeze out" "00", "01", etc. from the codewords.</p><p>Suppose the maximum value in <span class="math inline">\(L(x_1), L(x_2), \dots, L(x_n)\)</span> is <span class="math inline">\(L_{max}\)</span>. <strong>Then the encoding of all "words" are nodes on a full binary tree with a height of <span class="math inline">\(L_{max}\)</span>, and the full binary subtrees below each node have no intersection (otherwise violating the properties of the prefix code), as shown below</strong>.</p><figure><img src="https://upload.wikimedia.org/wikipedia/commons/0/04/Kraft_inequality_example.png" srcset="/img/loading.gif" lazyload alt=""><figcaption>The encoding of all "words" are nodes on a full binary tree with a height of <span class="math inline">\(L_{max}\)</span>, and the full binary subtrees below each node have no intersection</figcaption></figure><p>It is obvious that, <strong>all the full binary subtrees below each node, at most cover all the leaves of the full binary tree with height <span class="math inline">\(L_{max}\)</span>.</strong></p><p>For a "word" <span class="math inline">\(x_i, i \in \{1, 2, \dots, n\}\)</span>, the height of the full binary subtree below it is <span class="math inline">\(L_{max} - L(x_i)\)</span>, and it covers <span class="math inline">\(2^{L_{max} - L(x_i)}\)</span> leaves.</p><p>As the full binary tree with height <span class="math inline">\(L_{max}\)</span> has a total of <span class="math inline">\(2^{L_{max}}\)</span>, we have:</p><p><span class="math inline">\(2^{L_{max} - L(x_1)} + 2^{L_{max} - L(x_2)} + \dots + 2^{L_{max} - L(x_n)} \le 2^{L_{max}}\)</span></p><p>This simplifies to:</p><p><span class="math inline">\(2^{- L(x_1)} + 2^{- L(x_2)} + \dots + 2^{- L(x_n)} \le 1\)</span></p><p>This is the Kraft-McMillan inequality.</p><h2 id="optimization">Optimization</h2><p>Therefore, our overall optimization objective is:</p><p><span class="math inline">\(\bar{L} = p(x_1) L(x_1) + \dots + p(x_n) L(x_n)\)</span></p><p>Subject to:</p><ul><li><span class="math inline">\(p(x_i) \in (0, 1), i \in \{1, 2, \dots, n\}\)</span> are constants</li><li><span class="math inline">\(p(x_1) + p(x_2) + \dots + p(x_n) = 1\)</span></li><li><span class="math inline">\(L(x_i) &gt; 0, i \in \{1, 2, \dots, n\}\)</span> are independent variables</li><li><span class="math inline">\(2^{- L(x_1)} + 2^{- L(x_2)} + \dots + 2^{- L(x_n)} \le 1\)</span></li></ul><hr><p><strong>We can analyze the problem for the case where there are only two words <span class="math inline">\(x_1, x_2\)</span></strong>. At this point, we have:</p><p><span class="math inline">\(\bar{L} = p(x_1) L(x_1) + p(x_2) L(x_2)\)</span></p><p>Equivalently:</p><p><span class="math inline">\(\bar{L} = p(x_1) L(x_1) + (1 - p(x_1)) L(x_2)\)</span></p><p>Subject to:</p><ul><li><span class="math inline">\(p(x_1) \in (0, 1)\)</span> is a constant</li><li><span class="math inline">\(L(x_i) &gt; 0, i \in \{1, 2\}\)</span> are independent variables</li><li><span class="math inline">\(2^{- L(x_1)} + 2^{- L(x_2)} \le 1\)</span></li></ul><p>Define <span class="math inline">\(a_1 = 2^{- L(x_1)}, a_2 = 2^{- L(x_2)}\)</span>. Now we have:</p><p><span class="math inline">\(\bar{L} = - p(x_1) \log_2{a_1} - (1 - p(x_1)) \log_2{a_2}\)</span></p><p>Subject to:</p><ul><li><span class="math inline">\(p(x_1) \in (0, 1)\)</span> is a constant</li><li><span class="math inline">\(0 &lt; a_i &lt;1, i \in \{1, 2\}\)</span> are independent variables</li><li><span class="math inline">\(a_1 + a_2 \le 1\)</span></li></ul><p>At this point, <span class="math inline">\(\bar{L}\)</span> can be regarded as a binary function whose independent variables are <span class="math inline">\(a_1, a_2\)</span>, and the value ranges of the independent variables <span class="math inline">\(a_1, a_2\)</span> are as follows:</p><figure><img src="https://raw.githubusercontent.com/abbaswu/abbaswu.github.io-images/main/Value_ranges_of_a_1_a_2.png" srcset="/img/loading.gif" lazyload alt=""><figcaption>Value ranges of <span class="math inline">\(a_1, a_2\)</span></figcaption></figure><p>We want to find the minimum value of <span class="math inline">\(\bar{L}(a_1, a_2)\)</span> within this range of values.</p><p>The gradient of <span class="math inline">\(\bar{L}(a_1, a_2)\)</span> is as follows:</p><p><span class="math inline">\(\nabla\bar{L}(a_1, a_2) = {(-p(x_1) \log{2} \frac{1}{a_1}, -(1 - p(x_1)) \log{2} \frac{1}{a_2})}^T\)</span></p><p>Within the value range of the independent variables <span class="math inline">\(a_1, a_2\)</span>, <span class="math inline">\(\nabla\bar{L}(a_1, a_2)\)</span> is always less than 0, which means that <strong>with the growth of <span class="math inline">\(a_1, a_2\)</span>, <span class="math inline">\(\bar{L}(a_1, a_2)\)</span> decreases</strong>. Therefore, the maximum value of <strong><span class="math inline">\(\bar{L}(a_1, a_2)\)</span> must occur when <span class="math inline">\((a_1, a_2)\)</span> is on the boundary line <span class="math inline">\(a_1 + a_2 = 1\)</span></strong>.</p><p>Substituting the boundary line <span class="math inline">\(a_1 + a_2 = 1\)</span> into <span class="math inline">\(\bar{L}(a_1, a_2)\)</span>, you can get a unary function:</p><p><span class="math inline">\(\bar{L}(a_1) = - p(x_1) \log_2{a_1} - (1 - p(x_1)) \log_2{(1 - a_1)}\)</span></p><p>The constraints include:</p><ul><li><span class="math inline">\(p(x_1) \in (0, 1)\)</span>, constant</li><li><span class="math inline">\(0 &lt; a_1 &lt; 1\)</span></li></ul><p>The derivative of <span class="math inline">\(\bar{L}(a_1)\)</span> is as follows:</p><p><span class="math inline">\(\frac{d \bar{L}(a_1)}{d a_1} = \frac{\log{2} (a_1 - p(x_1))}{a_1 (1 - a_1)}\)</span></p><p>The constraints include:</p><ul><li><span class="math inline">\(p(x_1) \in (0, 1)\)</span> is a constant</li><li><span class="math inline">\(0 &lt; a_1 &lt; 1\)</span></li></ul><p>When <span class="math inline">\(0 &lt; a_1 &lt; p(x_1)\)</span>, <span class="math inline">\(\frac{d \bar{L}(a_1)}{d a_1} &lt; 0\)</span>, <span class="math inline">\(\bar{L}(a_1)\)</span> monotonically decreases, and when <span class="math inline">\(p(x_1) &lt; a_1 &lt; 1\)</span>, <span class="math inline">\(\frac{d \bar{L}(a_1)}{d a_1} &gt; 0\)</span>, <span class="math inline">\(\bar{L}(a_1)\)</span> monotonically increases. Therefore, when <span class="math inline">\(a_1 = p(x_1)\)</span>, <span class="math inline">\(\bar{L}(a_1)\)</span> obtains the minimum value.</p><p>As <span class="math inline">\(a_1 = 2^{- L(x_1)}, a_2 = 2^{- L(x_2)}\)</span>, this means that, for:</p><p><span class="math inline">\(\bar{L} = p(x_1) L(x_1) + (1 - p(x_1)) L(x_2)\)</span></p><p>Subject to:</p><ul><li><span class="math inline">\(p(x_1) \in (0, 1)\)</span> is a constant</li><li><span class="math inline">\(L(x_i) &gt; 0, i \in \{1, 2\}\)</span> are independent variables</li><li><span class="math inline">\(2^{- L(x_1)} + 2^{- L(x_2)} \le 1\)</span></li></ul><p><strong><span class="math inline">\(\bar{L}\)</span>'s minima occurs when <span class="math inline">\(L(x_1) = -\log_2{p(x_1)}, L(x_2) = -\log_2{p(x_2)}\)</span>, and the minima is <span class="math inline">\(- p(x_1) \log_2{p(x_1)} - p(x_2) \log_2{p(x_2)}\)</span></strong>.</p><hr><p>Going back to the multivariate optimization problem:</p><p><span class="math inline">\(\bar{L} = p(x_1) L(x_1) + \dots + p(x_n) L(x_n)\)</span></p><p>Subject to:</p><ul><li><span class="math inline">\(p(x_i) \in (0, 1), i \in \{1, 2, \dots, n\}\)</span> are constants</li><li><span class="math inline">\(p(x_1) + p(x_2) + \dots + p(x_n) = 1\)</span></li><li><span class="math inline">\(L(x_i) &gt; 0, i \in \{1, 2, \dots, n\}\)</span> are independent variables</li><li><span class="math inline">\(2^{- L(x_1)} + 2^{- L(x_2)} + \dots + 2^{- L(x_n)} \le 1\)</span></li></ul><p><strong><span class="math inline">\(\bar{L}\)</span>'s minima occurs when <span class="math inline">\(L(x_i) = -\log_2{p(x_i)}, i \in \{1, 2, \dots, n\}\)</span>, and the minima is <span class="math inline">\(- p(x_1) \log_2{p(x_1)} - \dots - p(x_n) \log_2{p(x_n)}\)</span></strong>.</p><h2 id="definition-of-information-entropy">Definition of Information Entropy</h2><p>If a language "language" <span class="math inline">\(X\)</span> has <span class="math inline">\(n\)</span> "words", <span class="math inline">\(x_1, x_2, \dots, x_n\)</span>, the probability of their occurrence is <span class="math inline">\(p(x_1), p(x_2), \dots, p(x_n)\)</span>, then <strong>all "words" under a certain optimal encoding, the previously calculated minimum weighted average encoding length</strong>, <span class="math inline">\(- p(x_1) \log_2{p(x_1)} - \dots - p (x_n) \log_2{p(x_n)}\)</span>, is called the <strong>information entropy</strong> of the "language", denoted as <span class="math inline">\(H(X)\)</span>.</p><p>The reason why it is called "information entropy" is mainly due to the following reasons:</p><ul><li>From von Neumann's naming suggestion for Shannon: My greatest concern was what to call it. I thought of calling it 'information,' but the word was overly used, so I decided to call it 'uncertainty.' When I discussed it with John von Neumann, he had a better idea. Von Neumann told me, 'You should call it entropy, for two reasons. <strong>In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name. In the second place, and more important, no one really knows what entropy really is, so in a debate you will always have the advantage.</strong></li><li>In a sense, it does reflect the frequency distribution of the "words" of "language" <span class="math inline">\(X\)</span>, just as entropy in thermodynamics reflects the distribution of microscopic particles. <strong>The lower <span class="math inline">\(H(X)\)</span> is, the more the case that only a few words are used frequently in <span class="math inline">\(X\)</span>; the higher <span class="math inline">\(H(X)\)</span> is, the more the case that all words in <span class="math inline">\(X\)</span> are used frequency.</strong></li></ul><h2 id="links-to-explanations-of-related-concepts">Links to Explanations of Related Concepts</h2><ul><li><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/#cross-entropy">Cross Entropy</a></li><li><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/#entropy-and-multiple-variables">Joint Entropy</a></li><li><a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/#mutual-information">Mutual Information</a></li></ul><h2 id="how-these-concept-are-applied-in-practice">How These Concept are Applied in Practice</h2><p>https://colah.github.io/posts/2015-09-Visual-Information/#conclusion</p><h2 id="references">References</h2><ul><li>https://colah.github.io/posts/2015-09-Visual-Information/</li><li>https://mbernste.github.io/posts/sourcecoding/</li><li>https://en.wikipedia.org/wiki/Kraftâ€“McMillan_inequality</li><li>https://mathoverflow.net/questions/403036/john-von-neumanns-remark-on-entropy</li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/Mathematics/" class="category-chain-item">Mathematics</a></span></span></div></div><div class="license-box my-3"><div class="license-title"><div>Understanding the Formulation of Information Entropy</div><div>https://abbaswu.github.io/2022/09/16/Understanding-the-Formulation-of-Information-Entropy/</div></div><div class="license-meta"><div class="license-meta-item"><div>Author</div><div>Jifeng Wu</div></div><div class="license-meta-item license-meta-date"><div>Posted on</div><div>September 16, 2022</div></div><div class="license-meta-item"><div>Licensed under</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - Attribution"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2022/09/19/Paper-Reading-How-Effective-Developers-Investigate-Source-Code-An-Exploratory-Study/" title="Paper Reading: How Effective Developers Investigate Source Code: An Exploratory Study"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Paper Reading: How Effective Developers Investigate Source Code: An Exploratory Study</span> <span class="visible-mobile">Previous</span></a></article><article class="post-next col-6"><a href="/2022/09/14/Paper-Reading-Asking-and-Answering-Questions-during-a-Programming-Change-Task/" title="Paper Reading: Asking and Answering Questions during a Programming Change Task"><span class="hidden-mobile">Paper Reading: Asking and Answering Questions during a Programming Change Task</span> <span class="visible-mobile">Next</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t=document.documentElement.getAttribute("data-user-color-scheme");t="dark"===t?"github-dark":"github-light",window.UtterancesThemeLight="github-light",window.UtterancesThemeDark="github-dark";var e=document.createElement("script");e.setAttribute("src","https://utteranc.es/client.js"),e.setAttribute("repo","abbaswu/utterances"),e.setAttribute("issue-term","pathname"),e.setAttribute("label","utterances"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(e)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><script>Fluid.utils.createScript("https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js",(function(){mermaid.initialize({theme:"default"}),Fluid.events.registerRefreshCallback((function(){"mermaid"in window&&mermaid.init()}))}))</script><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">Search</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">Keyword</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">Blog works best with JavaScript enabled</div></noscript></body></html>