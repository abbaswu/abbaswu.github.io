<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Date and Time Types in Python</title>
    <link href="/2022/12/31/Date-and-Time-Types-in-Python/"/>
    <url>/2022/12/31/Date-and-Time-Types-in-Python/</url>
    
    <content type="html"><![CDATA[<p>There are many types in Python which can store date and time information. These types can be broadly divided into two categories:</p><h1 id="JSON-Serializable-Formats"><a href="#JSON-Serializable-Formats" class="headerlink" title="JSON Serializable Formats"></a>JSON Serializable Formats</h1><ul><li>UNIX Timestamp (e.g. <code>0</code>)</li><li>ISO 8601 String (e.g. <code>&#39;1970-01-01T00:00:00&#39;</code>)</li></ul><p>UNIX Timestamp has its roots in the system time of Unix operating systems. It is now widely used in databases, programming languages, file systems, and other computer operating systems. It counts the number of seconds that have passed since the Unix epoch began on January 1, 1970 at 00:00:00 UTC, minus any modifications made for leap seconds.</p><p>ISO 8601 is an international standard for the transmission and interchange of time- and date-related information on a global scale. Dates in the Gregorian calendar, hours based on the 24-hour timekeeping system, with an optional UTC offset, time intervals, and combinations of these are covered by ISO 8601. The standard offers a clear, unambiguous manner of expressing calendar dates and times in international communications, notably to prevent numeric dates and times from being misinterpreted when such data is sent between nations.</p><p>As the categorization suggests, these formats can be used in JSON serialization, and are widely adopted in data exchange formats and APIs. For example, Stripe APIs use UNIX Timestamps, while Twitter and Dropbox APIs use ISO 8601 Strings. UNIX Timestamps are easier and more efficient to handle, while ISO 8601 Strings have the virtue of being human-readable.</p><h1 id="Widely-Used-In-Memory-Data-Structures"><a href="#Widely-Used-In-Memory-Data-Structures" class="headerlink" title="Widely Used In Memory Data Structures"></a>Widely Used In Memory Data Structures</h1><ul><li><code>datetime.datetime</code> (e.g. <code>datetime.datetime(1970, 1, 1, 0, 0)</code>)</li><li><code>datetime.date</code> (e.g. <code>datetime.date(1970, 1, 1)</code>)</li><li><code>pandas.Timestamp</code> (e.g. <code>Timestamp(&#39;1970-01-01 00:00:00&#39;)</code>)</li></ul><p>As the categorization suggests, these formats are in-memory, structured representations of date and time information.</p><p><code>datetime.datetime</code> and <code>datetime.date</code> are types implemented (and widely used) in the Python Standard Library. <code>datetime.date</code> represents a date (year, month, day) in an idealized calendar, which is the existing Gregorian calendar infinitely stretched in both directions, while <code>datetime.datetime</code> also combines the data from a time object (hour, minute, second, microsecond).</p><p><code>pandas.Timestamp</code> is implemented in <code>pandas</code>. It is the <code>pandas</code> replacement for <code>datetime.datetime</code>, and is the type used for the entries that make up a <code>pandas.DatetimeIndex</code>, and other time series-oriented data structures in <code>pandas</code>. Furthermore, it is also widely used across the Python Ecosystem for Data Science, such as being used by <code>matplotlib</code> as the <code>xticks</code> for plotting a <code>pandas.Series</code> with a <code>pandas.DatetimeIndex</code>, as shown below.</p><p><img src="https://i.stack.imgur.com/gLpr4.png" alt="`pandas.Timestamp` is the type used for the entries that make up a `pandas.DatetimeIndex`, and is used by `matplotlib` as the `xticks` for plotting a `pandas.Series` with a `pandas.DatetimeIndex`"></p><h1 id="Converting-Between-These-Types"><a href="#Converting-Between-These-Types" class="headerlink" title="Converting Between These Types"></a>Converting Between These Types</h1><p>With so many types in Python which can store date and time information, it is important to know how to convert between them. The following State Diagram depicts how we should perform the conversions.</p><pre><code class=" mermaid">stateDiagram    state &quot;UNIX Timestamp&quot; as UNIXTimestamp: 0    state &quot;ISO 8601 String&quot; as ISO8601String: &#x27;1970-01-01T00:00:00&#x27;    state &quot;datetime.datetime&quot; as DatetimeDatetime: datetime.datetime(1970, 1, 1, 0, 0)    state &quot;datetime.date&quot; as DatetimeDate: datetime.date(1970, 1, 1)    state &quot;pandas.Timestamp&quot; as PandasTimestamp: Timestamp(&#x27;1970-01-01 00:00:00&#x27;)      UNIXTimestamp --&gt; DatetimeDatetime: datetime.datetime.fromtimestamp function    UNIXTimestamp --&gt; PandasTimestamp: constructor    ISO8601String --&gt; DatetimeDatetime: isoformat method    ISO8601String --&gt; PandasTimestamp: constructor    DatetimeDatetime --&gt; UNIXTimestamp: datetime.datetime.timestamp function    DatetimeDatetime --&gt; ISO8601String: datetime.datetime.fromiso function    DatetimeDatetime --&gt; DatetimeDate: date method    DatetimeDatetime --&gt; PandasTimestamp: constructor    DatetimeDate --&gt; PandasTimestamp: pandas.Timestamp constructor    PandasTimestamp --&gt; UNIXTimestamp: timestamp method    PandasTimestamp --&gt; ISO8601String: isoformat method    PandasTimestamp --&gt; DatetimeDatetime: to_pydatetime method</code></pre><p>References:</p><ul><li><a href="https://en.wikipedia.org/wiki/Unix_time">https://en.wikipedia.org/wiki/Unix_time</a></li><li><a href="https://en.wikipedia.org/wiki/ISO_8601">https://en.wikipedia.org/wiki/ISO_8601</a></li><li><a href="https://dev.to/xngwng/do-you-prefer-unix-epoch-a-number-or-iso-8601-a-string-for-timestamps--28ll">https://dev.to/xngwng/do-you-prefer-unix-epoch-a-number-or-iso-8601-a-string-for-timestamps--28ll</a></li><li><a href="https://stackoverflow.com/questions/15554586/timestamps-iso8601-vs-unix-timestamp">https://stackoverflow.com/questions/15554586/timestamps-iso8601-vs-unix-timestamp</a></li><li><a href="https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/">https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/</a></li><li><a href="https://www.programiz.com/python-programming/datetime/timestamp-datetime">https://www.programiz.com/python-programming/datetime/timestamp-datetime</a></li><li><a href="https://stackoverflow.com/questions/3743222/how-do-i-convert-a-datetime-to-date">https://stackoverflow.com/questions/3743222/how-do-i-convert-a-datetime-to-date</a></li><li><a href="https://stackoverflow.com/questions/969285/how-do-i-translate-an-iso-8601-datetime-string-into-a-python-datetime-object">https://stackoverflow.com/questions/969285/how-do-i-translate-an-iso-8601-datetime-string-into-a-python-datetime-object</a></li><li><a href="https://www.programiz.com/python-programming/datetime/timestamp-datetime">https://www.programiz.com/python-programming/datetime/timestamp-datetime</a></li><li><a href="https://pynative.com/python-iso-8601-datetime/">https://pynative.com/python-iso-8601-datetime/</a></li><li><a href="https://docs.python.org/3/library/datetime.html">https://docs.python.org/3/library/datetime.html</a></li><li><a href="https://stackoverflow.com/questions/1937622/convert-date-to-datetime-in-python">https://stackoverflow.com/questions/1937622/convert-date-to-datetime-in-python</a></li><li><a href="https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html">https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html</a></li><li><a href="https://stackoverflow.com/questions/993358/creating-a-range-of-dates-in-python">https://stackoverflow.com/questions/993358/creating-a-range-of-dates-in-python</a></li><li><a href="https://stackoverflow.com/questions/41046630/set-time-formatting-on-a-datetime-index-when-plotting-pandas-series">https://stackoverflow.com/questions/41046630/set-time-formatting-on-a-datetime-index-when-plotting-pandas-series</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Code</category>
      
      <category>Python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Social Media Strategy (tentative)</title>
    <link href="/2022/12/31/Social-Media-Strategy-tentative/"/>
    <url>/2022/12/31/Social-Media-Strategy-tentative/</url>
    
    <content type="html"><![CDATA[<p>Social media accounts are windows that exhibit our image to the public, and we must pay attention to them. However, on the one hand, the use of social media should complement, and not negatively affect, our routine work, study, and life patterns; on the other hand, different social media platforms generally differ in terms of appropriate content to display. After a period of observation and reflection, we have developed the following social media strategy to address these issues, as depicted in the Bipartite Graph below.</p><pre><code class=" mermaid">stateDiagramstate &quot;Life Moments&quot; as LifeMomentsstate &quot;Reflections on Life&quot; as ReflectionsOnLifestate &quot;Work Moments&quot; as WorkMomentsstate &quot;Reflections on Work&quot; as ReflectionsOnWorkstate &quot;Reflections on Development&quot; as ReflectionsOnDevelopmentstate &quot;Detailed Explanations&quot; as DetailedExplanationsstate &quot;Planning&quot; as Planningstate &quot;Instagram&quot; as Instagramstate &quot;小红书&quot; as XiaoHongShustate &quot;WeChat&quot; as WeChatstate &quot;QQ&quot; as QQstate &quot;LinkedIn&quot; as LinkedInstate &quot;Blog&quot; as Blog    LifeMoments --&gt; Instagram    LifeMoments --&gt; XiaoHongShu    LifeMoments --&gt; WeChat    LifeMoments --&gt; QQ        ReflectionsOnLife --&gt; XiaoHongShu    ReflectionsOnLife --&gt; Twitter    ReflectionsOnLife --&gt; WeChat    ReflectionsOnLife --&gt; QQ    WorkMoments --&gt; Twitter    WorkMoments --&gt; WeChat    WorkMoments --&gt; QQ    ReflectionsOnWork --&gt; Twitter    ReflectionsOnWork --&gt; WeChat    ReflectionsOnWork --&gt; QQ    ReflectionsOnDevelopment --&gt; LinkedIn        DetailedExplanations --&gt; Blog        Planning --&gt; Blog</code></pre><p>In addition, a pain point we will encounter is that we will post some content to both Chinese and English social media platforms. To overcome this problem, we can first write a Chinese (or English) version and use automated tools such as Google Translate and DeepL before manually touching up the machine-translated version.</p><p>Furthermore, to boost the following of our social media accounts, when we need to share the content posted on social media with others via private chat, we can share the link of the content posted to social media instead of copying and pasting the content itself.</p>]]></content>
    
    
    <categories>
      
      <category>Planning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Command-line HTTP Servers for Rapid File Sharing</title>
    <link href="/2022/12/26/Command-line-HTTP-Servers-for-Rapid-File-Sharing/"/>
    <url>/2022/12/26/Command-line-HTTP-Servers-for-Rapid-File-Sharing/</url>
    
    <content type="html"><![CDATA[<p>Sometimes, we need an ad-hoc, quick-and-dirty way of sharing files with others while maintaining complete control of the data transmission.</p><ul><li>We should not store our data on any third-party servers.</li><li>The connections established through the network should be point-to-point.</li></ul><p>Being supported by virtually every Internet-capable device and from both command-line tools (such as wget and curl) and graphical Web browsers, the HTTP protocol is one of our best bets. Thus, we have compiled a list of command-line HTTP servers that enable rapid file sharing and compare their features.</p><h1 id="python3-m-http-server"><a href="#python3-m-http-server" class="headerlink" title="python3 -m http.server"></a><a href="https://docs.python.org/dev/library/http.server.html">python3 -m http.server</a></h1><p>The Python standard library has a barebones built-in HTTP server. Not recommended for production.</p><ul><li>Language: Python</li></ul><h1 id="mjpclab-x2F-go-http-file-server"><a href="#mjpclab-x2F-go-http-file-server" class="headerlink" title="mjpclab&#x2F;go-http-file-server"></a><a href="https://github.com/mjpclab/go-http-file-server">mjpclab&#x2F;go-http-file-server</a></h1><p>Simple command line based HTTP file server to share local file system.</p><ul><li>Features:<ul><li>Cross-Origin Resource Sharing (CORS)</li><li>Frontend Features:<ul><li>File Upload</li><li>File Delete</li><li>Create Subdirectory</li><li>Download the Current Directory as an Archive</li></ul></li><li>HTTP Basic Authentication</li><li>HTTP Range Requests</li><li>HTTP Strict Transport Security (HSTS)</li><li>HTTPS</li></ul></li><li>GitHub Stars: 175</li><li>Language: Go</li></ul><h1 id="mar10-x2F-wsgidav"><a href="#mar10-x2F-wsgidav" class="headerlink" title="mar10&#x2F;wsgidav"></a><a href="https://github.com/mar10/wsgidav">mar10&#x2F;wsgidav</a></h1><p>A generic and extendable WebDAV server written in Python and based on WSGI.</p><ul><li>Features:<ul><li>HTTP Range Requests</li></ul></li><li>GitHub Stars: 640</li><li>Language: Python</li><li>Multithreaded</li><li>WebDAV Server</li></ul><h1 id="TheWaWaR-x2F-simple-http-server"><a href="#TheWaWaR-x2F-simple-http-server" class="headerlink" title="TheWaWaR&#x2F;simple-http-server"></a><a href="https://github.com/TheWaWaR/simple-http-server">TheWaWaR&#x2F;simple-http-server</a></h1><p><img src="https://github.com/TheWaWaR/simple-http-server/raw/master/screenshot.png" alt="Screenshot"></p><ul><li>Features:<ul><li>Cross-Origin-Embedder-Policy (COEP)</li><li>Cross-Origin Resource Sharing (CORS) </li><li>Cross-Origin-Opener-Policy (COOP)</li><li>HTTP Basic Authentication</li><li>HTTP Range Requests</li><li>HTTPS</li><li>Frontend Features:<ul><li>File Upload</li></ul></li></ul></li><li>GitHub Stars: 785</li><li>Language: Rust</li><li>Multithreaded</li></ul><h1 id="http-party-x2F-http-server"><a href="#http-party-x2F-http-server" class="headerlink" title="http-party&#x2F;http-server"></a><a href="https://github.com/http-party/http-server">http-party&#x2F;http-server</a></h1><p><code>http-server</code> is a simple, zero-configuration command-line static HTTP server. It is powerful enough for production usage, but it’s simple and hackable enough to be used for testing, local development and learning.</p><ul><li>Features:<ul><li>Cross-Origin Resource Sharing (CORS)</li><li>HTTP Basic Authentication</li><li>HTTP Range Requests</li><li>HTTPS</li></ul></li><li>GitHub Stars: 12.4k</li><li>Language: node.js</li></ul><h1 id="EstebanBorai-x2F-http-server"><a href="#EstebanBorai-x2F-http-server" class="headerlink" title="EstebanBorai&#x2F;http-server"></a><a href="https://github.com/EstebanBorai/http-server">EstebanBorai&#x2F;http-server</a></h1><p>Simple and configurable command-line HTTP server</p><ul><li>Features:<ul><li>Cross-Origin Resource Sharing (CORS)</li><li>HTTP Basic Authentication</li><li>HTTPS</li><li>GZip Compression</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Code</category>
      
      <category>Unix</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Efficient scalable thread-safety-violation detection: finding thousands of concurrency bugs during testing</title>
    <link href="/2022/11/27/Paper-Review-Efficient-scalable-thread-safety-violation-detection-finding-thousands-of-concurrency-bugs-during-testing/"/>
    <url>/2022/11/27/Paper-Review-Efficient-scalable-thread-safety-violation-detection-finding-thousands-of-concurrency-bugs-during-testing/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://dl.acm.org/doi/10.1145/3341301.3359638">here</a>.</p><p>This paper presents Thread Safety Violation Detection (TSVD), a tool that dynamically detects thread safety violations with low runtime overhead, and which is compatible with real-world, distributed-developed code employing different synchronization mechanisms. The tool frames thread safety violations as two methods, with one of them being a write operation, occurring concurrently. It infers thread safety violations using a very creative approach. First, it instruments the program and detects method calls that access objects behind thread-safety contracts. Later on, during the execution of the program, TSVD injects delays into threads with method calls accessing those objects and monitors whether another thread also accesses the same objects during the delay. As this may incur significant overhead, the tool uses two strategies to determine when to inject delays - keeping track of “near misses”, where the two method calls of two threads occur within a time threshold apart from each other, and inferring “happens before” relations, to rule out two accesses which are causally related.</p><p>The tool was tested on 43000 .NET programs in Microsoft teams, and its bug-finding capability outperformed both existing tools and configuring TSVD to emulate the strategies of existing tools, which shows the feasibility of TSVD.</p><p>There are two questions that come to mind after reading this paper:</p><ul><li>How does the tool acquire the information on which methods are thread-unsafe?</li><li>The approach the tool uses to infer thread safely - injecting delays and monitoring the behavior of other threads - sounds very interesting to me. Have there been any other applications of such an approach?</li><li>What is the sensitivity of the relevant parameters used in TSVD to its effectiveness and efficiency? Is there any guide on how to properly adjust these parameters?</li></ul><hr><p>Feedback from the Class Discussion</p><p>The proposed approach can handle different concurrency models, such as:</p><ul><li>async</li><li>task-based</li><li>thread-based</li></ul><p>But can it handle unstructured concurrency?</p><p>The approach generalizes data race for objects and data structures at the method-level (e.g. there cannot be two simultaneous calls to add() for a <code>List</code> class).</p><p>Using delays can handle many more cases than reasoning about thread scheduling. It is a “simple thing” which works for many cases (akin to fuzzing).</p><p>The approach requires manually specifying read and write APIs. Is it possible to create a semi-automatic approach starting from contracts labeled for standard library APIs?</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Hybrid dynamic data race detection</title>
    <link href="/2022/11/23/Paper-Review-Hybrid-dynamic-data-race-detection/"/>
    <url>/2022/11/23/Paper-Review-Hybrid-dynamic-data-race-detection/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/781498.781528">here</a>.</p><p>The paper proposes a hybrid approach to dynamically (at runtime) data races in multithreaded Java programs. It first proposes two specific detection approaches, each with its strengths and weaknesses. The first is lockset-based detection, which identifies a data race when multiple threads use a shared memory location without holding a shared lock object. Such an approach is fast but may lead to false positives. As a result, the paper proposes another approach, happens-before detection, which uses several heuristics to reason about relations between events and infer whether a potential race has occurred at a particular memory location. In comparison, this approach is more computationally expensive and may lead to false negatives. Considering that neither approach is sound, they combine the two approaches by first using lockset-based detection to identify potential data races before using happens-before detection to reason whether these are probable. The paper then conducts an experimental study of their hybrid approach on various Java programs, demonstrating its effectiveness and efficiency.</p><p>I like this paper’s idea of combining a pessimistic and optimistic approach when doing program analysis. Are there any other works that use such an idea?</p><p>However, I have a question concerning the applicability of the hybrid approach in real life. Although pessimistic, shouldn’t lockset-based detection be enough to stamp out all potential data races by providing programmers with feedback to add relevant locks to prevent such possible data races? This is relevant to the requirements for defensive programming. Or are there design patterns where multiple threads can safely use a shared memory location without holding a common lock and not lead to data races?</p><hr><p>Feedback from the Class Discussion</p><p>Difference Between Race Condition and Data Race:</p><ul><li>Race Condition: There are multiple threads, and the behavior of program depends on thread scheduling.</li><li>Data Race: Different from race condition. This frequently happens when you parallelize a program that shouldn’t be parallelized. Data race can be solved by using locks, but there may still be race coditions.</li></ul><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gams">Thread<span class="hljs-number">-1</span>:<br><br><span class="hljs-function"><span class="hljs-title">synchronized</span>(<span class="hljs-params">...</span>)</span> &#123;<br>    x = <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gams">Thread<span class="hljs-number">-2</span>:<br><br><span class="hljs-function"><span class="hljs-title">synchronized</span>(<span class="hljs-params">...</span>)</span>&#123;<br>    x = <span class="hljs-number">2</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>Modelling in the Paper:</p><ul><li>Lamport Timestamps&#x2F;Vector Clocks</li><li>Thread events: statement executions in threads. A thread event is dependent on previous thread events. This is captured used using the happens-before formal definition in the paper, but leads to false negatives.</li><li>Thread communications: signals (enforce order) and locks (mutually exclusive).</li><li>Message send&#x2F;receive: enqueue and dequeue.</li></ul><p>Architecure-dependednt atomic operations can also be a lock-free solution (e.g. C++’s atomic).</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Lightweight Verification of Array Indexing</title>
    <link href="/2022/11/16/Paper-Review-Lightweight-Verification-of-Array-Indexing/"/>
    <url>/2022/11/16/Paper-Review-Lightweight-Verification-of-Array-Indexing/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/3213846.3213849">here</a>.</p><h1 id="Summary-of-the-Paper"><a href="#Summary-of-the-Paper" class="headerlink" title="Summary of the Paper"></a>Summary of the Paper</h1><p>The authors propose a methodology to detect out-of-bound array accesses statically. They first define that criteria that ideal techniques for detecting out-of-bound array accesses should satisfy, before analyzing the insufficiency of existing academic and industrial approaches, and presenting their own approach, Index Checker, implemented for Java.</p><p>Index Checker reduces checking array bonds to identifying 7 kinds of knowledge, which concern array index and array length, and form a hierarchy. It models such hierarchical knowledge as a Type System, requires the user to write “Type” Annotations at procedure boundaries, and verifies that values have the given “Type” at runtime. This is implemented using Checker Framework, an “industrial-strength, open-source tool for building Java type systems”.</p><p>The authors evaluate Index Checker on 3 large-scale, well-tested Java projects (Google Guava, JFreeChart, Plume-lib), and compare Index Checker with 3 other approaches (FindBugs, KeY, and Clousot), proving the effectiveness of Index Checker (scalability, finding bugs in well-tested programs, and low false positive rate). They also assess the burden of writing type annotations for Index Checker.</p><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>What is the rationale behind the 7 kinds of knowledge concerning array index and array length proposed in the paper?</li><li>I am not very familiar with Type Theory, which may have impeded my understanding of the value of the paper. What are the benefits of using Type Systems and Type Inference, and using Type Annotations to capture known constraints? Is it just to leverage the power of Checker Framework, an “industrial-strength, open-source tool for building Java type systems”, for sound inference? Or are there any further benefits?</li><li>No matter what the benefits are, from this paper, modeling hierarchical knowledge as a Type System, using Type Annotations to capture known constraints, and using Type Inference to verify such constraints sounds like a very innovative technique with many potential use cases. Have there been any other applications of such a technique?</li></ul><hr><h1 id="Feedback-from-the-Class-Discussion"><a href="#Feedback-from-the-Class-Discussion" class="headerlink" title="Feedback from the Class Discussion"></a>Feedback from the Class Discussion</h1><p>The hierarchy of knowledge is derived from Exploratory Data Analysis (trying stuff until it works, see Section 2.8).</p><p>“Subtype” is a kind of Comparable Partial Ordering (‘&lt;’). The Types in the Bottom have more information, while the Types in the Top have less information.</p><p>In Java, aside from Inheritance, another form of Subtyping is Function Subtyping. e.g. Comparator (to compare two Dog’s we can pass a function that compares two Animal’s) the inputs can be more general types.</p><p>Rules define what to do when a Pattern is encountered; however, it takes a (nontrivial) search to determine the order to apply the rules.</p><p>Fixed Point: Convergence of Information.</p><p>Reach a Fixed Point: Iterate until Convergence.</p><p>The Paper uses Subtyping to implement Widening.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Modular Checking for Buffer Overflows in the Large</title>
    <link href="/2022/11/13/Paper-Review-Modular-Checking-for-Buffer-Overflows-in-the-Large/"/>
    <url>/2022/11/13/Paper-Review-Modular-Checking-for-Buffer-Overflows-in-the-Large/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/1134285.1134319">here</a>.</p><h1 id="Background-Information"><a href="#Background-Information" class="headerlink" title="Background Information"></a>Background Information</h1><h2 id="Datalog"><a href="#Datalog" class="headerlink" title="Datalog"></a>Datalog</h2><ul><li>Declarative Programming Language which began as a Query Language for Relational Databases, and is now used in Data Integration, Information Extraction, Program Analysis, Cloud Computing, Machine Learning, etc.</li><li>Akin to SQL in many aspects.<ul><li>Not Turing Complete.</li><li>Used as a Domain Specific Language.</li><li>No Canonical Implementation, many different Implementations exist for different Applications (c.f. SQLite, MySQL, PostgreSQL, etc. for SQL).</li></ul></li><li>Follows the ‘Logic Programming’ Paradigm.<ul><li>A Program consists of Constants, Variables, Facts, and Rules (based on First Order Logic, in a form similar to “a new Fact A is true if B, C, and D are already known to be true”).</li><li>The Execution of a Program is <em>iteratively inferring new Facts given the Rules</em>.</li><li>Maps very nicely to many problems encountered during Program Analysis.</li></ul></li></ul><h1 id="Summary-of-the-Paper"><a href="#Summary-of-the-Paper" class="headerlink" title="Summary of the Paper"></a>Summary of the Paper</h1><p>The authors proposed a Methodology for detecting possible Buffer Overflow-based Security Exploits in C code and providing developers with instant feedback during the build process. The Methodology prefers usability over accuracy, and should be used alongside other tools in a Swiss Cheese Model against Security Exploits.</p><p>First, the authors proposed a Simple Annotations Language for annotating Pointers passed as parameters to and returned from Functions, to denote Preconditions and Postconditions of Function Execution. The authors propose that for new code, annotation should be inserted manually, and code should be fully annotated before being checked in to Version Control.</p><p>For legacy codebases and&#x2F;or third-party code without such Annotations, the authors propose an Inference Engline, SALInfer, which tries to infer such Annotations, preferring Coverage over Accuracy. SALInfer supports specifying Inference Algorithms using Datalog.</p><p>Finally, the authors propose a modular checker, ESPX, which tries to infer if a program is potentially vulnerable to Buffer Overflow-based Security Exploits by statically analyzing the annotations within the program’s code. The confidence of the inference results vary based on the extent and quality of the annotations.</p><h1 id="Questions-Regarding-the-Paper"><a href="#Questions-Regarding-the-Paper" class="headerlink" title="Questions Regarding the Paper"></a>Questions Regarding the Paper</h1><ul><li>What is the relevance of such a technique to “safe” programming languages that do not allow using overflowable buffers?</li><li>The authors state that “control over annotation insertion is given to individual developers”. However, developers might be reluctant to insert Annotations, and inserting Annotations can negatively affect developer productivity. Furthermore, the quality of the inserted Annotations is not guaranteed. Last but not least, inferring Annotations for legacy codebases and&#x2F;or third-party code without such Annotations prefers Coverage over Accuracy, which may not lead to sound results. Considering all these real concerns, the practical usability of this tool is seriously compromised.</li><li>The authors did an evaluation on an unnamed Microsoft product. With little information regarding the product being disclosed, such an evaluation is far from convincing, and I suspect that there might be manipulation of some kind within the evaluation.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Precise Interprocedural Dataflow Analysis via Graph Reachability</title>
    <link href="/2022/11/07/Paper-Review-Precise-Interprocedural-Dataflow-Analysis-via-Graph-Reachability/"/>
    <url>/2022/11/07/Paper-Review-Precise-Interprocedural-Dataflow-Analysis-via-Graph-Reachability/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/199448.199462">here</a>.</p><p>To be honest, I found the paper to be almost unreadable due to it being full of unfamiliar concepts and abstract formalizations. I tried my best to do some studying into the topic so that I can understand the problem that they are trying to solve, and important aspects of their algorithm, better.</p><h1 id="Graph-Reachability"><a href="#Graph-Reachability" class="headerlink" title="Graph Reachability"></a>Graph Reachability</h1><p>Graph Reachability means whether it is possible to get from one vertex to another vertex within a graph.</p><p>In an Undirected Graph $G(V, E)$, Graph Reachability between <em>one pair of nodes</em> can be calculated using Breadth-First Search, while Graph Reachability between <em>all pair of nodes</em> can be reduced to calculating the Connected Components of the Undirected Graph, which is an efficient algorithm with $O(|V| + |E|)$ time complexity.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/3/38/Equivalentie.svg" alt="Connected Components within an Undirected Graph"></p><p>In a Directed Graph, Graph Reachability between <em>one pair of nodes</em> can also be calculated using Breadth-First Search. <strong>However, there is no efficient algorithm that can calculate Graph Reachability between <em>all pair of nodes</em> for all Directed Graphs.</strong></p><p>For <em>any</em> Directed Graph, calculating Graph Reachability between <em>all pair of nodes</em> can be reduced to calculating <strong>All Pairs Shortest Distance</strong> using the Floyd-Warshall Algorithm, which has an $O({|V|}^3)$ time complexity.</p><p>More efficient algorithms are only applicable to Planar Directed Graphs.</p><h1 id="Data-Flow-Analysis"><a href="#Data-Flow-Analysis" class="headerlink" title="Data Flow Analysis"></a>Data Flow Analysis</h1><p>Constant Propogation (determining whether variables at a given point in the program are guaranteed to have constant values) and Live Variable Analysis (determining at a given point in the program, which variables might be used before being overwritten) are two commonly encountered examples of Data Flow Analysis.</p><p>Given a program’s Control Flow Graph, Data Flow Analysis:</p><ul><li>Associates each Node of the Control Flow Graph with Information concerning the Variables within that Node (known as <em>Dataflow Fact</em>‘s, usually a Mapping between Variables and their Values or Properties)</li><li>Models the effect of executing a Node with a <em>Dataflow Function</em>.</li></ul><p>In most Data Flow Analysis problems, we take one of the following approaches to obtain the Dataflow Facts for each Node:</p><ul><li>Summarizing paths entering the Node from the Start, such as in Constant Propogation. Known as “Forward Problem”‘s.</li><li>Summarizing paths exiting the Node from the Exit, such as in Live Variable Analysis. Known as “Backward Problem”‘s.</li></ul><p>How we summarize paths is known as the <em>Confluence Operator</em>.</p><p>Data Flow Analysis problems can also be divided into “may” problems and “must” problems.</p><ul><li>In “may” problems, the Dataflow Facts for each Node include information about what may be true. An example is Live Variable Analysis, where we determine whether a variable <em>may</em> be used before being overwritten in a given point in the program.</li><li>In “must” problems, the Dataflow Facts for each Node include information about what must be true. An example is Constant Propogation, where we determine whether a variable <em>must</em> have a given value in a given point in the program.</li></ul><p>Many interesting Data Flow Analysis problems, such as Live Variable Analysis, can be modeled as GEN&#x2F;KILL problems, or bit-vector problems, in which:</p><ul><li>A set of variables, $KILL[n]$, is defined at Node $n$.</li><li>A set of variables, $GEN[n]$, is used at Node $n$.</li><li>We use Union or Intersection to summarize paths entering a Node to obtain the Dataflow Facts for the Node.</li></ul><h1 id="Interprocedural-Dataflow-Analysis"><a href="#Interprocedural-Dataflow-Analysis" class="headerlink" title="Interprocedural Dataflow Analysis"></a>Interprocedural Dataflow Analysis</h1><p>The goal of Interprocedural Dataflow Analysis is to capture an Abstraction of the Effect of calling a Procedure in Dataflow Analysis.</p><p>A naive approach to Interprocedural Dataflow Analysis is to reduce it to Intraprocedural Dataflow Analysis in some way.</p><ul><li>Procedure Inlining<ul><li>Exponentially increases the Control Flow Graph</li><li>Cannot handle recursion</li></ul></li><li>Context Sensitive Procedure Inlining<ul><li>Uses Context Information (often an Approximation of the Call Stack) to distinguish between different Calls of the same Procedure, and reduce the number of inlined Procedures.</li></ul></li></ul><hr><p>However, even after research, I have failed to understand the more complicated approaches (as well as the approaches proposed in this Paper).</p><p>I can only get the point that the author shows that many Interprocedural Dataflow Analysis problems, in which:</p><ul><li>A finite set of Dataflow Facts</li><li>Dataflow Functions distribute over the Confluence Operator (which I don’t fully understand)</li></ul><p>including GEN&#x2F;KILL problems, or bit-vector problems, can be reduced to a Graph Reachability Problem on a Directed Graph.</p><p>Furthermore, I believe the main contribution of this paper is theoretical, but what is its value in real-world Dataflow Analysis problems, especially considering that the Time Complexity of Graph Reachability Problems on Directed Graphs are high?</p><p>I honestly hope that I can get some insight into these approaches during our class on Monday. Thank you!</p><hr><h1 id="Feedback-from-the-Class-Discussion"><a href="#Feedback-from-the-Class-Discussion" class="headerlink" title="Feedback from the Class Discussion"></a>Feedback from the Class Discussion</h1><p>Some of the paper’s idea comes from Abstract Interpretation. It is nice theoretically, but it is far from implementation.</p><p>Graph Reachability in the context of Interprocedure Analysis is also known as Context-Free Language Reachability and Dyck Reachability.</p><p><strong>In the context of this paper, there are multiple Dataflow Functions, one for each Node in the Control Flow Graph. Given a Node in the Control Flow Graph, we use Pattern Matching to determine what its Dataflow Function is.</strong> Lambdas are used to represent these Dataflow Functions. Explanation for the notations: $\lambda <parameters>.&lt;return_value&gt;$ means <code>def f(&lt;parameters&gt;): return &lt;return_value&gt;</code>.</p><p>In the context of this paper, we require all Dataflow Functions to be distributive over the Meet Function (Confluence Function). This means that, given the Meet Function $\Pi$ and a Dataflow Function $f$, $f(X<del>\Pi</del>Y) &#x3D; f(X)<del>\Pi</del>f(Y)$ for any two Dataflow Facts $X, Y$. </p><p>Each Dataflow Function can be visualized using a Graph Representation. The Edges represent Dependencies between Facts of the Variables in the Old Dataflow Facts and Facts of the Variables in the New Dataflow Facts.</p><p><img src="https://picx1.zhimg.com/v2-f2b6351350543806f3a1b5f709071f78_1440w.jpg?source=172ae18b" alt="Graph Representation of Dataflow Functions, `x` is Shorthand for the Facts of `x`"></p><p>Worklist Algorithm: an Algorithm which takes Objects from a Worklist (a Queue of some sort) one at a time, processes it in some way, and perhaps further adds new Objects to the Worklist, until some Target is reached. Example: Breadth First Search.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Mining Input Grammars from Dynamic Taints</title>
    <link href="/2022/11/02/Paper-Review-Mining-Input-Grammars-from-Dynamic-Taints/"/>
    <url>/2022/11/02/Paper-Review-Mining-Input-Grammars-from-Dynamic-Taints/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/2970276.2970321">here</a>.</p><p>A program usually accepts a formal language as input. Inferring the grammar of this formal language is an important task with many use cases.</p><ul><li>Helps humans understand the structure of the formal language.<ul><li>Manually writing valid inputs</li><li>Reverse Engineering</li></ul></li><li>Generate inputs for testing and fuzzing</li></ul><p>The authors propose Autogram, a method that infers a Context Free Grammar given a set of sample inputs and a Java program that accepts that set of inputs and uses it in some way. Autogram adapts a Dynamic Taining-based approach: </p><ul><li>It monitors the data flow of each character within the input, with “the Input Fragment it came from” as the taint.</li><li>It traces method entries, method exits, field accesses, and array accesses within the execution of the program.</li><li>From such a trace, the Dynamic Call Tree is reconstructed, and the sets of Intervals (Input Fragments) processed by functions, stored in variables, and returned by functions is derived.</li><li>This is used to build an Interval Tree, and the Interval Tree is refined into a Pure Input Tree free of conflicting overlaps (resulting from parsers using lookaheads).</li><li>The pure input tree is assumed to be a Parse Tree, and Production Rules are derived from it. The leaf nodes are considered to be Terminals, and Regular Expressions matching them are learned.</li></ul><p>The authors then conduct an experimental study concerning the accuracy and completeness of the inferred Context Free Grammars using “parts of the Java Standard API that are used to process URLs and property files”, and “open source projects that implement support for CSV, INI, and JSON formats”.</p><hr><p>However, I had more questions than answers after reading this paper.</p><ul><li>One of the use cases that the authors mentioned is “the grammar vastly simplifies the creation of parsing programs that decompose existing inputs into their constituents”. Why don’t we directly extract the parsing logic out of the program Autogram runs on?</li><li>The type of Context Free Grammar inferred by Autogram seems to be an LL(1) Grammar. This type of Grammar is only able to represent simple Grammars, and does not support for Left Recursion, which is pervasive in real-world Grammars. Why don’t they infer an LALR(1) Grammar, which is both simple and expressive (it supports representing may real-world Programming Languages). Perhaps, a Hidden Markov Model could be trained to infer the Transitions between the States within the LALR(1) Parse Table should an LALR(1) Grammar be inferred?</li><li>In the current implementation of Autogram, tracing is efficient, as the authors have mentioned: “millions of calls result in traces of a few Megabytes”. However, the current implementation incurs a ~100x performance overhead, and there is a lot of room for performance optimization. Maybe ideas that we have discussed for TaintCheck and Qsym (direct Binary Analysis, preinstrumenting Bytecode, JIT compilation etc.) could be used here?</li><li>The specific process of refining an Interval Tree into a Pure Interval Tree free of conflicting overlaps is not described clearly in the paper. Why don’t the author present an example with figures showing the manipulation of nodes within the Interval Tree during this process? The author also mentions applying “a simple heuristic that assumes left to right processing of the input” to resolve possible ambiguities associated with parsers using lookaheads. However, what is the rationale behind this “simple heuristic”?</li><li>The specific process of deriving Production Rules from the Pure Interval Tree is also unclear. What do the authors mean by “We can thus check if nodes are compatible and can be used to derive productions for for the same nonterminal symbol”? What is the meaning of “compatible” in this context?</li><li>The programs used in the experimental study are all open-source programs of very high code quality (containing accurately named variables and functions). However, how well does Autogram work with closed-source programs, and&#x2F;or programs with low code quality, containing obscure variable and function names? This is frequently the situation we encounter when we try to reverse engineer the (often closed-source and&#x2F;or obscure) structure of a program’s input, one of the major use cases of Autogram.</li></ul><p>Also some inspiration and ideas I got from the paper:</p><ul><li>The author mentions that “dynamic tainting allows us to precisely identify which parts of a programs input are read, stored and processed at any point in time”. Could this technique be used in a Fuzzing context to identify which bits generated by a Coverage-Guided Fuzzer are used in which sections of a fuzzed program?</li><li>The logic of building an Interval Tree is very interesting, and it reads like the “Subset Tree” mentioned in the KLEE paper. I conject that both these Tree Structures could be generalized and used in a much wider range of contexts.</li></ul><hr><p>Feedback from the Class Discussion</p><ul><li>A Context Free Grammar may not capture the structure of binary files.</li><li>How does the approach compare to unsupervised parsing in NLP or fine-tuning language models, especially with a lot of input?</li><li>Is it possible to use feedback to improve the mined grammar?</li><li>From one tree, we infer one set of grammar rules; from 1000 trees, we infer 1000 sets of grammar rules. They are merged together to derive the final Context Free Grammar.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Various Solutions for Different Types of Reverse Proxying</title>
    <link href="/2022/10/30/Various-Solutions-for-Different-Types-of-Reverse-Proxying/"/>
    <url>/2022/10/30/Various-Solutions-for-Different-Types-of-Reverse-Proxying/</url>
    
    <content type="html"><![CDATA[<p>There are some situations in which we have to expose a locally running web service to the Internet. This is know as Reverse Proxying. Depending on the situation in hand, there are multiple ways to do this:</p><h1 id="Server-with-Public-IP-Available"><a href="#Server-with-Public-IP-Available" class="headerlink" title="Server with Public IP Available"></a>Server with Public IP Available</h1><p>In this case, the Server is also known as a Jump Server.</p><h2 id="Client-Accessible-from-Server"><a href="#Client-Accessible-from-Server" class="headerlink" title="Client Accessible from Server"></a>Client Accessible from Server</h2><p>Run a port-forwarding tool such as <code>socat</code> on the Server.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">socat TCP-LISTEN:&lt;Port the Server listens on&gt;,fork,reuseaddr TCP:&lt;IP address of the Client&gt;:&lt;Port of the Service on the Client&gt;<br></code></pre></td></tr></table></figure><h2 id="Client-Inaccessible-from-Server"><a href="#Client-Inaccessible-from-Server" class="headerlink" title="Client Inaccessible from Server"></a>Client Inaccessible from Server</h2><p>Use <a href="https://github.com/rofl0r/nat-tunnel">nat-tunnel</a> on both the Server and the Client.</p><p>Or, use <a href="https://jfrog.com/connect/post/reverse-ssh-tunneling-from-start-to-end/">Reverse SSH Tunneling</a> on the Client.</p><h3 id="Reverse-SSH-Tunneling"><a href="#Reverse-SSH-Tunneling" class="headerlink" title="Reverse SSH Tunneling"></a>Reverse SSH Tunneling</h3><h3 id="Before-Tunneling"><a href="#Before-Tunneling" class="headerlink" title="Before Tunneling"></a>Before Tunneling</h3><p>On the Server:</p><ul><li>Update the sshd config file (<code>/etc/ssh/sshd_config</code>). Set <code>GatewayPorts</code> to <code>yes</code>.</li><li>Restart the SSH Service.</li><li>Make sure the Port the Server listens on allows Inbound Traffic.</li></ul><h3 id="To-Tunnel"><a href="#To-Tunnel" class="headerlink" title="To Tunnel"></a>To Tunnel</h3><p>On the Client:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">ssh [-f] [-N] [-T] -R &lt;Port the Server listens on&gt;:localhost:&lt;Port of the Service on the Client&gt; [How you connect to the Server (e.g. `-i key-pair.pem &lt;username&gt;@&lt;domain&gt;`)]<br></code></pre></td></tr></table></figure><ul><li><code>-f</code> tells the SSH to background itself after it authenticates, saving you time by not having to run something on the remote server for the tunnel to remain alive.</li><li><code>-N</code> if all you need is to create a tunnel without running any remote commands then include this option to save resources.</li><li><code>-T</code> useful to disable pseudo-tty allocation, which is fitting if you are not trying to create an interactive shell.</li><li><code>-R</code> tells the tunnel to answer on the remote side.</li></ul><h1 id="Server-with-Public-IP-Unavailable"><a href="#Server-with-Public-IP-Unavailable" class="headerlink" title="Server with Public IP Unavailable"></a>Server with Public IP Unavailable</h1><p>Use a commercial service such as <code>ngrok</code> on the Client.</p><p>References:</p><ul><li><a href="https://en.wikipedia.org/wiki/Reverse_proxy">https://en.wikipedia.org/wiki/Reverse_proxy</a></li><li><a href="https://www.kvm.la/1328.html">https://www.kvm.la/1328.html</a></li><li><a href="https://blog.csdn.net/weixin_35867652/article/details/104362302">https://blog.csdn.net/weixin_35867652/article/details/104362302</a></li><li><a href="https://www.hostinger.com/tutorials/how-to-set-up-nginx-reverse-proxy/">https://www.hostinger.com/tutorials/how-to-set-up-nginx-reverse-proxy/</a></li><li><a href="https://stevessmarthomeguide.com/understanding-port-forwarding/">https://stevessmarthomeguide.com/understanding-port-forwarding/</a></li><li><a href="https://jfrog.com/connect/post/reverse-ssh-tunneling-from-start-to-end/">https://jfrog.com/connect/post/reverse-ssh-tunneling-from-start-to-end/</a></li><li><a href="https://linuxhint.com/ssh-port-forwarding-linux/">https://linuxhint.com/ssh-port-forwarding-linux/</a></li><li><a href="https://www.ssh.com/academy/ssh/tunneling-example">https://www.ssh.com/academy/ssh/tunneling-example</a></li><li><a href="https://superuser.com/questions/1408427/remote-port-forwarding-through-a-jump-server">https://superuser.com/questions/1408427/remote-port-forwarding-through-a-jump-server</a></li><li><a href="https://unix.stackexchange.com/questions/436290/single-step-ssh-port-forwarding-not-working-but-only-works-when-ssh-port-forward?rq=1&amp;newreg=def5dfc9fb43466d8685fd7639eb17cc">https://unix.stackexchange.com/questions/436290/single-step-ssh-port-forwarding-not-working-but-only-works-when-ssh-port-forward?rq=1&amp;newreg=def5dfc9fb43466d8685fd7639eb17cc</a></li><li><a href="https://www.opensourceforu.com/2021/09/how-to-do-reverse-tunnelling-with-the-amazon-ec2-instance/">https://www.opensourceforu.com/2021/09/how-to-do-reverse-tunnelling-with-the-amazon-ec2-instance/</a></li><li><a href="https://superuser.com/questions/1194105/ssh-troubleshooting-remote-port-forwarding-failed-for-listen-port-errors">https://superuser.com/questions/1194105/ssh-troubleshooting-remote-port-forwarding-failed-for-listen-port-errors</a></li><li><a href="https://docs.hevodata.com/getting-started/connection-options/connecting-through-reverse-ssh/">https://docs.hevodata.com/getting-started/connection-options/connecting-through-reverse-ssh/</a></li><li><a href="https://www.youtube.com/watch?v=TZ6W9Hi9YJw">https://www.youtube.com/watch?v=TZ6W9Hi9YJw</a></li><li><a href="https://blog.devolutions.net/2017/03/what-is-reverse-ssh-port-forwarding/">https://blog.devolutions.net/2017/03/what-is-reverse-ssh-port-forwarding/</a></li><li><a href="https://chenhuijing.com/blog/tunnelling-services-for-exposing-localhost-to-the-web/">https://chenhuijing.com/blog/tunnelling-services-for-exposing-localhost-to-the-web/</a></li><li><a href="https://johackim.com/how-to-expose-local-server-behind-firewall">https://johackim.com/how-to-expose-local-server-behind-firewall</a></li><li><a href="https://gabrieltanner.org/blog/port-forwarding-frp/">https://gabrieltanner.org/blog/port-forwarding-frp/</a></li><li><a href="https://www.techiediaries.com/public-localhost/">https://www.techiediaries.com/public-localhost/</a></li><li><a href="https://superuser.com/questions/121435/is-it-possible-to-host-a-web-server-from-behind-a-nat/1360660">https://superuser.com/questions/121435/is-it-possible-to-host-a-web-server-from-behind-a-nat/1360660</a></li><li><a href="https://medium.com/tech-learnings/how-to-expose-a-local-server-to-the-internet-without-any-additional-tools-ae49e6b8fe93">https://medium.com/tech-learnings/how-to-expose-a-local-server-to-the-internet-without-any-additional-tools-ae49e6b8fe93</a></li><li><a href="https://serverfault.com/questions/282959/how-do-i-reach-my-internal-server-on-the-external-ip">https://serverfault.com/questions/282959/how-do-i-reach-my-internal-server-on-the-external-ip</a></li><li><a href="https://superuser.com/questions/624925/how-to-access-internal-valid-ip-through-internet">https://superuser.com/questions/624925/how-to-access-internal-valid-ip-through-internet</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Code</category>
      
      <category>Computer Networking</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software</title>
    <link href="/2022/10/29/Paper-Review-Dynamic-Taint-Analysis-for-Automatic-Detection-Analysis-and-Signature-Generation-of-Exploits-on-Commodity-Software/"/>
    <url>/2022/10/29/Paper-Review-Dynamic-Taint-Analysis-for-Automatic-Detection-Analysis-and-Signature-Generation-of-Exploits-on-Commodity-Software/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://valgrind.org/docs/newsome2005.pdf">here</a>.</p><p>To combat worms spread by the Internet exploiting software vulnerabilities, the paper proposes TaintCheck, a dynamic taint analysis technique for automatic detection of exploits on software.</p><p>Summary of TaintCheck:</p><ul><li>TaintCheck directly operates on an arbitrary executable and does not require its source code. It uses Valgrind to translate basic blocks being executed into Valgrind’s RISC-like instruction set (UCode), inserts UCode instructions for instrumentation, and passes the modified UCode back to Valgrind for execution.</li><li>TaintCheck by default considers data originating from the network as “untrusted” and taints it. It keeps track of “the propagation of tainted data as the program executes”, which involves monitoring data movement instructions and arithmetic instructions, with the exception of constant functions such as <code>xor eax, eax</code>.</li><li>To accomplish this, TaintCheck associates “each byte of memory” with a Taint data structure. Different instances of such a data structure are “chained” to record “how tainted data is propagated”.</li><li>TaintCheck checks whether tainted data is used in ways it considers illegitimate, such as being used as a return address, a function pointer, a format string, and (optionally) as an argument of a system call. When such illegitimate uses are detected, it is possible to collect information about a software vulnerability, especially “the execution path from tainted data’s entry and its use in a probable exploit”.</li></ul><p>The paper also proposes a new semantic-based automatic signature generation approach on top of TaintCheck.</p><hr><p>There are several questions that came to my mind when I was reading this paper:</p><ul><li>The paper mentions that “the current implementation slows program execution between 1.5 and 40 times”, but also mentions that “the prototype has not been optimized”, and proposes optimization techniques. Why didn’t the authors implement these optimization techniques and conduct experiments on the optimized TaintCheck?</li><li>There is no doubt that using Valgrind to translate basic blocks being executed into UCode greatly simplifies dynamic taint analysis on an arbitrary executable, as TaintCheck deals with an RISC-like instruction set instead of raw machine code. However, this incurs significant overhead. Would directly performing dynamic taint analysis on machine code at runtime using a dynamic binary instrumentation tool such as Intel Pin boost performance (like the case of QSym)? What about generating UCode, inserting instructions for instrumentation, and passing the modified UCode back to Valgrind <em>before the executable is executed</em>?</li><li>What is the overhead of using the Taint data structure? Would the total size of all Taint data structures explode for long-running processes? And why do they use this Taint data structure, instead of using a conventional Data Flow Graph?</li><li>What is the list of constant functions that TaintCheck supports? Is it representative, and is it extensible?</li><li>Are the ways tainted data is used considered by TaintCheck to be illegitimate representative of real exploits? How well can TaintCheck discriminate from “illegitimate” uses with intentional uses, and&#x2F;or uses with checks? Specifically, the paper mentions that TaintCheck can “untaint the data immediately after it has been sanity checked”, but how is this situation detected?</li><li>In the evaluation section, why are the benchmarks used in assessing “compatibility and false positives” different from those used in assessing “attack detection” on actual exploits?</li><li>What does a “signature” look like, and how is it used to filter attacks?</li></ul><hr><p>Feedback from the Class Discussion</p><ul><li>Performance is not a priority. <strong>The paper is more of a proof-of-concept, and even “reads like a grant proposal”</strong>, especially Section 6.</li><li>The “taint data structure” includes more information than a dataflow graph (snapshots of the stacks etc.). It can also use a <strong>“memory arena”</strong> instead of vanilla heap allocation to improve performance.</li><li>Some of the detected attacks may not be present in “safe”, managed languages.</li><li>Due to the large overhead, the technique cannot be used to handle requests in production, but requests can be forked to it instead.</li><li>Dynamic taint analysis can have applications outside of the security domain.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Python in a Functional Style: Closures, Generators, and Coroutines</title>
    <link href="/2022/10/28/Python-in-a-Functional-Style-Closures-Generators-and-Coroutines/"/>
    <url>/2022/10/28/Python-in-a-Functional-Style-Closures-Generators-and-Coroutines/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="Closures"><a href="#Closures" class="headerlink" title="Closures"></a>Closures</h1><p>Python supports nested function definitions. However, should an inner function <strong>use an outer function’s local variable</strong> (instead of <strong>shadowing it</strong>), that local variable should be declared <code>nonlocal</code> within the inner function.</p><p>Not using <code>nonlocal</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">outer_function</span>():<br><span class="hljs-meta">... </span>  string = <span class="hljs-string">&#x27;Hello&#x27;</span><br><span class="hljs-meta">... </span>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner_function</span>():<br><span class="hljs-meta">... </span>    <span class="hljs-comment"># Shadows the local variable `string` of `outer_function`</span><br><span class="hljs-meta">... </span>    string = <span class="hljs-string">&#x27;World&#x27;</span><br><span class="hljs-meta">... </span>  inner_function()<br><span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> string<br><span class="hljs-meta">... </span><br><span class="hljs-meta">&gt;&gt;&gt; </span>outer_function()<br><span class="hljs-string">&#x27;Hello&#x27;</span><br></code></pre></td></tr></table></figure><hr><h1 id="Closures-1"><a href="#Closures-1" class="headerlink" title="Closures"></a>Closures</h1><p>Python supports nested function definitions. However, should an inner function <strong>use an outer function’s local variable</strong> (instead of <strong>shadowing it</strong>), that local variable should be declared <code>nonlocal</code> within the inner function.</p><p>Using <code>nonlocal</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">outer_function</span>():<br><span class="hljs-meta">... </span>    string = <span class="hljs-string">&#x27;Hello&#x27;</span><br><span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner_function</span>():<br><span class="hljs-meta">... </span>        <span class="hljs-comment"># Uses the local variable `string` of `outer_function`</span><br><span class="hljs-meta">... </span>        <span class="hljs-keyword">nonlocal</span> string<br><span class="hljs-meta">... </span>        string = <span class="hljs-string">&#x27;World&#x27;</span><br><span class="hljs-meta">... </span>    inner_function()<br><span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> string<br><span class="hljs-meta">... </span><br><span class="hljs-meta">&gt;&gt;&gt; </span>outer_function()<br><span class="hljs-string">&#x27;World&#x27;</span><br></code></pre></td></tr></table></figure><hr><h1 id="Closures-2"><a href="#Closures-2" class="headerlink" title="Closures"></a>Closures</h1><p>All Python functions are <strong>closures</strong>.</p><ul><li>Function code</li><li>Execution environment of function code</li></ul><p>A nested function can be returned. This is a common design pattern for creating <strong>tailored functions</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_greeting_function</span>(<span class="hljs-params">name</span>):<br><span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">greeting_function</span>():<br><span class="hljs-meta">... </span>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Hello, <span class="hljs-subst">&#123;name&#125;</span>&#x27;</span>)<br><span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> greeting_function<br><span class="hljs-meta">... </span><br></code></pre></td></tr></table></figure><hr><h1 id="Closures-3"><a href="#Closures-3" class="headerlink" title="Closures"></a>Closures</h1><p>All Python functions are <strong>closures</strong>.</p><ul><li>Function code</li><li>Execution environment of function code</li></ul><p>A nested function can be returned. This is a common design pattern for creating <strong>tailored functions</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_a = get_greeting_function(<span class="hljs-string">&#x27;A&#x27;</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_a()<br>Hello, A<br>&gt;&gt;&gt;<br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_b = get_greeting_function(<span class="hljs-string">&#x27;B&#x27;</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_b()<br>Hello, B<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-4"><a href="#Closures-4" class="headerlink" title="Closures"></a>Closures</h1><p>Look into a closure’s <code>cell_contents</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_a.__closure__<br>(&lt;cell at <span class="hljs-number">0x7f3c81849ca8</span>: <span class="hljs-built_in">str</span> <span class="hljs-built_in">object</span> at <span class="hljs-number">0x7f3c8185ac70</span>&gt;,)<br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_a.__closure__[<span class="hljs-number">0</span>]<br>&lt;cell at <span class="hljs-number">0x7f3c81849ca8</span>: <span class="hljs-built_in">str</span> <span class="hljs-built_in">object</span> at <span class="hljs-number">0x7f3c8185ac70</span>&gt;<br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_a.__closure__[<span class="hljs-number">0</span>].cell_contents<br><span class="hljs-string">&#x27;A&#x27;</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_b.__closure__<br>(&lt;cell at <span class="hljs-number">0x7f3c81849c18</span>: <span class="hljs-built_in">str</span> <span class="hljs-built_in">object</span> at <span class="hljs-number">0x7f3c82f18e30</span>&gt;,)<br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_b.__closure__[<span class="hljs-number">0</span>]<br>&lt;cell at <span class="hljs-number">0x7f3c81849c18</span>: <span class="hljs-built_in">str</span> <span class="hljs-built_in">object</span> at <span class="hljs-number">0x7f3c82f18e30</span>&gt;<br><span class="hljs-meta">&gt;&gt;&gt; </span>function_greeting_b.__closure__[<span class="hljs-number">0</span>].cell_contents<br><span class="hljs-string">&#x27;B&#x27;</span><br></code></pre></td></tr></table></figure><hr><h1 id="Closures-5"><a href="#Closures-5" class="headerlink" title="Closures"></a>Closures</h1><p><strong>Creating and returning a nested function based on a function argument passed to the outer function</strong> is another widely used design pattern in Python, called <strong>decorating a function</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cached</span>(<span class="hljs-params">function</span>):<br>    cache = &#123;&#125;<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">cached_function</span>(<span class="hljs-params">*args</span>):<br>        <span class="hljs-keyword">nonlocal</span> function, cache<br>        <span class="hljs-keyword">if</span> args <span class="hljs-keyword">in</span> cache:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Cache hit with args: <span class="hljs-subst">&#123;args&#125;</span>&#x27;</span>)<br>            <span class="hljs-keyword">return</span> cache[args]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Cache miss with args: <span class="hljs-subst">&#123;args&#125;</span>&#x27;</span>)<br>            result = function(*args)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Writing f(<span class="hljs-subst">&#123;args&#125;</span>) =&gt; <span class="hljs-subst">&#123;result&#125;</span> to cache&#x27;</span>)<br>            cache[args] = result<br>            <span class="hljs-keyword">return</span> result<br>    <br>    <span class="hljs-keyword">return</span> cached_function<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-6"><a href="#Closures-6" class="headerlink" title="Closures"></a>Closures</h1><p><strong>Creating and returning a nested function based on a function argument passed to the outer function</strong> is another widely used design pattern in Python, called <strong>decorating a function</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">square</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x * x<br><br>cached_square = cached(square)<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-7"><a href="#Closures-7" class="headerlink" title="Closures"></a>Closures</h1><p><strong>Creating and returning a nested function based on a function argument passed to the outer function</strong> is another widely used design pattern in Python, called <strong>decorating a function</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">15</span>]: cached_square(<span class="hljs-number">1</span>)                                                     <br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">1</span>,)<br>Writing f((<span class="hljs-number">1</span>,)) =&gt; <span class="hljs-number">1</span> to cache<br>Out[<span class="hljs-number">15</span>]: <span class="hljs-number">1</span><br><br>In [<span class="hljs-number">16</span>]: cached_square(<span class="hljs-number">2</span>)                                                     <br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">2</span>,)<br>Writing f((<span class="hljs-number">2</span>,)) =&gt; <span class="hljs-number">4</span> to cache<br>Out[<span class="hljs-number">16</span>]: <span class="hljs-number">4</span><br><br>In [<span class="hljs-number">17</span>]: cached_square(<span class="hljs-number">1</span>)                                                     <br>Cache hit <span class="hljs-keyword">with</span> args: (<span class="hljs-number">1</span>,)<br>Out[<span class="hljs-number">17</span>]: <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><hr><h1 id="Closures-8"><a href="#Closures-8" class="headerlink" title="Closures"></a>Closures</h1><p>Python even has special syntatical support for this.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@cached</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fib</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">elif</span> n &lt; <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> fib(n - <span class="hljs-number">1</span>) + fib(n - <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-9"><a href="#Closures-9" class="headerlink" title="Closures"></a>Closures</h1><p>Python even has special syntatical support for this.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">4</span>]: fib(<span class="hljs-number">5</span>)                                                                                       <br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">5</span>,)<br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">4</span>,)<br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">3</span>,)<br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">2</span>,)<br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">1</span>,)<br>Writing f((<span class="hljs-number">1</span>,)) =&gt; <span class="hljs-number">1</span> to cache<br>Cache miss <span class="hljs-keyword">with</span> args: (<span class="hljs-number">0</span>,)<br>Writing f((<span class="hljs-number">0</span>,)) =&gt; <span class="hljs-number">0</span> to cache<br>Writing f((<span class="hljs-number">2</span>,)) =&gt; <span class="hljs-number">1</span> to cache<br>Cache hit <span class="hljs-keyword">with</span> args: (<span class="hljs-number">1</span>,)<br>Writing f((<span class="hljs-number">3</span>,)) =&gt; <span class="hljs-number">2</span> to cache<br>Cache hit <span class="hljs-keyword">with</span> args: (<span class="hljs-number">2</span>,)<br>Writing f((<span class="hljs-number">4</span>,)) =&gt; <span class="hljs-number">3</span> to cache<br>Cache hit <span class="hljs-keyword">with</span> args: (<span class="hljs-number">3</span>,)<br>Writing f((<span class="hljs-number">5</span>,)) =&gt; <span class="hljs-number">5</span> to cache<br>Out[<span class="hljs-number">4</span>]: <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>$O(n)$ time complexity.</p><hr><h1 id="Closures-10"><a href="#Closures-10" class="headerlink" title="Closures"></a>Closures</h1><p>The <code>functools</code> library provides several commonly-used decorators:</p><ul><li><code>functools.lru_cache</code></li><li><code>functools.partial</code></li><li><code>functools.singledispatch</code></li></ul><hr><h1 id="Closures-11"><a href="#Closures-11" class="headerlink" title="Closures"></a>Closures</h1><p><code>functools.lru_cache</code></p><p>Given n pairs of parentheses, write a function to generate all combinations of well-formed parentheses. </p><p>Example 1:</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">Input:</span> n = <span class="hljs-number">3</span><br><span class="hljs-symbol">Output:</span> [<span class="hljs-string">&quot;((()))&quot;</span>,<span class="hljs-string">&quot;(()())&quot;</span>,<span class="hljs-string">&quot;(())()&quot;</span>,<span class="hljs-string">&quot;()(())&quot;</span>,<span class="hljs-string">&quot;()()()&quot;</span>]<br></code></pre></td></tr></table></figure><p>Example 2:</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">Input:</span> n = <span class="hljs-number">1</span><br><span class="hljs-symbol">Output:</span> [<span class="hljs-string">&quot;()&quot;</span>]<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-12"><a href="#Closures-12" class="headerlink" title="Closures"></a>Closures</h1><p><img src="/images/grammar.png" alt="Grammar"></p><hr><h1 id="Closures-13"><a href="#Closures-13" class="headerlink" title="Closures"></a>Closures</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@functools.lru_cache(<span class="hljs-params">maxsize=<span class="hljs-literal">None</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">s_generator</span>(<span class="hljs-params">number_of_parenthesis</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;s_generator(<span class="hljs-subst">&#123;number_of_parenthesis&#125;</span>)&#x27;</span>)<br>    <br>    return_value = []<br>    <br>    <span class="hljs-comment"># s -&gt; ss .</span><br>    <span class="hljs-keyword">if</span> number_of_parenthesis &gt;= <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">for</span> ss_string <span class="hljs-keyword">in</span> ss_generator(number_of_parenthesis):<br>            return_value.append(ss_string)<br>    <br>    <span class="hljs-comment"># s -&gt; s ss .</span><br>    <span class="hljs-keyword">if</span> number_of_parenthesis &gt;= <span class="hljs-number">2</span>: <br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, number_of_parenthesis):<br>            <span class="hljs-keyword">for</span> s_string, ss_string <span class="hljs-keyword">in</span> itertools.product(<br>                s_generator(i),<br>                ss_generator(number_of_parenthesis - i)<br>            ):<br>                return_value.append(s_string + ss_string)<br>    <br>    <span class="hljs-keyword">return</span> return_value<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-14"><a href="#Closures-14" class="headerlink" title="Closures"></a>Closures</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@functools.lru_cache(<span class="hljs-params">maxsize=<span class="hljs-literal">None</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ss_generator</span>(<span class="hljs-params">number_of_parenthesis</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;ss_generator(<span class="hljs-subst">&#123;number_of_parenthesis&#125;</span>)&#x27;</span>)<br>    <br>    return_value = []<br>    <br>    <span class="hljs-comment"># ss -&gt; ( ) .</span><br>    <span class="hljs-keyword">if</span> number_of_parenthesis == <span class="hljs-number">1</span>:<br>        return_value.append(<span class="hljs-string">&#x27;()&#x27;</span>)<br>    <span class="hljs-comment"># ss -&gt; ( s ) .</span><br>    <span class="hljs-keyword">if</span> number_of_parenthesis &gt; <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">for</span> s_string <span class="hljs-keyword">in</span> s_generator(number_of_parenthesis - <span class="hljs-number">1</span>):<br>            return_value.append(<span class="hljs-string">&#x27;(&#x27;</span> + s_string + <span class="hljs-string">&#x27;)&#x27;</span>)<br><br>    <span class="hljs-keyword">return</span> return_value<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-15"><a href="#Closures-15" class="headerlink" title="Closures"></a>Closures</h1><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">Input:</span> n = <span class="hljs-number">3</span><br><span class="hljs-symbol">Output:</span> [<span class="hljs-string">&quot;((()))&quot;</span>,<span class="hljs-string">&quot;(()())&quot;</span>,<span class="hljs-string">&quot;(())()&quot;</span>,<span class="hljs-string">&quot;()(())&quot;</span>,<span class="hljs-string">&quot;()()()&quot;</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">4</span>]: s_generator(<span class="hljs-number">3</span>)                                                                               <br>s_generator(<span class="hljs-number">3</span>)<br>ss_generator(<span class="hljs-number">3</span>)<br>s_generator(<span class="hljs-number">2</span>)<br>ss_generator(<span class="hljs-number">2</span>)<br>s_generator(<span class="hljs-number">1</span>)<br>ss_generator(<span class="hljs-number">1</span>)<br>Out[<span class="hljs-number">4</span>]: [<span class="hljs-string">&#x27;((()))&#x27;</span>, <span class="hljs-string">&#x27;(()())&#x27;</span>, <span class="hljs-string">&#x27;()(())&#x27;</span>, <span class="hljs-string">&#x27;(())()&#x27;</span>, <span class="hljs-string">&#x27;()()()&#x27;</span>]<br><br>In [<span class="hljs-number">5</span>]: s_generator.cache_info()                                                                     <br>Out[<span class="hljs-number">5</span>]: CacheInfo(hits=<span class="hljs-number">3</span>, misses=<span class="hljs-number">3</span>, maxsize=<span class="hljs-literal">None</span>, currsize=<span class="hljs-number">3</span>)<br><br>In [<span class="hljs-number">6</span>]: ss_generator.cache_info()                                                                    <br>Out[<span class="hljs-number">6</span>]: CacheInfo(hits=<span class="hljs-number">3</span>, misses=<span class="hljs-number">3</span>, maxsize=<span class="hljs-literal">None</span>, currsize=<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-16"><a href="#Closures-16" class="headerlink" title="Closures"></a>Closures</h1><p>Closures provide an efficient mechanism for <strong>maintaining state between several calls</strong>.</p><p>Traditional (OOP) approach:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Countdown</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n</span>):<br>        self.n = n<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">next_value</span>(<span class="hljs-params">self</span>):<br>        old_value = self.n<br>        self.n -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> old_value<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-17"><a href="#Closures-17" class="headerlink" title="Closures"></a>Closures</h1><p>Closures provide an efficient mechanism for <strong>maintaining state between several calls</strong>.</p><p>Closure-based approach:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">countdown</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_next_value</span>():<br>        <span class="hljs-keyword">nonlocal</span> n<br>        old_value = n<br>        n -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> old_value<br>    <br>    <span class="hljs-keyword">return</span> get_next_value<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-18"><a href="#Closures-18" class="headerlink" title="Closures"></a>Closures</h1><p>This is not only clean but also <strong>fast</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_object_oriented_approach</span>():<br>    c = Countdown(<span class="hljs-number">1_000_000</span>)<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        value = c.next_value()<br>        <span class="hljs-keyword">if</span> value == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">break</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_functional_approach</span>():<br>    get_next_value = countdown(<span class="hljs-number">1_000_000</span>)<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        value = get_next_value()<br>        <span class="hljs-keyword">if</span> value == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><hr><h1 id="Closures-19"><a href="#Closures-19" class="headerlink" title="Closures"></a>Closures</h1><p>This is not only clean but also <strong>fast</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">5</span>]: %timeit test_object_oriented_approach()<br><span class="hljs-number">182</span> ms ± <span class="hljs-number">2.61</span> ms per loop (mean ± std. dev. of <span class="hljs-number">7</span> runs, <span class="hljs-number">1</span> loop each)<br><br>In [<span class="hljs-number">6</span>]: %timeit test_functional_approach()<br><span class="hljs-number">96.8</span> ms ± <span class="hljs-number">1.18</span> ms per loop (mean ± std. dev. of <span class="hljs-number">7</span> runs, <span class="hljs-number">10</span> loops each)<br></code></pre></td></tr></table></figure><hr><h1 id="Closures-20"><a href="#Closures-20" class="headerlink" title="Closures"></a>Closures</h1><p>Why?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">9</span>]: c = Countdown(<span class="hljs-number">1_000_000</span>)                                               <br><br>In [<span class="hljs-number">10</span>]: dis(c.next_value)                                                     <br>  <span class="hljs-number">6</span>           <span class="hljs-number">0</span> LOAD_FAST                <span class="hljs-number">0</span> (self)<br>              <span class="hljs-number">2</span> LOAD_ATTR                <span class="hljs-number">0</span> (n)<br>              <span class="hljs-number">4</span> STORE_FAST               <span class="hljs-number">1</span> (old_value)<br><br>  <span class="hljs-number">7</span>           <span class="hljs-number">6</span> LOAD_FAST                <span class="hljs-number">0</span> (self)<br>              <span class="hljs-number">8</span> DUP_TOP<br>             <span class="hljs-number">10</span> LOAD_ATTR                <span class="hljs-number">0</span> (n)<br>             <span class="hljs-number">12</span> LOAD_CONST               <span class="hljs-number">1</span> (<span class="hljs-number">1</span>)<br>             <span class="hljs-number">14</span> INPLACE_SUBTRACT<br>             <span class="hljs-number">16</span> ROT_TWO<br>             <span class="hljs-number">18</span> STORE_ATTR               <span class="hljs-number">0</span> (n)<br><br>  <span class="hljs-number">8</span>          <span class="hljs-number">20</span> LOAD_FAST                <span class="hljs-number">1</span> (old_value)<br>             <span class="hljs-number">22</span> RETURN_VALUE<br></code></pre></td></tr></table></figure><p>12 instructions, 2 <code>LOAD_ATTR</code> instructions, 1 <code>STORE_ATTR</code> instruction.</p><hr><h1 id="Closures-21"><a href="#Closures-21" class="headerlink" title="Closures"></a>Closures</h1><p>Why?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">11</span>]: get_next_value = countdown(<span class="hljs-number">1_000_000</span>)                                 <br><br>In [<span class="hljs-number">12</span>]: dis(get_next_value)                                                   <br>  <span class="hljs-number">4</span>           <span class="hljs-number">0</span> LOAD_DEREF               <span class="hljs-number">0</span> (n)<br>              <span class="hljs-number">2</span> STORE_FAST               <span class="hljs-number">0</span> (old_value)<br><br>  <span class="hljs-number">5</span>           <span class="hljs-number">4</span> LOAD_DEREF               <span class="hljs-number">0</span> (n)<br>              <span class="hljs-number">6</span> LOAD_CONST               <span class="hljs-number">1</span> (<span class="hljs-number">1</span>)<br>              <span class="hljs-number">8</span> INPLACE_SUBTRACT<br>             <span class="hljs-number">10</span> STORE_DEREF              <span class="hljs-number">0</span> (n)<br><br>  <span class="hljs-number">6</span>          <span class="hljs-number">12</span> LOAD_FAST                <span class="hljs-number">0</span> (old_value)<br>             <span class="hljs-number">14</span> RETURN_VALUE<br></code></pre></td></tr></table></figure><p>8 instructions, NO <code>LOAD_ATTR</code>, <code>STORE_ATTR</code> instructions.</p><hr><h1 id="Generators"><a href="#Generators" class="headerlink" title="Generators"></a>Generators</h1><p>When we define a function containing the <code>yield</code> keyword, we define a generator. Defining a generator allows the user to define a <strong>custom iterator</strong> in the style of defining a function.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">countdown</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-keyword">while</span> n &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">yield</span> n<br>        n -= <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><hr><h1 id="Generators-1"><a href="#Generators-1" class="headerlink" title="Generators"></a>Generators</h1><p>We create a <strong>generator object</strong> when we call a generator definition. The generator object can be used like any iterator:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">2</span>]: c = countdown(<span class="hljs-number">5</span>)<br><br>In [<span class="hljs-number">3</span>]: <span class="hljs-built_in">next</span>(c)<br>Out[<span class="hljs-number">3</span>]: <span class="hljs-number">5</span><br><br>In [<span class="hljs-number">4</span>]: <span class="hljs-built_in">next</span>(c)<br>Out[<span class="hljs-number">4</span>]: <span class="hljs-number">4</span><br><br>In [<span class="hljs-number">5</span>]: <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> c:<br>   ...:     <span class="hljs-built_in">print</span>(value)<br>   ...:<br><span class="hljs-number">3</span><br><span class="hljs-number">2</span><br><span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><hr><h1 id="Generators-2"><a href="#Generators-2" class="headerlink" title="Generators"></a>Generators</h1><p>When we call <code>next()</code> on a generator object, it will execute code, until it encounters a <code>yield</code> statement. The <code>yield</code> statement tells the generator object to <strong>return a value, and continue execution from here when <code>next()</code> is called again</strong>. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">2</span>]: c = countdown(<span class="hljs-number">5</span>)<br><br>In [<span class="hljs-number">3</span>]: <span class="hljs-built_in">next</span>(c)<br>Out[<span class="hljs-number">3</span>]: <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>This executes:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">while</span> n &gt; <span class="hljs-number">0</span>:<br>    <span class="hljs-keyword">yield</span> n<br></code></pre></td></tr></table></figure><p>and returns <code>n</code>.</p><hr><h1 id="Generators-3"><a href="#Generators-3" class="headerlink" title="Generators"></a>Generators</h1><p>When we call <code>next()</code> on a generator object, it will execute code, until it encounters a <code>yield</code> statement. The <code>yield</code> statement tells the generator object to <strong>return a value, and continue execution from here when <code>next()</code> is called again</strong>. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">4</span>]: <span class="hljs-built_in">next</span>(c)<br>Out[<span class="hljs-number">4</span>]: <span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><p>This executes:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">   n -= <span class="hljs-number">1</span><br><span class="hljs-keyword">while</span> n &gt; <span class="hljs-number">0</span>:<br>   <span class="hljs-keyword">yield</span> n<br></code></pre></td></tr></table></figure><p>and returns <code>n</code>.</p><hr><h1 id="Generators-4"><a href="#Generators-4" class="headerlink" title="Generators"></a>Generators</h1><p>This is called <strong>lazy evaluation</strong>. This can dramatically boost performance and reduce memory usage in some applications. For example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_comments_from_file</span>(<span class="hljs-params">file</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> fp:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> fp:<br>            <span class="hljs-comment"># strip whitespace</span><br>            stripped_line = line.strip()<br>            <span class="hljs-comment"># check if the line is empty after stripping whitespace</span><br>            <span class="hljs-keyword">if</span> stripped_line:<br>                <span class="hljs-comment"># check if the line is a comment</span><br>                <span class="hljs-keyword">if</span> stripped_line[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;#&#x27;</span>:<br>                    <span class="hljs-comment"># if it is, yield it</span><br>                    <span class="hljs-keyword">yield</span> stripped_line<br></code></pre></td></tr></table></figure><hr><h1 id="Generators-5"><a href="#Generators-5" class="headerlink" title="Generators"></a>Generators</h1><p>This will <strong>NOT</strong> read the whole file into memory. Only when the user calls <code>next()</code> on the generator object, will the generator read the file <strong>LINE BY LINE</strong> (with only <strong>ONE LINE</strong> of the file in memory at once), and return the next comment line.</p><p>This is an efficient way of extracting comments from GB-sized files (such as logs).</p><hr><h1 id="itertools"><a href="#itertools" class="headerlink" title="itertools"></a>itertools</h1><p>Python provides many functions for creating an iterator from another iterator:</p><ul><li>Filtering<ul><li><code>filter(predicate, iterable)</code></li><li><code>itertools.filterfalse(predicate, iterable)</code></li><li><code>itertools.dropwhile(predicate, iterable)</code></li><li><code>itertools.takewhile(predicate, iterable)</code></li><li><code>itertools.islice(predicate, [start,] stop [,step])</code></li></ul></li></ul><hr><h1 id="itertools-1"><a href="#itertools-1" class="headerlink" title="itertools"></a>itertools</h1><p>Python provides many functions for creating an iterator from another iterator:</p><ul><li>Permutations and Combinations<ul><li><code>itertools.permutations(iterable [, r])</code></li><li><code>itertools.combinations(iterable, r)</code></li></ul></li></ul><hr><h1 id="itertools-2"><a href="#itertools-2" class="headerlink" title="itertools"></a>itertools</h1><p>Python provides many functions for creating an iterator from another iterator:</p><ul><li>Combining<ul><li><code>zip(iter1, iter2, ... iterN)</code></li><li><code>itertools.product(iter1, iter2, ... iterN, [repeat=1])</code></li></ul></li></ul><hr><h1 id="itertools-3"><a href="#itertools-3" class="headerlink" title="itertools"></a>itertools</h1><p>Python provides many functions for creating an iterator from another iterator:</p><ul><li>Enumerating<ul><li><code>enumerate(iterable, start=0)</code></li></ul></li></ul><hr><h1 id="itertools-4"><a href="#itertools-4" class="headerlink" title="itertools"></a>itertools</h1><p>Python provides many functions for creating an iterator from another iterator:</p><ul><li>Map and Reduce<ul><li><code>map(func, *iterables)</code></li><li><code>functools.reduce(function, sequence[, initial])</code></li></ul></li></ul><hr><h1 id="itertools-5"><a href="#itertools-5" class="headerlink" title="itertools"></a>itertools</h1><p>Widely used in algorithms: <code>itertools.permutations(iterable [,r])</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]: <span class="hljs-keyword">import</span> itertools<br><br><br>In [<span class="hljs-number">2</span>]: numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)<br><br>In [<span class="hljs-number">3</span>]: permutations_of_two_numbers_iterator = itertools.permutations(numbers, r=<span class="hljs-number">2</span>)<br><br>In [<span class="hljs-number">4</span>]: <span class="hljs-built_in">next</span>(permutations_of_two_numbers_iterator)<br>Out[<span class="hljs-number">4</span>]: (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><br>In [<span class="hljs-number">5</span>]: <span class="hljs-built_in">next</span>(permutations_of_two_numbers_iterator)<br>Out[<span class="hljs-number">5</span>]: (<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br><br>In [<span class="hljs-number">6</span>]: <span class="hljs-built_in">next</span>(permutations_of_two_numbers_iterator)<br>Out[<span class="hljs-number">6</span>]: (<span class="hljs-number">0</span>, <span class="hljs-number">3</span>)<br><br>In [<span class="hljs-number">7</span>]: <span class="hljs-built_in">next</span>(permutations_of_two_numbers_iterator)<br>Out[<span class="hljs-number">7</span>]: (<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><hr><h1 id="itertools-6"><a href="#itertools-6" class="headerlink" title="itertools"></a>itertools</h1><p>Widely used in algorithms: <code>itertools.combinations(iterable ,r)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]: <span class="hljs-keyword">import</span> itertools<br><br>In [<span class="hljs-number">2</span>]: numbers = <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)<br><br>In [<span class="hljs-number">3</span>]: <span class="hljs-keyword">for</span> first, second <span class="hljs-keyword">in</span> itertools.combinations(numbers, <span class="hljs-number">2</span>):<br>   ...:     <span class="hljs-built_in">print</span>(first, second)<br>   ...:<br><span class="hljs-number">0</span> <span class="hljs-number">1</span><br><span class="hljs-number">0</span> <span class="hljs-number">2</span><br><span class="hljs-number">0</span> <span class="hljs-number">3</span><br><span class="hljs-number">1</span> <span class="hljs-number">2</span><br><span class="hljs-number">1</span> <span class="hljs-number">3</span><br><span class="hljs-number">2</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><hr><h1 id="Coroutines"><a href="#Coroutines" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Starting from Python 2.5, the <code>yield</code> statement can be used as an <strong>right value</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">captured_input = <span class="hljs-keyword">yield</span> value_to_yield<br></code></pre></td></tr></table></figure><p>Generators defined like this can <strong>accept sent input</strong> while providing output. These generators are called <strong>coroutines</strong>.</p><hr><h1 id="Coroutines-1"><a href="#Coroutines-1" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>The concept of coroutines was proposed in the 60s, but only gained traction in recent years.</p><p>Coroutines can be seen as a combination of <strong>subroutines</strong> and <strong>threads</strong>.</p><ul><li>Can <strong>pause and restart</strong> during execution.</li><li>Controlled by <strong>itself</strong> instead of the operating system.</li><li>Different coroutines run within a thread are <strong>concurrent</strong> instead of <strong>parallel</strong>.</li></ul><hr><h1 id="Coroutines-2"><a href="#Coroutines-2" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Simple example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update_mean</span>():<br>    current_input = <span class="hljs-keyword">yield</span><br>    <br>    <span class="hljs-built_in">sum</span> = current_input<br>    count = <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        current_input = <span class="hljs-keyword">yield</span> <span class="hljs-built_in">sum</span> / count<br>        <br>        <span class="hljs-built_in">sum</span> += current_input<br>        count += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><hr><h1 id="Coroutines-3"><a href="#Coroutines-3" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Simple example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">3</span>]: updater = update_mean()<br><br>In [<span class="hljs-number">4</span>]: <span class="hljs-built_in">next</span>(updater)<br></code></pre></td></tr></table></figure><p>This executes:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">current_input = <span class="hljs-keyword">yield</span><br></code></pre></td></tr></table></figure><p>And the coroutine waits for an input to be sent.</p><hr><h1 id="Coroutines-4"><a href="#Coroutines-4" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Send an input:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">5</span>]: updater.send(<span class="hljs-number">2</span>)<br>Out[<span class="hljs-number">5</span>]: <span class="hljs-number">2.0</span><br></code></pre></td></tr></table></figure><p>The coroutine receives the input, and executes:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">sum</span> = current_input<br>count = <span class="hljs-number">1</span><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    current_input = <span class="hljs-keyword">yield</span> <span class="hljs-built_in">sum</span> / count<br></code></pre></td></tr></table></figure><p>And the coroutine waits for an input to be sent.</p><hr><h1 id="Coroutines-5"><a href="#Coroutines-5" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Send an input:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">6</span>]: updater.send(<span class="hljs-number">4</span>)<br>Out[<span class="hljs-number">6</span>]: <span class="hljs-number">3.0</span><br></code></pre></td></tr></table></figure><p>The coroutine receives the input, and executes:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">    <span class="hljs-built_in">sum</span> += current_input<br>    count += <span class="hljs-number">1</span><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    current_input = <span class="hljs-keyword">yield</span> <span class="hljs-built_in">sum</span> / count<br></code></pre></td></tr></table></figure><p>And the coroutine waits again for an input to be sent.</p><hr><h1 id="Coroutines-6"><a href="#Coroutines-6" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>More complicated example: set-associative cache simulation</p><ul><li>The whole set-associative cache is a coroutine receiving <code>(address, is_write)</code> tuples as input, and calculating <code>(cache_hit, writeback_address)</code> tuples as output.<ul><li>It models <strong>each set</strong> as a coroutine receiving <code>(tag, is_write)</code> tuples as input, and calculating <code>(cache_hit, writeback_address)</code> tuples as output.<ul><li>Different coroutine definitions for round-robin, LRU, etc.</li></ul></li></ul></li></ul><hr><h1 id="Coroutines-7"><a href="#Coroutines-7" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>The whole set-associative cache</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cache_coroutine</span>(<span class="hljs-params">cache_set_coroutine_function, block_size_in_bytes, number_of_ways_of_associativity, number_of_cache_sets</span>):<br>    <span class="hljs-comment"># create cache_set_coroutine_list and activate each cache_set_coroutine</span><br>    cache_set_coroutine_list = [ cache_set_coroutine_function(number_of_ways_of_associativity) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number_of_cache_sets) ]<br>    <span class="hljs-keyword">for</span> cache_set_coroutine <span class="hljs-keyword">in</span> cache_set_coroutine_list:<br>        <span class="hljs-built_in">next</span>(cache_set_coroutine)<br>    <br>    <span class="hljs-comment"># get function_to_split_address and function_to_merge_address</span><br>    function_to_split_address, function_to_merge_address = get_functions_to_split_and_merge_address(<br>        block_size_in_bytes,<br>        number_of_cache_sets<br>    )<br>    <br>    <span class="hljs-comment"># receive address, is_write</span><br>    <span class="hljs-comment"># yields nothing</span><br>    address, is_write = <span class="hljs-keyword">yield</span><br>    <br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-comment"># splits address</span><br>        tag, cache_set_index, offset = function_to_split_address(address)<br>        <br>        <span class="hljs-comment"># send (tag, is_write) to the appropriate cache_set_coroutine</span><br>        cache_hit, victim_tag, writeback_required = cache_set_coroutine_list[cache_set_index].send((tag, is_write))<br>        <br>        <span class="hljs-comment"># create writeback_address if (victim_tag is not None) and writeback_required</span><br>        <span class="hljs-keyword">if</span> (victim_tag <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">and</span> writeback_required:<br>            writeback_address = function_to_merge_address(victim_tag, cache_set_index, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">else</span>:<br>            writeback_address = <span class="hljs-literal">None</span><br>        <br>        <span class="hljs-comment"># receive address, is_write</span><br>        <span class="hljs-comment"># yield cache_hit, writeback_address</span><br>        address, is_write = <span class="hljs-keyword">yield</span> cache_hit, writeback_address<br></code></pre></td></tr></table></figure><hr><h1 id="Coroutines-8"><a href="#Coroutines-8" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Set with LRU replacement policy</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lru_cache_set_coroutine</span>(<span class="hljs-params">associativity</span>):<br>    tag_list = [ <span class="hljs-literal">None</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(associativity) ]<br>    dirty_bit_list = [ <span class="hljs-literal">False</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(associativity) ]<br>    <br>    indices_in_lru_order = OrderedDict()<br>    <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(associativity - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>        indices_in_lru_order[index] = <span class="hljs-literal">None</span><br>    <br>    <span class="hljs-comment"># receive first tag and is_write</span><br>    <span class="hljs-comment"># yields nothing</span><br>    tag, is_write = <span class="hljs-keyword">yield</span><br>    <br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        cache_hit = <span class="hljs-literal">False</span><br>        victim_tag = <span class="hljs-literal">None</span><br>        writeback_required = <span class="hljs-literal">False</span><br>        <br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-comment"># find tag_index</span><br>            tag_index = tag_list.index(tag)<br>            <br>            <span class="hljs-comment"># tag_index found</span><br>            cache_hit = <span class="hljs-literal">True</span><br>            <br>            <span class="hljs-keyword">if</span> is_write:<br>                dirty_bit_list[tag_index] = <span class="hljs-literal">True</span><br>            <br>            <span class="hljs-comment"># move tag_index to the end of indices_in_lru_order</span><br>            indices_in_lru_order.move_to_end(tag_index)<br>        <br>        <span class="hljs-keyword">except</span> ValueError:<br>            <span class="hljs-comment"># tag_index not found</span><br>            <br>            <span class="hljs-comment"># get index_of_victim from indices_in_lru_order</span><br>            index_of_victim, _ = indices_in_lru_order.popitem(last=<span class="hljs-literal">False</span>)<br>            <br>            victim_tag = tag_list[index_of_victim]<br>            <br>            <span class="hljs-keyword">if</span> dirty_bit_list[index_of_victim]:<br>                writeback_required = <span class="hljs-literal">True</span><br>            <br>            tag_list[index_of_victim] = tag<br>            <br>            <span class="hljs-keyword">if</span> is_write:<br>                dirty_bit_list[index_of_victim] = <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">else</span>:<br>                dirty_bit_list[index_of_victim] = <span class="hljs-literal">False</span><br>            <br>            <span class="hljs-comment"># insert index_of_victim to the end of indices_in_lru_order</span><br>            indices_in_lru_order[index_of_victim] = <span class="hljs-literal">None</span><br>            <br>        <span class="hljs-comment"># receive tag and is_write</span><br>        <span class="hljs-comment"># yield (cache_hit, victim_tag, writeback_required)</span><br>        tag, is_write = <span class="hljs-keyword">yield</span> (cache_hit, victim_tag, writeback_required)<br></code></pre></td></tr></table></figure><hr><h1 id="Coroutines-9"><a href="#Coroutines-9" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Cache Simulation</p><p>Cache</p><ul><li><code>number_of_cache_sets</code> Set<ul><li><code>number_of_ways_of_associativity</code> Block<ul><li><code>block_size_in_bytes</code> Byte</li></ul></li></ul></li></ul><p>Suppose our cache has only eight blocks and each block contains four words. The cache is 2-way set associative, so there are four sets of two blocks. The write policy is write-back and write-allocate. LRU replacement is used. Assume memory is initialized to zero.</p><p><a href="https://courses.cs.washington.edu/courses/cse378/02sp/sections/section9-3.html">https://courses.cs.washington.edu/courses/cse378/02sp/sections/section9-3.html</a></p><hr><h1 id="Coroutines-10"><a href="#Coroutines-10" class="headerlink" title="Coroutines"></a>Coroutines</h1><p>Cache Simulation</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">3</span>]: cache = cache_coroutine(lru_cache_set_coroutine, block_size_in_bytes=<span class="hljs-number">4</span> *<br>   ...:  <span class="hljs-number">2</span>, number_of_ways_of_associativity=<span class="hljs-number">2</span>, number_of_cache_sets=<span class="hljs-number">4</span>)          <br><br>In [<span class="hljs-number">4</span>]: <span class="hljs-built_in">next</span>(cache)                                                             <br><br>In [<span class="hljs-number">5</span>]: cache.send((<span class="hljs-number">0</span>, <span class="hljs-literal">True</span>))                                                   <br>Out[<span class="hljs-number">5</span>]: (<span class="hljs-literal">False</span>, <span class="hljs-literal">None</span>)<br><br>In [<span class="hljs-number">6</span>]: cache.send((<span class="hljs-number">64</span>, <span class="hljs-literal">False</span>))                                                 <br>Out[<span class="hljs-number">6</span>]: (<span class="hljs-literal">False</span>, <span class="hljs-literal">None</span>)<br><br>In [<span class="hljs-number">7</span>]: cache.send((<span class="hljs-number">4</span>, <span class="hljs-literal">True</span>))                                                   <br>Out[<span class="hljs-number">7</span>]: (<span class="hljs-literal">True</span>, <span class="hljs-literal">None</span>)<br><br>In [<span class="hljs-number">8</span>]: cache.send((<span class="hljs-number">40</span>, <span class="hljs-literal">True</span>))                                                  <br>Out[<span class="hljs-number">8</span>]: (<span class="hljs-literal">False</span>, <span class="hljs-literal">None</span>)<br><br>In [<span class="hljs-number">9</span>]: cache.send((<span class="hljs-number">68</span>, <span class="hljs-literal">False</span>))                                                 <br>Out[<span class="hljs-number">9</span>]: (<span class="hljs-literal">True</span>, <span class="hljs-literal">None</span>)<br><br>In [<span class="hljs-number">10</span>]: cache.send((<span class="hljs-number">128</span>, <span class="hljs-literal">True</span>))                                                <br>Out[<span class="hljs-number">10</span>]: (<span class="hljs-literal">False</span>, <span class="hljs-number">0</span>)<br><br>In [<span class="hljs-number">11</span>]: cache.send((<span class="hljs-number">0</span>, <span class="hljs-literal">False</span>))                                                 <br>Out[<span class="hljs-number">11</span>]: (<span class="hljs-literal">False</span>, <span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><hr><h1 id="Thank-You"><a href="#Thank-You" class="headerlink" title="Thank You!"></a>Thank You!</h1>]]></content>
    
    
    <categories>
      
      <category>Code</category>
      
      <category>Python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: The Fundamentals of Writing Questions</title>
    <link href="/2022/10/26/Paper-Review-The-Fundamentals-of-Writing-Questions/"/>
    <url>/2022/10/26/Paper-Review-The-Fundamentals-of-Writing-Questions/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://www.wiley.com/en-us/Internet,+Phone,+Mail,+and+Mixed+Mode+Surveys:+The+Tailored+Design+Method,+4th+Edition-p-9781118456149">here</a>.</p><p>This part of the book addresses the problem of crafting survey questions that respondents are willing to answer and respond to accurately. It first discusses issues to consider when designing survey questions, then presents the structure of a survey question and different question formats, before providing specific guidelines on wording survey questions.</p><h2 id="Issues-to-consider-when-designing-survey-questions"><a href="#Issues-to-consider-when-designing-survey-questions" class="headerlink" title="Issues to consider when designing survey questions"></a>Issues to consider when designing survey questions</h2><ul><li>What concepts to measure<ul><li>Recommended: Adopt established measures from existing surveys</li></ul></li><li>What data to collect<ul><li>Factual information: precise, readily available</li><li>Opinion: requires time to formulate, strongly influenced by context</li><li>Behavior: better memory of recent, memorable events compared with distant, mundane events</li></ul></li><li>What question format to use<ul><li>Different cognitive information processing for aural and visual surveys</li></ul></li><li>What mode to adopt<ul><li>The presence of an interviewer may speed up surveys, but may induce social desirability and acquiescence, leading to interviewer bias.</li><li>Lack of standardization among different interviewers may lead to interviewer variance.</li></ul></li><li>What to modify (from existing surveys)<ul><li>no changes or only minimal changes when replicating or comparing results<ul><li>questions should also be asked in a similar fashion</li></ul></li></ul></li><li>How to motivate respondents<ul><li>think about the cognitive process respondents go through</li><li>pay attention to the context and wording</li></ul></li></ul><h2 id="The-structure-of-a-survey-question"><a href="#The-structure-of-a-survey-question" class="headerlink" title="The structure of a survey question"></a>The structure of a survey question</h2><ul><li>Question stem</li><li>Additional instructions</li><li>Answer spaces or choices</li></ul><h2 id="Different-question-formats"><a href="#Different-question-formats" class="headerlink" title="Different question formats"></a>Different question formats</h2><ul><li>Open-ended<ul><li>rich, detailed</li><li>more prone to skipping</li><li>requires lengthy data processing</li></ul></li><li>Closed-ended<ul><li>nominal or ordinal categories</li><li>set of answer choices known in advance</li><li>easy to analyze</li></ul></li><li>Partially closed-ended<ul><li>closed-ended with “other” response</li><li>respondents more likely to select the options instead of “other”</li></ul></li></ul><h2 id="Specific-guidelines-on-wording-survey-questions"><a href="#Specific-guidelines-on-wording-survey-questions" class="headerlink" title="Specific guidelines on wording survey questions"></a>Specific guidelines on wording survey questions</h2><ul><li>Choose the appropriate question format.</li><li>Make sure the question applies to the respondent.</li><li>Ask one question at a time.</li><li>Make sure the question is technically accurate.</li><li>Use simple, familiar and specific words.</li><li>Use short, simple sentences that take a question form.</li><li>Avoid double negatives.</li><li>Organize questions in a more straightforward, comprehensible way.</li></ul><p>Also sprinkled throughout the section is the notion that the crafter should get into a respondent’s state of mind when crafting survey questions, and also test the survey questions to evaluate their quality.</p><p>This section is very comprehensive and convincing, as the author supports his arguments by analyzing specific examples from actual surveys, and also frequently quoting previous work on the topic. From such a chapter we can gain a deep understanding of the nature of survey questions, especially the underlying cognitive, psychology and sociology problems, as well as the best practices within the domain, and we can also refer to this chapter as a guide and checklist when we craft survey questions ourselves.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: ReCrash: Making Software Failures Reproducible by Preserving Object States</title>
    <link href="/2022/10/25/Paper-Review-ReCrash-Making-Software-Failures-Reproducible-by-Preserving-Object-States/"/>
    <url>/2022/10/25/Paper-Review-ReCrash-Making-Software-Failures-Reproducible-by-Preserving-Object-States/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1007/978-3-540-70592-5_23">here</a>.</p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>Reproduction is key to finding and fixing software problems and verifying proposed solutions, but reproduction can be difficult.</p><ul><li>Nondeterminism: A problem may depend on timing (e.g., context switching), memory layout (e.g., hash codes), or random number generators.</li><li>Remote detection: A problem may be discovered by someone other than the developer, and it may depend on implicit program inputs such as user GUI actions, environment variables, the state of the file system, operating system behavior, etc. This information may be easy to miss, difficult to collect, or confidential.</li><li>Test case complexity: The exposing execution might be complex, and the buggy method might be called multiple times before the bug is triggered.</li></ul><hr><h1 id="Proposed-Solution-ReCrash"><a href="#Proposed-Solution-ReCrash" class="headerlink" title="Proposed Solution: ReCrash"></a>Proposed Solution: ReCrash</h1><p>ReCrash maintains a <strong>shadow stack</strong> with copies of the receiver and arguments to each method during execution of the target program.</p><ul><li>Several copy strategies</li><li>Several optimizations</li></ul><p>When the program crashes, ReCrash serializes the shadow stack, and generates <strong>unit tests</strong> by calling <strong>each</strong> method on the shadow call stack with their receiver and arguments.</p><ul><li>Calling the method at top of the call stack may not provide enough context.</li><li>Calling a method closer to the bottom provides more context, but is less likely to reproduce the original failure.</li></ul><hr><h1 id="Proposed-Solution-ReCrash-1"><a href="#Proposed-Solution-ReCrash-1" class="headerlink" title="Proposed Solution: ReCrash"></a>Proposed Solution: ReCrash</h1><p>Assumption:</p><ul><li>It is possible to reproduce many failures with only some of the information available on entry to the methods on the stack at the time of the failure.<ul><li>Many bugs are dependent on small parts of the heap.</li><li>Good object-oriented style encapsulates important state nearby.</li><li>Good object-oriented style avoids excessive use of globals.</li></ul></li><li>ReCrash has access to and will store any parts of the global state or environment that are passed as method arguments.</li></ul><p><strong>Question: What if global state is read or written in the method?</strong></p><hr><h1 id="Monitoring-Phase"><a href="#Monitoring-Phase" class="headerlink" title="Monitoring Phase"></a>Monitoring Phase</h1><ul><li>Several copy strategies</li><li>Several optimizations<ul><li>Monitoring fewer methods</li><li>Second-chance mode</li></ul></li></ul><hr><h1 id="Copy-Strategies"><a href="#Copy-Strategies" class="headerlink" title="Copy Strategies"></a>Copy Strategies</h1><p>An argument may be side-effected between the method entry and the point of the failure in the method. Copying strategies:</p><ul><li>Reference: copying only the reference to the argument.</li><li>Shallow: copying the argument itself.</li><li>Depth-i: copying all the state reachable with $\le i$ dereferences from the argument.</li><li>Deep-copy: copying the entire state.</li></ul><p>Options:</p><ul><li>Used-fields: deeper copying on fields that are used (read or written) in the method.</li></ul><p>ReCrash always uses the reference strategy for immutable parameters. </p><hr><h1 id="Monitoring-Fewer-Methods"><a href="#Monitoring-Fewer-Methods" class="headerlink" title="Monitoring Fewer Methods"></a>Monitoring Fewer Methods</h1><p>Dosen’t monitor methods that cannot be used in the generated tests, or are unlikely to expose problems.</p><ul><li>non-public methods</li><li>empty methods</li><li>simple methods such as getters and setters (no more than 6 opcodes)</li></ul><hr><h1 id="Second-chance-Mode"><a href="#Second-chance-Mode" class="headerlink" title="Second-chance Mode"></a>Second-chance Mode</h1><ul><li>ReCrash initially monitors no method calls.</li><li>Each time a failure occurs, ReCrash enables method argument monitoring for all methods found on the stack trace.</li><li>Efficient, but requires a failure to be repeated twice. If the developer doesn’t mind missing the first time a failure happens, and the failure occurs relatively often, second chance mode is a good fit.</li></ul><p><strong>Question: could recording all inputs provided to the program be used in tandom with second-chance mode (such that the failure is probable to happen the second time)?</strong></p><hr><h1 id="Test-Generation-Phase"><a href="#Test-Generation-Phase" class="headerlink" title="Test Generation Phase"></a>Test Generation Phase</h1><p>ReCrash generates a test for each of the methods in the shadow stack.</p><ul><li>Restores the state of the arguments that were passed to a method.</li><li>Invokes the method the same way it was invoked in the original execution. Only tests that end with the same exception as the original failure are saved.</li><li>Storing more than one test that ends with the same failure is useful. Some tests reproduce a failure, but would not help the developer understand, fix, or check her solution.</li></ul><hr><h1 id="Experimental-Study"><a href="#Experimental-Study" class="headerlink" title="Experimental Study"></a>Experimental Study</h1><p>Subject programs:</p><ul><li>Javac-jsr308: the OpenJDK Java compiler, extended with JSR308 (“Annotations on Java Types”), with four crashes provided by the developers.</li><li>SVNKit: a subversion  client, with three crash examples from bug reports.</li><li>Eclipsec: a Java compiler included in the Eclipse JDT, with a crash found in the Eclipse bug database.</li><li>BST: a toy subject program used by Csallner in evaluating CnC, with three crashes found by CnC.</li></ul><hr><h1 id="Experimental-Study-1"><a href="#Experimental-Study-1" class="headerlink" title="Experimental Study"></a>Experimental Study</h1><p>For each subject program:</p><ul><li>Run PIDASA for parameter immutability classification.</li><li>For different argument copying strategies, with and without second-chance mode:<ul><li>Run ReCrash on inputs that made the subject programs crash.</li><li>Count how many test cases reproduced each crash.</li></ul></li></ul><p><strong>Question: how useful would ReCrash be in reality where it is unknown whether the subject projects could crash, and which inputs would make the subject programs crash?</strong></p><hr><h1 id="Experimental-Study-2"><a href="#Experimental-Study-2" class="headerlink" title="Experimental Study"></a>Experimental Study</h1><p>Research questions:</p><ul><li>How reliably can ReCrashJ reproduce crashes?</li><li>What is the size of the stored deep copy of the shadow stack?</li><li>Are the tests generated by ReCrash useful for debugging?<ul><li>Like a <strong>case study</strong>: an analysis of two crashes, and comments from developers</li></ul></li><li>What is the overhead (time and memory) of running ReCrash?</li></ul><p>Aspects assessed:</p><ul><li>different argument copying strategies</li><li>with and without second-chance mode</li></ul><hr><h1 id="How-reliably-can-ReCrash-reproduce-crashes"><a href="#How-reliably-can-ReCrash-reproduce-crashes" class="headerlink" title="How reliably can ReCrash reproduce crashes?"></a>How reliably can ReCrash reproduce crashes?</h1><p>ReCrash was able to reproduce the crash in all cases.</p><ul><li>For some crashes, every candidate test case reproduces the crash.</li><li>For other crashes, only a subset of the generated test cases reproduces the crash.</li></ul><p>In most cases, simply copying references is enough to reproduce crashes. In other cases, using the shallow copying strategy with used-fields was necessary.</p><hr><h1 id="What-is-the-size-of-the-stored-deep-copy-of-the-shadow-stack"><a href="#What-is-the-size-of-the-stored-deep-copy-of-the-shadow-stack" class="headerlink" title="What is the size of the stored deep copy of the shadow stack?"></a>What is the size of the stored deep copy of the shadow stack?</h1><p><img src="/images/subject_programs_and_crashes_used_in_our_experimental_study.png" alt="Subject Programs and Crashes Used in our Experimental Study"></p><p><strong>Question: why isn’t it compared with the program size and the program memory usage?</strong></p><hr><h1 id="An-analysis-of-two-crashes"><a href="#An-analysis-of-two-crashes" class="headerlink" title="An analysis of two crashes"></a>An analysis of two crashes</h1><p>Eclipsec bug e1:</p><ul><li>Eclipsec crashes in callee <code>canBeInstantiated</code> because an earlier if statement in the caller <code>resolveType</code> failed to set a boolean flag <code>hasError</code> to true.</li><li>The test case for <code>canBeInstantiated</code> will reproduce the crash, but is not helpful.</li><li>Demonstrates importance of generating tests for multiple methods on the stack.</li></ul><p>Javac-jsr308 bug j4:</p><ul><li>Compiling source code containing an annotation with too many arguments results in an index-out-of-bounds exception in method <code>visitMethodInvocation</code>. </li><li>The generated test does not require the whole source code and encodes only the necessary minimum to reproduce the crash.</li><li>Useful when the compiler crash happens in the field, and the user cannot provide the entire source code for debugging.</li></ul><hr><h1 id="Comments-from-Developers"><a href="#Comments-from-Developers" class="headerlink" title="Comments from Developers"></a>Comments from Developers</h1><p>We gave the tests for j1-4 to two Javac-jsr308 developers and asked for comments about the tests’ usefulness, receiving positive responses.</p><ul><li>I often have to climb back up through a stack trace when debugging. ReCrash seems to generate a test method for multiple levels of the stack, making it useful.</li><li>I find that you wouldn’t have to wait for the crash to occur again useful.</li><li>When I set a break point, the break point maybe be executed multiple times before the error. Using ReCrash, I was able to jump (almost directly) to the necessary breakpoint.</li></ul><p><strong>Question: Why only analyze two crashes and ask only two developers?</strong></p><hr><h1 id="What-is-the-overhead-time-and-memory-of-running-ReCrash"><a href="#What-is-the-overhead-time-and-memory-of-running-ReCrash" class="headerlink" title="What is the overhead (time and memory) of running ReCrash?"></a>What is the overhead (time and memory) of running ReCrash?</h1><h2 id="Time-overhead"><a href="#Time-overhead" class="headerlink" title="Time overhead"></a>Time overhead</h2><p>Non second-chance mode:</p><ul><li>Copying only the references can be expensive (11%-42%), and shallow copying with used-fields is similar (13%–60%). Usable for in-house testing.</li><li>Deep copying is completely unusable (12,000%-638,000%).</li></ul><p>Second-chance mode:</p><ul><li>A barely noticeable 0%–1.7% under copying only the references and shallow copying with used-fields, after a crash has already been observed.</li></ul><hr><h1 id="What-is-the-overhead-time-and-memory-of-running-ReCrash-1"><a href="#What-is-the-overhead-time-and-memory-of-running-ReCrash-1" class="headerlink" title="What is the overhead (time and memory) of running ReCrash?"></a>What is the overhead (time and memory) of running ReCrash?</h1><h2 id="Memory-overhead"><a href="#Memory-overhead" class="headerlink" title="Memory overhead"></a>Memory overhead</h2><p>Non second-chance mode:</p><ul><li>0.2M–4.7M (2.6%-90.3%) under shallow copying with used-fields.</li></ul><p>Second-chance mode:</p><ul><li>negligible</li></ul><hr><h1 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h1><p>ReCrashJ is usable in real software deployment</p><ul><li>Simple to implement</li><li>Scalable</li><li>Generates simple, helpful test cases that effectively reproduce failures</li><li>Time and memory overhead (13%–60%, 2.6%-90.3%) under non second-chance mode and shallow copying with used-fields usable for in-house testing</li><li>Extremely efficient under second-chance mode</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution (but might have been afraid to ask)</title>
    <link href="/2022/10/25/Paper-Review-All-You-Ever-Wanted-to-Know-About-Dynamic-Taint-Analysis-and-Forward-Symbolic-Execution-but-might-have-been-afraid-to-ask/"/>
    <url>/2022/10/25/Paper-Review-All-You-Ever-Wanted-to-Know-About-Dynamic-Taint-Analysis-and-Forward-Symbolic-Execution-but-might-have-been-afraid-to-ask/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1109/SP.2010.26">here</a>.</p><p>Forward symbolic execution and dynamic taint analysis are quickly becoming “staple techniques in security analyses”. </p><ol><li>Dynamic taint analysis runs a program and observes which computations are affected by predefined taint sources such as user input.</li><li>Dynamic forward symbolic execution automatically builds a logical formula describing a program execution path, which reduces the problem of reasoning about the execution to logic, allowing us to reason about the behavior of a program on many different inputs at one time.</li><li>The two analyses can be used in conjunction to build formulas representing only the parts of an execution that depend upon tainted values.</li></ol><p>Forward symbolic execution:</p><ol><li>Test Case Generation (automatically generate inputs to test programs, generate inputs that cause two implementations of the same protocol to behave differently)</li><li>Automatic Input Filter Generation (input filters that detect and remove exploits from the input stream)</li></ol><p>Cristian Cadar, Daniel Dunbar, and Dawson Engler. Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs. In Proceedings of the USENIX Symposium on Operating System Design and Implementation, 2008.</p><p>Cristian Cadar, Vijay Ganesh, Peter Pawlowski, David Dill, and Dawson Engler. EXE: A system for automatically generating inputs of death using symbolic execution. In Proceedings of the ACM Conference on Computer and Communications Security, October 2006.</p><p>Patrice Godefroid, Nils Klarlund, and Koushik Sen. DART: Directed automated random testing. In Proceedings of the ACM Conference on Programming Language Design and Implementation, 2005.</p><p>Dynamic taint analysis:</p><ol><li>Unknown Vulnerability Detection (misuses of user input)</li><li>Automatic Network Protocol Understanding. Dynamic taint analysis has been used to automatically understand the behavior of network protocols when given an implementation of the protocol.</li><li>Malware Analysis (analyze how information flows through a malware binary, explore trigger-based behavior, and detect emulators)</li></ol><p>However, there has been little effort to formally define them and summarize critical issues that arise when applying these techniques in “typical security contexts”.</p><p>The authors formalize the runtime semantics of dynamic taint analysis and forward symbolic execution by using SIMPIL (Simple Intermediate Language), which is “representative of internal representations used by compilers and is powerful enough to express typical languages”.</p><hr><p>Concepts:</p><ul><li>Statements: assignments, assertions, jumps, conditional jumps.</li><li>Expressions: constants, variables, binary operators, unary operators, get_input.</li><li>Execution state: the list of program statements, the current memory state, the current value for variables, the program counter, the current statement.</li></ul><p>Notation:</p><ul><li>$\Sigma$: list of program statements<ul><li>$\Sigma[v_1]$: statement at $pc &#x3D; v_1$.</li></ul></li><li>$\mu$: memory state<ul><li>$\mu[v_1]$: memory content at address $v_1$</li></ul></li><li>$\Delta$: register state (values of all variables)<ul><li>$\Delta[x]$: value of variable $x$</li><li>$\Delta[x \leftarrow 10]$: setting the value of variable $x$ to 10</li></ul></li><li>$pc$: program counter.</li><li>$\mu, \Delta \vdash e \Downarrow v$: Given memory state $\mu$ and register state $\Delta$, the value of expression $e$ is $v$.</li><li>$\Sigma, \mu, \Delta, pc, EXPRESSION \rightsquigarrow \Sigma, \mu’, \Delta’, pc’, {EXPRESSION}’$: Given list of program statements $\Sigma$, memory state $\mu$, register state $\Delta$, program counter $pc$, executing expression $EXPRESSION$ leads to new memory state $\mu’$, new register state $\Delta’$, new program counter $pc’$, and the next expression is ${EXPRESSION}’$.</li></ul><p>Other high-level language constructs such as functions or scopes can be easily represented using these constructs.</p><hr><p>Dynamic taint analysis tracks values in a program dependent on data derived from a “taint source” at runtime. As it is conducted at runtime, it can be expressed by extending SIMPIL.</p><p>Dynamic taint analysis is conducted in different ways (i.e., under different “taint policies”) for different applications. The differences lie in “how new taint is introduced to a program”, “how taint propagates as instructions execute”, and “how taint is checked during execution”. The author presents the example of the “tainted jump policy” for attack detection, points out several challenges it faces, and analyzes the proposed solutions.</p><ul><li>“Distinguishing between memory addresses and cells is not always appropriate”. An alternative “tainted addresses policy” could be used, but this may also overtaint.</li><li>Information flow can occur through control dependencies in addition to dataflow dependencies. This requires “reasoning about multiple paths”, while pure dynamic taint analysis “executes on a single path at a time”. Solutions include “supplementing dynamic analysis with static analysis” and “using heuristics”.</li><li>Taint is only added and never removed (i.e., “sanitized”), leading to the problem of “taint spread”, reducing precision. Well-known constant functions (i.e. using XOR to zero out registers in x86 code) can be checked. In addition, we can consider the outputs of some functions like cryptographic hash functions as untainted, due to limited influence of input on output. This can be quantified (Newsome  et al.) to automatically recognize such cases. Furthermore, values can be untainted “if the program logic performs sanitization itself” (e.g., index bounds checking).</li></ul><p>In conclusion, this paper is an useful introductory paper in forward symbolic execution and dynamic taint analysis, and I have mainly learned the following two things from the paper:</p><ul><li>The idea of formalizing runtime semantics using RISC-like bytecode</li><li>An introduction to dynamic taint analysis - what it is, what it can do, and what challenges it faces</li></ul><hr><p>Feedback from the Class Discussion</p><ul><li>What is the difference between a statement and an expression? A statement can modify program state when it is executed, while an expression doesn’t modify program state.</li><li>In the formalism of SIMPIL, we determine which expression to evaluate by <strong>pattern-matching the rule</strong>.</li><li>LLVM has a dataflow sanitization pass, which may be useful for implementing taint analysis.</li><li>Dynamic program analysis only looks at a single path. If we are to <strong>prove something about a program</strong>, static program analysis would be a better direction.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Evolutionary Generation of Whole Test Suites</title>
    <link href="/2022/10/24/Paper-Review-Evolutionary-Generation-of-Whole-Test-Suites/"/>
    <url>/2022/10/24/Paper-Review-Evolutionary-Generation-of-Whole-Test-Suites/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1109/QSIC.2011.19">here</a>.</p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>Automatically deriving test cases for realistically sized programs:</p><ul><li>Select one coverage goal (e.g., program branch) at a time, and derive a test case that exercises this particular goal.<ul><li>Solving path constraints generated with symbolic execution &#x2F; dynamic symbolic execution</li><li>Meta-heuristic search techniques</li><li>Mutation testing</li></ul></li><li>Alternative approaches not directly aimed to achieve code coverage<ul><li>Randoop<ul><li>incrementally generate sequences of function calls to find buggy test sequences</li><li>requires automated oracles (e.g. developer-written assertions and exceptions)</li></ul></li></ul></li></ul><hr><h1 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h1><p>Many coverage goals are unreachable.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">void</span> <span class="hljs-title function_">push</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    <span class="hljs-keyword">if</span> (size &gt;= values.length) &#123;<br>        resize();<br>    &#125;<br>    <span class="hljs-keyword">if</span> (size &lt; values.length) &#123;<br>        values[size++] = x;<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// UNREACHABLE</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><hr><h1 id="Problems-1"><a href="#Problems-1" class="headerlink" title="Problems"></a>Problems</h1><p>Some coverage goals are more difficult to satisfy than others.</p><p>The order of coverage goals is important: a lucky choice can result in a good test suite, while an unlucky choice can result in a waste of resources.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">void</span> <span class="hljs-title function_">push</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    <span class="hljs-keyword">if</span> (size &gt;= values.length) &#123;<br>        <span class="hljs-comment">// HARD</span><br>        resize();<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// EASY</span><br>    &#125;<br>    <span class="hljs-keyword">if</span> (size &lt; values.length) &#123;<br>        values[size++] = x;<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><hr><h1 id="Problems-2"><a href="#Problems-2" class="headerlink" title="Problems"></a>Problems</h1><p>Satisfying a particular coverage goal frequently entails satisfying further coverage goals by accident.</p><p>The order of coverage goals is important.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">int</span> <span class="hljs-title function_">pop</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">if</span> (size &gt; <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-comment">// May imply coverage in `push` and `resize`</span><br>        <span class="hljs-keyword">return</span> values[size];<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">EmptyStackException</span>();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><hr><h1 id="Our-Solution-EvoSuite"><a href="#Our-Solution-EvoSuite" class="headerlink" title="Our Solution: EvoSuite"></a>Our Solution: EvoSuite</h1><ul><li>Optimize an entire test suite at once instead of considering distinct test cases.</li><li>Evolve a population of test suites towards satisfying a coverage criterion.</li><li>Assume automated oracles are not available, and require the outputs of the test cases to be manually verified.<ul><li>The generated test suites should be of manageable size.</li></ul></li></ul><p>Solves the problem of:</p><ul><li>difficult and unreachable coverage goals</li><li>order of coverage goals</li><li>accidentally satisfying further coverage goals</li></ul><hr><h1 id="Our-Solution-EvoSuite-1"><a href="#Our-Solution-EvoSuite-1" class="headerlink" title="Our Solution: EvoSuite"></a>Our Solution: EvoSuite</h1><p>Questions:</p><ul><li>We are interested in sequences in OOP. Should coverage in terms of a new ordering seen in the last $n$ function calls in the sequence should make more sense? (Praveen)</li><li>It seems like Evosuite offloads the responsibility of adding in correct assertions to the developers. How easy is it for the developers to do this, especially when compared with manually writing all of the test suite? (Shizuko, ToTo, Larry)</li></ul><hr><h1 id="EvoSuite-Modeling"><a href="#EvoSuite-Modeling" class="headerlink" title="EvoSuite Modeling"></a>EvoSuite Modeling</h1><p>Population 1 .. M Test Suite 1 .. N Test Case 1 .. L Statement</p><p>Four types of statements are modeled.</p><ul><li>Primitive statements: numeric variables (e.g. <code>int var0 = 54;</code>)</li><li>Constructor statements: new instances of a class (e.g. <code>Stack var1 = new Stack();</code>). All parameters of the constructor call have to be values of previous statements.</li><li>Field statements: public fields of objects (e.g. <code>int var2 = var1.size;</code>). If the field is non-static, then the source object of the field has to be a value of a previous statement.</li><li>Method statements: public methods of objects (e.g. <code>int var3 = var1.pop();</code>). The source object and all parameters have to be values of previous statements.</li></ul><hr><h1 id="EvoSuite-Modeling-1"><a href="#EvoSuite-Modeling-1" class="headerlink" title="EvoSuite Modeling"></a>EvoSuite Modeling</h1><p>The set of available classes, their public constructors, methods, and fields are extracted from the given software under test.</p><p>An optimal solution is a test suite that covers all the feasible branches&#x2F;methods and is minimal in the number of statements.</p><hr><h1 id="EvoSuite-Process-Overview"><a href="#EvoSuite-Process-Overview" class="headerlink" title="EvoSuite Process Overview"></a>EvoSuite Process Overview</h1><ul><li>Randomly generate a set of initial test suites.</li><li>Evolve using evolutionary search towards satisfying a coverage criterion.</li><li>Minimize the best resulting test suite.</li></ul><p>Questions:</p><ul><li>How are test suites randomly generated? The author discusses “sampling”. Where are we sampling from? (Larry, Jifeng)</li></ul><hr><h1 id="Evolutionary-Search"><a href="#Evolutionary-Search" class="headerlink" title="Evolutionary Search"></a>Evolutionary Search</h1><ul><li>Test Suite Fitness Function</li><li>Crossover</li><li>Accepting the Mutated Offspring</li><li>Bloat Control</li></ul><hr><h1 id="Test-Suite-Fitness-Function"><a href="#Test-Suite-Fitness-Function" class="headerlink" title="Test Suite Fitness Function"></a>Test Suite Fitness Function</h1><p>Covering all branches $B$ and methods $M$ of a program.</p><ul><li>To estimates how close a test suite $T$ is to covering all branches $B$ of a program, for each branch $b$, <strong>minimal branch distance</strong> $d_{min}(b, T)$ is measured. If the branch predicate is $x \ge 10$, and during execution, $x &#x3D;&#x3D; 5$, then the minimal branch distance is $10 - 5 &#x3D; 5$.</li><li>The minimal branch distance is then normalized to get the <strong>branch distance</strong> $d(b, T) &#x3D; f(d_{min}(b, T))$, where $f(x) &#x3D; \frac{x}{x + 1}$.</li></ul><p>$fitness(T) &#x3D; |M| - |M_T| + \sum_{b \in B}{d(b, T)}$</p><p>If execution exceeds a time limit of 5 minutes, maximum fitness is automatically assigned.</p><hr><h1 id="Test-Suite-Fitness-Function-1"><a href="#Test-Suite-Fitness-Function-1" class="headerlink" title="Test Suite Fitness Function"></a>Test Suite Fitness Function</h1><p>Questions:</p><ul><li>What does branch distance actually mean? Why do we use it? (Eric, Rut, Yayu, Udit, Jifeng)</li><li>Doesn’t $\sum_{b \in B}{d(b, T)}$ already consider that branch distances are maximal in unvisited methods? Why do we need an additional $|M| - |M_T|$ term? Furthermore, different methods could have a different number of branches. Should the branch distance sum for all branches within a method be normalized? (Jifeng)</li></ul><hr><h1 id="Crossover"><a href="#Crossover" class="headerlink" title="Crossover"></a>Crossover</h1><p>Rank selection based on the fitness function is used to select two parent test suites $P_1$ and $P_2$ for crossover. In case of ties, smaller test suites are assigned better ranks.</p><p>During crossover:</p><ul><li>a random value $\alpha$ is chosen from $(0, 1)$</li><li>the first offspring test suite $O_1$ will contain the first $\alpha |P_1|$ test cases from $P_1$ and the last $(1 - \alpha)|P_2|$ test cases from $P_2$</li><li>the second offspring test suite $O_2$ will contain the first $\alpha |P_2|$ test cases from $P_2$ and the last $(1 - \alpha)|P_1|$ test cases from $P_1$</li><li>because test cases are independent, $O_1$ and $O_2$ will always be valid</li></ul><hr><h1 id="Mutation"><a href="#Mutation" class="headerlink" title="Mutation"></a>Mutation</h1><p>The two offspring test suites $O_1$ and $O_2$ are then mutated.</p><p>When a test suite T is mutated, each of its <strong>test cases</strong> is mutated with probability $\frac{1}{|T|}$.</p><p>If a test case $t$ is mutated, <strong>remove statements</strong>, <strong>change statements</strong>, and <strong>insert statements</strong> are each applied with probability $\frac{1}{3}$. Then, a number of new random test cases are added to $T$.</p><hr><h1 id="Remove-Statements"><a href="#Remove-Statements" class="headerlink" title="Remove Statements"></a>Remove Statements</h1><ul><li>If a test case $t$ contains $n$ statements, each statement is removed with probability $\frac{1}{n}$.</li><li>If the removed statement $s_i$ is subsequently used by $s_j (j &gt; i)$, try to replace this use with another statement before $s_j$.<ul><li>If this is not possible, recursively remove $s_j$.</li></ul></li><li>If all statements have been removed from $t$, remove $t$ from $T$.</li></ul><hr><h1 id="Change-Statements"><a href="#Change-Statements" class="headerlink" title="Change Statements"></a>Change Statements</h1><ul><li>If a test case $t$ contains $n$ statements, each statement is changed with probability $\frac{1}{n}$.</li><li>If the changed statement $s_i$ is a primitive statement, its numeric value is changed by a random value.</li><li>Otherwise, a method, field, or constructor with the same return type is randomly chosen.</li></ul><hr><h1 id="Insert-Statements"><a href="#Insert-Statements" class="headerlink" title="Insert Statements"></a>Insert Statements</h1><ul><li>With probability $p$, a new statement is inserted at a random position in the test case.</li><li>With probability $p^2$, a second statement is inserted, and so on.</li></ul><hr><p>Questions:</p><ul><li>What are the justifications for the probabilities? (Kevin)</li><li>Can we change the probabilities used in the mutation and insertion by using method calls they kept track of and variables generated in each iteration? (Joyce)</li><li>When deleting, if the statement is chosen from the beginning few statements, is there a high probability that many&#x2F;multiple following statements would be removed? Because an initial statement usually has a higher probability of containing an initialization&#x2F;declaration function. (Rut)</li><li>Why is the probability of inserting the first, second, etc. statement different? This is not the case with remove statements and change statements. (Jifeng)</li><li>To mutate and generate test cases, the GA algorithm should have knowledge of the programming language constructs, fields &amp; methods of the software under test, etc. Does this require a significant engineering effort? (Udit)</li></ul><hr><h1 id="Accepting-the-Mutated-Offspring"><a href="#Accepting-the-Mutated-Offspring" class="headerlink" title="Accepting the Mutated Offspring"></a>Accepting the Mutated Offspring</h1><p>The coverage achieved by the Mutated Offspring is measured by the Test Suite Fitness Function.</p><p>Conditions for accepting the mutated offspring:</p><ul><li>The coverage achieved by the Mutated Offspring <strong>exceeds that achieved by its parents</strong>, or is on par with that achieved by its parents, <strong>and that the mutated offspring are shorter</strong>.</li><li>Their length do not exceed <strong>twice</strong> that of the Test Suite with the best coverage in the community.</li></ul><hr><h1 id="Accepting-the-Mutated-Offspring-1"><a href="#Accepting-the-Mutated-Offspring-1" class="headerlink" title="Accepting the Mutated Offspring"></a>Accepting the Mutated Offspring</h1><p>Questions:</p><ul><li>Are the parents removed before adding the children? (Rut)</li><li>Compared with the single branch strategy, only the crossover is different, and the mutation is done in the same way. (Tarcisio)</li></ul><hr><h1 id="Bloat-Control"><a href="#Bloat-Control" class="headerlink" title="Bloat Control"></a>Bloat Control</h1><p>A <strong>variable size representation</strong> could lead to bloat, where <strong>small negligible improvements in the fitness value are obtained with larger solutions.</strong></p><p>This is a <strong>very common problem in Genetic Programming</strong>.</p><p>The following measures are used for bloat control:</p><ul><li>Limit the maximum number $N$ of test cases within a test suite and the maximum number of statements $L$ within a test case. (still need to choose comparatively larger $N$ and $L$ and then reduce their length during&#x2F;after the search to dramatically boost coverage)</li><li>Crossover selection policy</li><li>Mutated offspring acception policy</li></ul><hr><h1 id="Bloat-Control-1"><a href="#Bloat-Control-1" class="headerlink" title="Bloat Control"></a>Bloat Control</h1><p>Questions:</p><ul><li>Does coverage-guided fuzzing, which uses a variant of Genetic Programming, suffer from bloat? If so, could any measures be applied to solve this problem? (Jifeng)</li><li>How to reduce the length during&#x2F;after the search? (Yayu, Jifeng)</li></ul><hr><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>EvoSuite is compared with the traditional single branch approach on top of EvoSuite infrastructure.</p><ul><li>Offspring is generated using the crossover function, but is conducted on two sequences of statements.<ul><li>Because there are dependencies between statements, the statements of the second part are appended one at a time, trying to satisfy dependencies with existing values, generating new values if necessary.</li></ul></li><li>The traditional approach level plus normalized branch distance fitness function is used.</li></ul><p>The two approaches are compared on five open source libraries and a subset of an industrial case study project previously used by Arcuri et al. The units are testable without complex interactions with external resources and are not multithreaded.</p><hr><h1 id="Evaluation-1"><a href="#Evaluation-1" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>“Best practices” based on past experience are used for EvoSuite:</p><ul><li>Population size: 80</li><li>Maximum test suite size $N &#x3D; 100$</li><li>Maximum test case size $L &#x3D; 80$</li><li>The initial test suites are generated with 2 test cases each</li><li>Initial probability for test case insertion: 0.1</li><li>Crossover probability: 3 &#x2F; 4</li><li>Initial probability for statement insertion: 0.5</li></ul><hr><h1 id="Evaluation-2"><a href="#Evaluation-2" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>The search operators for test cases make use of only the type information in the test cluster, and so difficulties can arise when method signatures are imprecise. To overcome this problem for container classes, we always put Integer objects into container classes, and cast returned Object instances back to Integer.</p><p>As the length of test cases can vary greatly and longer test cases generally have higher coverage, we decided to take the number of executed statements as execution limit. The search is performed until either a solution with 100% branch coverage is found, or $k &#x3D; 1,000,000$ statements have been executed as part of the fitness evaluations.</p><hr><h1 id="Evaluation-3"><a href="#Evaluation-3" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>Questions:</p><ul><li>Why not compare EvoSuite to any other (non genetic-testing based) approach? (Zack)</li><li>Why “the units are testable without complex interactions with external resources and are not multithreaded”? (Marie)</li><li>Is there a justification for these “best practices”? (Praveen, Kevin, Madonna, Jifeng)</li><li>Do the “best practices” overfit the 5 open-source libraries? (Joyce)</li><li>Why the choice of an Integer? And does it work in practice? Given that the internals of the program might be expecting something else? (Rut)</li></ul><hr><h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><ul><li>Whole test suite generation achieves higher coverage than single branch test case generation.</li><li>Whole test suite generation produces smaller test suites than single branch test case generation.</li></ul><hr><h1 id="Results-1"><a href="#Results-1" class="headerlink" title="Results"></a>Results</h1><p>Questions:</p><ul><li>While we have focused on branch coverage in this paper, the findings also carry over to other test criteria is an unwarranted extrapolation. (Zack)</li><li>Evosuite claims that the test cases are smaller, but how much smaller? (not obvious from Figure 7) (ToTo)</li><li>High coverage test suite does not necessary mean high bug-finding abilities.</li><li>How does the performance compare to other tools? (ToTo, Praveen, Kevin, Madonna)</li><li>The authors did not evaluate EvoSuite against a human in software engineering. Whether EvoSuite will improve the ability to test software from a software developer’s point of view is unknown. (Marie)</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Personal Website Design Considerations</title>
    <link href="/2022/10/20/Personal-Website-Design-Considerations/"/>
    <url>/2022/10/20/Personal-Website-Design-Considerations/</url>
    
    <content type="html"><![CDATA[<h1 id="Hosting"><a href="#Hosting" class="headerlink" title="Hosting"></a>Hosting</h1><p>We host our personal website on <a href="https://docs.github.com/en/pages/getting-started-with-github-pages/about-github-pages">GitHub Pages</a>, a static site hosting service. Considerations:</p><ul><li>No need to buy&#x2F;rent and set up infrastructure, such as Elastic Computing instances, Domain Name, Content Distribution Network, Load Balancer, DDoS protection</li><li>Hosted directly from GitHub repository</li><li>Our personal website meets its limitations:<ul><li>Non-commercial.</li><li>No confidential information.</li><li>Published GitHub Pages sites may be no larger than 1 GB.</li><li>GitHub Pages sites have a soft bandwidth limit of 100 GB per month.</li><li>GitHub Pages sites have a soft limit of 10 builds per hour.</li></ul></li></ul><p>Implications:</p><ul><li>Static pages.</li><li>Limit content of our personal website to text and lightweight multimedia, such as vector graphics and vector PDFs. Use raster graphics sparingly, and avoid heavyweight multimedia such as audio and video.</li><li>Do not rebuild too frequently (&gt;10 builds per hour).</li></ul><h1 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h1><p>Our personal website uses the <a href="https://hexo.io/">Hexo</a> blog framework. Considerations:</p><ul><li>Support for GitHub Flavored Markdown.</li><li>Easy-to-use CLI.</li><li>One-command deploy to GitHub Pages.</li><li>Support for two types of pages (Posts and Pages), adequate for a personal website.</li><li>Huge library of spectacular, feature-packed and customizable themes.</li></ul><h1 id="Theme"><a href="#Theme" class="headerlink" title="Theme"></a>Theme</h1><p>Our personal website uses the <a href="https://github.com/fluid-dev/hexo-theme-fluid">fluid</a> theme for Hexo. Considerations:</p><ul><li>Appropriate Features<ul><li>Support for <a href="https://github.com/YunYouJun/yunyoujun.github.io/issues/105">many third-party commenting systems</a>.</li><li>Mathjax support, renders equations like $E&#x3D;mc^2$.</li><li>Mermaid support.</li><li>Social network links.</li></ul></li><li>Extremely Detailed Documentation.</li><li>Actively Maintained.</li></ul><h1 id="Our-Considerations-When-Writing-Posts"><a href="#Our-Considerations-When-Writing-Posts" class="headerlink" title="Our Considerations When Writing Posts"></a>Our Considerations When Writing Posts</h1><ul><li>Make the Markdown file as self-contained as possible. This includes:<ul><li>Using third-party pictures from the Internet with stable URLs whenever possible.</li><li>Utilize fluid’s support for Mermaid, and use Mermaid to describe and render in real-time diagrams such as Flowcharts, Sequence Diagrams, Class Diagrams, State Diagrams, and Mindmaps whenever possible, as opposed to including diagrams generated using other tools.</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Code</category>
      
      <category>Personal Website</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Feedback-Directed Random Test Generation</title>
    <link href="/2022/10/18/Paper-Review-Feedback-Directed-Random-Test-Generation/"/>
    <url>/2022/10/18/Paper-Review-Feedback-Directed-Random-Test-Generation/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1109/ICSE.2007.37">here</a>.</p><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>The authors present Randoop, a feedback-directed random unit test generator for object-oriented programs which generates sequences of method calls that create and mutate objects, and uses feedback obtained from executing the sequences to guide the search towards new sequences.</p><h1 id="Logic-of-Randoop"><a href="#Logic-of-Randoop" class="headerlink" title="Logic of Randoop"></a>Logic of Randoop</h1><p>Randoop builds sequences incrementally starting from an empty set of sequences. In each iteration, it generates and executes a new sequence.</p><h2 id="Sequence-Generation"><a href="#Sequence-Generation" class="headerlink" title="Sequence Generation"></a>Sequence Generation</h2><p>First, it selects a method randomly among the public methods of classes.</p><p>Second, it finds arguments to provide to the method.</p><ul><li>If an argument is a primitive type, select a primitive value from a fixed pool of values.</li><li>If an argument is a reference type, select an extensible value of the corresponding type from a previously generated sequence in $nonErrorSeqs$ and put the previous generated sequence into a temporary list if possible, or select null otherwise.</li></ul><p>Third, a new sequence is formed by concatenating the sequences in the temporary list and the randomly selected method.</p><p>Fourth, the new sequence is checked whether it has been generated before. If so, the process is repeated.</p><p>Furthermore, the authors considers that repeated calls to a method may increase code coverage (e.g. reach code that increases the capacity of a container object, or reach code that goes down certain branches). Thus, with a probability $p &#x3D; 0.1$, instead of appending a single call of a chosen method, a maximum of $N &#x3D; 100$ calls are appended.</p><h2 id="Sequence-Execution"><a href="#Sequence-Execution" class="headerlink" title="Sequence Execution"></a>Sequence Execution</h2><p>After a new sequence is generated, each method call in the sequence is executed, and after each call, contracts are checked.</p><p>Default contracts checked by Randoop include:</p><ul><li>method throws no NullPointerException if no input parameter was null</li><li>method throws no AssertionError</li><li>o.equals(o) returns true and throws no exception</li><li>o.hashCode() throws no exception</li><li>o.toString() throws no exception</li></ul><p>If at least one contract is violated, the sequence is put in $errorSeqs$, and no values within the sequence can be extended. If all contracts are not violated, the sequence is put in $nonErrorSeqs$, and all values within the sequence are checked whether they can be extended. If the value has been encountered before, is null, or an exception occurs when executing the sequence leading to the value, the value cannot be extended.</p><h1 id="Experimental-Study"><a href="#Experimental-Study" class="headerlink" title="Experimental Study"></a>Experimental Study</h1><p>The authors evaluate the effectiveness of Randoop through three experiments.</p><ol><li>Comparing the basic block and predicate coverage of Randoop and five systematic input generation techniques on four container data structures used previously to evaluate these systematic input generation techniques.</li><li>Comparing Randoop with JPF (a systematic testing technique) and undirected random testing on 14 widely-used libraries.</li><li>A case study using Randoop to find regression errors between different implementations of the Java JDK.</li></ol><p>The experimental results strongly suggest that Randoop outperforms systematic and undirected random test generation in both coverage and error detection.</p><h1 id="Personal-Thoughts"><a href="#Personal-Thoughts" class="headerlink" title="Personal Thoughts"></a>Personal Thoughts</h1><ol><li>In my opinion, a key advantage of Randoop is the “sparse, global sampling” that it performs, which “retains the benefits of random testing (scalability, simplicity of implementation)”, while avoiding undirected random testing’s pitfalls (generation of redundant or meaningless inputs), and is better adapted to large-scale library code than the “dense, local sampling” of systematic test generation.</li><li>The sequences Randoop builds are akin to seeds in coverage-guided fuzzing, and I believe the efficiency and effectiveness of Randoop may be further boosted by applying a power schedule to the built sequences, much like applying a power schedule to the seeds in coverage-guided fuzzing.</li><li>The built sequences could possibly have overlapping prefixes. Would using a tree structure be better than storing each sequence on its own?</li><li>Randoop only supports a limited number of contracts, and its error-detection ability is rather weak. It may be appropriate on library code filled with assertions and checks, but may not work well on client code where these may be sparse.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Exploiting Dynamic Information in IDEs Improves Speed and Correctness of Software Maintenance Tasks</title>
    <link href="/2022/10/16/Paper-Review-Exploiting-Dynamic-Information-in-IDEs-Improves-Speed-and-Correctness-of-Software-Maintenance-Tasks/"/>
    <url>/2022/10/16/Paper-Review-Exploiting-Dynamic-Information-in-IDEs-Improves-Speed-and-Correctness-of-Software-Maintenance-Tasks/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/TSE.2011.42">here</a>.</p><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The pervasive use of inheritance, interfaces, and runtime polymorphism in object-oriented software systems leads to it being unclear which concrete method is invoked at a call site. Modern IDEs such as Eclipse offer static views of the source code, but provide little help in revealing the execution paths an object-oriented software system actually takes at runtime.</p><p>In this situation, developers usually resort to debuggers or profilers. However, the information extracted by such tools are volatile, and developers cannot continuously benefit from dynamic information integrated in the static source views in the IDE.</p><p>To solve this problem, the authors propose Senseo, an Eclipse plugin that collects dynamic information by running unit and&#x2F;or system tests of the project with a customized JVM, that enriches the source views of Eclipse with dynamic information, such as:</p><ul><li>which concrete methods a particular method invokes, and how often</li><li>which methods invoke this particular method</li><li>how many objects are allocated in methods</li><li>the dynamic collaborations between different source artifacts</li><li>a visualization of the system’s Calling Context Tree</li></ul><p>These are displayed in tooltips, ruler columns, the Package Explorer, and a dedicated Collaboration Overview.</p><p>The authors conducted an experiment with 30 professional Java developers solving five typical software maintenance tasks in JEdit, an unfamiliar, medium-sized software system, measured the time and correctness of the tasks, and conducted statistical tests on the measurements. Senseo yields a significant decrease in time of 17.5 percent and a significant increase in correctness of 33.5 percent, which validates the practical usefulness of Senseo.</p><h1 id="Personal-Thoughts"><a href="#Personal-Thoughts" class="headerlink" title="Personal Thoughts"></a>Personal Thoughts</h1><p>There is no doubt that the idea of enriching the source views of an IDE with dynamic information, as well as its implementation Senseo, is of great practical value to developers writing object-oriented software systems. However, I do have a few concerns after reading the paper.</p><ul><li>To enrich the source views of Eclipse with dynamic information, Senseo runs unit and&#x2F;or system tests of the project with a customized JVM. There are several concerns here.<ul><li>The project should have unit and&#x2F;or system tests that thoroughly exercise all units in a manner resembling an actual execution of the project in production, otherwise, the dynamic information for some units may be missing and&#x2F;or inaccurate.</li><li>The unit and&#x2F;or system tests should be self-contained and not rely on interacting with the environment, such as getting input from the user, using OS services, etc. If so, a possible remedy would be to carve unit tests from such executions.</li><li>There is significant overhead in the process of collecting dynamic information. As the authors have reported: “On average (geometric mean), CCT creation alone causes an overhead of factor 2.68. CCT creation and collection of dynamic information result in an overhead of factor 9.07. The total overhead, including serialization&#x2F;transmission, is of factor 9.47.” Although the authors claim that “even though the overall overhead is high when gathering dynamic information, we do not consider this a major issue as the application does not need to run at productive speed while analyzing it”, this could be a problem for lengthy system tests, especially if units in the system tests are frequently modified, and new dynamic information has to be reacquired. Carving unit tests from such system tests would also be a possible remedy.</li></ul></li></ul><p>Furthermore, aside from the idea and implementation of the tool, something else I appreciate and have learned from this paper is the experimental study, in which two measures, the time and correctness of the tasks, are selected, and statistical tests on the measurements are conducted. This convincingly proves the effectiveness of Senseo.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: A Practical Guide for Using Statistical Tests to Assess Randomized Algorithms in Software Engineering</title>
    <link href="/2022/10/16/Paper-Review-A-Practical-Guide-for-Using-Statistical-Tests-to-Assess-Randomized-Algorithms-in-Software-Engineering/"/>
    <url>/2022/10/16/Paper-Review-A-Practical-Guide-for-Using-Statistical-Tests-to-Assess-Randomized-Algorithms-in-Software-Engineering/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/1985793.1985795">here</a>.</p><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>There are many problems in software engineering which are undecidable and use randomized algorithms, such as automated unit test generation, random testing, and search algorithms (including Genetic Algorithms). As the outcomes of these randomized algorithms vary greatly from run to run, assessing their effectiveness is an important topic.</p><p>To uncover whether randomized algorithms are properly assessed in software engineering research, the authors conducted a small-scale systematic review on three representative software engineering venues, namely IEEE Transactions of Software Engineering (TSE), IEEE International Conference on Software Engineering (ICSE) and International Symposium on Search Based Software Engineering (SSBSE), in the year 2009. The review shows that the analyses “are either missing, inadequate, or incomplete”, and “randomness is not properly taken into account”. The authors then put forward guidelines for properly assessing randomized algorithms in software engineering research.</p><h1 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h1><dl><dt>Censoring<br>: a condition in which only the <strong>range</strong> (i.e. above a certan value, below a certain value, within an interval) of a measurement or observation is known, and its precise value is unknown.<br>: Akin to <strong>clamping</strong> in saturated arithmetic.</dt><dd>Commonly encountered in software engineering experiments when <strong>time limits</strong> are used.</dd></dl><h1 id="Assessment-Procedure-and-Guidelines"><a href="#Assessment-Procedure-and-Guidelines" class="headerlink" title="Assessment Procedure and Guidelines"></a>Assessment Procedure and Guidelines</h1><p>A novel randomized algorithm is commonly compared against an existing technique. After determing a measure to compare (e.g. source code coverage, execution time), we should run both algorithms <strong>a large enough number of times independently (the author recommends “a very high number of runs” and not the rule of thumb of $n &#x3D; 30$ in medicine and behavioral science, as human aspects are not involved</strong>. With the collected measure data, we conduct the following:</p><h2 id="Statistical-Testing"><a href="#Statistical-Testing" class="headerlink" title="Statistical Testing"></a>Statistical Testing</h2><p>We use a <strong>statistical test</strong> to assess “whether there is enough empirical evidence to claim a difference between the two algorithms”.</p><p><strong>In such a statistical test, the null hypothesis is typically “there is no difference”, and we verify whether we should reject the null hypothesis.</strong></p><h3 id="Definitions-related-to-Statistical-Testing"><a href="#Definitions-related-to-Statistical-Testing" class="headerlink" title="Definitions related to Statistical Testing"></a>Definitions related to Statistical Testing</h3><p>There are two conflicting types of error when performing statistical testing: (I) we reject the null hypothesis when it is true, and (II) we accept the null hypothesis when it is false.</p><ul><li>The <strong>p-value</strong> of a statistical test is the probability of rejecting the null hypothesis when it is true.</li><li>The <strong>significant level $\alpha$</strong> of a statistical test is the highest p-value we accept for rejecting the null hypothesis. There is a tradition of using $\alpha &#x3D; 0.05$ in the natural sciences. <strong>However, an increasing number of researchers believe that, and the author endorses that, such thresholds are arbitrary, and that researchers should “simply report p-values and let the reader decide in context”.</strong></li><li>The <strong>statistical power</strong> of a statistical test is the probability of rejecting the null hypothesis when it is false.</li></ul><h3 id="Selection-of-Statistical-Test"><a href="#Selection-of-Statistical-Test" class="headerlink" title="Selection of Statistical Test"></a>Selection of Statistical Test</h3><p>In different statistical tests, <strong>different probability distributions of the collected measures</strong> are assumed, and <strong>different aspects of the probability distributions of the collected measures</strong> are being compared. Common statistical tests include:</p><ul><li>parametric<ul><li>Student’s t-test</li><li>Welch’s t-test</li><li>F-test</li><li>ANOVA</li></ul></li><li>nonparametric<ul><li>Fisher exact test</li><li>Wilcoxon signed ranks test</li><li>Mann-Whitney U-test</li></ul></li></ul><p>When selecting a statistical test, tt is worth paying attention to the probability distributions of the collected measures:</p><ul><li>there may be a “very strong departure from normality”</li><li>the mean and variance may not exist</li><li>the data may be censored</li></ul><h2 id="Effect-Size-Measurement"><a href="#Effect-Size-Measurement" class="headerlink" title="Effect Size Measurement"></a>Effect Size Measurement</h2><p>In addition to using a statistic test to assess improvement of one algorithm over another, it is also critical to assess “the magnitude of the improvement”, for which effect size measures are used.</p><ul><li>Unstandardized effect size measures: dependent on the unit of measurement<ul><li>difference in mean</li></ul></li><li>Standardized effect size measures:<ul><li>d family &#x2F; Mahalanobis distance, <strong>assumes the normality of the data</strong></li><li>Common Language (CL) Statistic. The probability that a randomly selected score from the first population $X_1$ is greater than a randomly selected score from the second population $X_2$, $P(X_1 &gt; X_2)$.</li><li>Measure of Stochastic Superiority. A generalization of Common Language Statistic, $A_{12} &#x3D; P(X_1 &gt; X_2) + 0.5 P(X_1 &#x3D; X_2)$. <strong>Recommended.</strong></li><li>Odds ratio. A measure of “how many times greater the odds are that a member of a certain population will fall into a certain category than the odds are that a member of another population will fall into that category”. If the total number of runs is $n$, and the number of times two algorithms find optimal solutions are $n_1$ and $n_2$, then the odds ratio is $\psi &#x3D; \frac{\frac{n_1}{n - n_1}}{\frac{n_2}{n - n_2}}$. <strong>Recommended.</strong></li></ul></li></ul><h3 id="Multiple-Statistical-Tests-and-Effect-Size-Measurements"><a href="#Multiple-Statistical-Tests-and-Effect-Size-Measurements" class="headerlink" title="Multiple Statistical Tests and Effect Size Measurements"></a>Multiple Statistical Tests and Effect Size Measurements</h3><p>When comparing $k$ algorithms, we frequently would like to know the performance of each algorithm “compared against all other alternatives individually”. This incurs $\frac{k (k - 1)}{2}$ comparisons.</p><p>However, when doing multiple stastical tests, given a significant level $\alpha$ and the number of tests $n$, the probability that at least one null hypothesis is true is $1 - {(1 - \alpha)}^n$, which converges to $1$ as $n$ increases.</p><p>A remedy is the Bonferroni adjustment, in which we use an adjusted significant level $\frac{\alpha}{n}$. However, this has been “seriously criticized in the literature”, and the author recommends <strong>“simply report p-values and let the reader decide in context”</strong> instead.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Breaking the Barriers to Successful Refactoring: Observations and Tools for Extract Method</title>
    <link href="/2022/10/13/Paper-Review-Breaking-the-Barriers-to-Successful-Refactoring-Observations-and-Tools-for-Extract-Method/"/>
    <url>/2022/10/13/Paper-Review-Breaking-the-Barriers-to-Successful-Refactoring-Observations-and-Tools-for-Extract-Method/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1145/1368088.1368146">here</a>.</p><p>Refactoring is important to software development. Performing a refactoring is not trivial, for which refactoring tools have been developed. Nevertheless, programmers do not use refactoring tools as often as they could.</p><p>To investigate this problem, the authors focus on one type of refactoring and one specific tool - the Extract Method tool in the Eclipse IDE.</p><ul><li>Fowler reports that Extract Method is “one of the most common refactorings”, “a key refactoring” which if successful, means “you can go on [to do] more refactorings”.</li><li>The Extract Method tool in the Eclipse IDE it is a mature, non-trivial refactoring tool.</li><li>Most refactoring tool user interfaces are very similar.</li></ul><p>The authors first conject tools are non-specific and unhelpful in diagnosing problems, and undertake a formative study observing 11 programmers perform a number of Extract Method refactorings on several large, open-source projects, which suggest that programmers fairly frequently encounter a variety of errors arising from violated refactoring preconditions.</p><p>The authors further conjecture error messages were conflated, insufficiently descriptive, and discouraged programmers from refactoring, and built three visualization tools within the Eclipse IDE as solutions. Then, they conducted a study to assess whether or not the new tools overcome these usability problems by comparing the accuracy and time to complete refactoring tasks with and without the new tools, and administered a post-test questionnaire for the subjects to express their preferences. The results of the study were very positive, and subjects found the new tools superior and helpful outside of the context of the study.</p><p>Finally, the authors provide recommendations for future tools.</p><ul><li>Code Selection: A selection tool should be lightweight, task-specific, and help the programmer overcome unfamiliar&#x2F;unusual code formatting.</li><li>Displaying Violated Preconditions: quickly comprehensible, indicate location, easily distinguishable from warnings and advisories, display amount of work required, display relations between precondition violations, distinguish different types of violations.</li></ul><p>The experimental study is very concise, and there are many aspects that can be borrowed.</p><ul><li>Undertaking a formative study to verify conjections about problems within current tools, before building new tools based on the verified conjections, and evaluating them.</li><li>The visualization comparing the the accuracy and time of <strong>each participant</strong> to complete refactoring tasks with and without the new tools is accurate and straightforward.</li><li>Using a questionnaire to acquire subjective feedback complimentary to an objective evaluation.</li></ul><p>However, there are still some flaws.</p><ul><li>Only one type of refactoring (Extract Method) and one specific tool was considered. The takeaways may not apply to other types of refactoring.</li><li>Several key variates were not controlled in the formative study, such as participants were free to refactor whatever code they thought necessary.</li></ul><p>Future directions of work include:</p><ul><li>Replicating the study for other types of refactoring.</li><li>Build and assess new refactoring tools with increased usability.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: QSYM: A Practical Concolic Execution Engine Tailored for Hybrid Fuzzing</title>
    <link href="/2022/10/11/Paper-Review-QSYM-A-Practical-Concolic-Execution-Engine-Tailored-for-Hybrid-Fuzzing/"/>
    <url>/2022/10/11/Paper-Review-QSYM-A-Practical-Concolic-Execution-Engine-Tailored-for-Hybrid-Fuzzing/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-yun.pdf">here</a>.</p><h1 id="What-is-the-problem-being-tackled-How-was-it-addressed-by-prior-work"><a href="#What-is-the-problem-being-tackled-How-was-it-addressed-by-prior-work" class="headerlink" title="What is the problem being tackled? How was it addressed by prior work?"></a>What is the problem being tackled? How was it addressed by prior work?</h1><p>There are two notable technologies to automatically find vulnerabilities in software:</p><ul><li>Coverage-guided fuzzing, quickly explores the input space, but only good at discovering inputs leading to an execution path with loose branch conditions</li><li>Concolic execution, good at finding inputs driving the program into tight and complex branch conditions, but very expensive to formulate and solve constraints</li></ul><p>A hybrid approach, hybrid fuzzing, was recently proposed.</p><ul><li>The fuzzer will quickly explore trivial input spaces (loose conditions)</li><li>The concolic execution will solve the complex branches (tight conditions)</li><li>Still suffer from scaling to find real bugs in real-world applications. Bottlenecks are their concolic executors. The symbolic emulation is too slow in formulating path constraints, and it is often not even possible to generate constraints due to incomplete and erroneous environment models.</li></ul><h1 id="What-are-the-innovation-s-proposed-in-this-paper-Which-technical-innovations-are-most-compelling-to-you"><a href="#What-are-the-innovation-s-proposed-in-this-paper-Which-technical-innovations-are-most-compelling-to-you" class="headerlink" title="What are the innovation(s) proposed in this paper? Which technical innovations are most compelling to you?"></a>What are the innovation(s) proposed in this paper? Which technical innovations are most compelling to you?</h1><p>Concolic executors adopt IR in their symbolic emulation. Although IR makes implementation easy, it incurs additional overhead and  blocks further optimization. According to our measurement with real-world software, only 30% of instructions require symbolic execution. This implies an instruction-level approach has an opportunity to reduce the number of unnecessary symbolic executions.</p><p>Concolic execution engines use snapshot techniques to reduce the overhead of re-executing a target program when exploring its multiple paths. However, in hybrid fuzzing, test cases from the fuzzer are associated with greatly different paths, rendering snapshoting inefficient. Furthermore, snapshots cannot reflect external status, and solving this problem through full system concolic execution or external environment modeling is expensive and&#x2F;or inaccurate.</p><p>Concolic execution tries to guarantee soundness by collecting complete constraints. However, this can be expensive, and also over-constrain a path, limiting finding future paths.</p><p>To solve these problems, Qsym uses Intel Pin along with a coverage-guided fuzzer:</p><ul><li>Get input test cases and validate newly produced test cases (potentially unsound) from the fuzzer.</li><li>Employ instruction-level taint tracking, and only symbolically execute tainted instructions.</li><li>Generate more relaxed (incomplete) forms of constraints that can be easily solved (can result in unsound test cases, but quickly checked with fuzzer).</li><li>Fast execution makes re-execution much preferable to snapshoting for repetitive concolic testing.</li><li>Considers external environments as “black-boxes” and simply executes them concretely (can result in unsound test cases, but quickly checked with fuzzer).</li><li>Chooses the last constraint of a path for optimistic solving. It typically has a very simple form, and avoids solving irrelevant constraints repeatedly tested by fuzzers. <strong>This can be applied to other domains to speed up symbolic execution, if the domain has an efficient validator like a fuzzer.</strong></li><li>If a basic block has been executed too frequently in a context (a call stack of the current execution), Qsym stops generating further constraints from it. Extremely suitable for loops. <strong>This can directly be applied to other concolic executors as a heuristic path exploration strategy.</strong></li></ul><h1 id="How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement"><a href="#How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement" class="headerlink" title="How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?"></a>How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?</h1><p>A series of experiments are conducted.</p><ol><li>To highlight the effectiveness, we applied QSYM to non-trivial programs that are large in size and well-tested - all applications and libraries tested by OSS-Fuzz.</li><li>To show how effectively our concolic executor can assist a fuzzer in discovering new code paths, we measured the achieved code coverage during the fuzzing process using Qsym and AFM with a varying number of input seed files. We selected libpng as a fuzzing target because it contained various narrow-ranged checks.</li><li>To show the performance benefits of QSYM’s symbolic emulation, we used the DARPA CGC dataset to compare QSYM with Driller, which placed third in the CGC competition.</li><li>To evaluate the effect of optimistic solving, we compared Qsym with others using the LAVA dataset, a test suite that injects hard-to-find bugs in Linux utilities to evaluate bug-finding techniques.</li><li>To show the effect of basic block pruning, we evaluated Qsym with and without this technique with four widely-used open-source programs - libjpeg, libpng, libtiff, and file.</li><li>The author then analyzes new bugs found by Qsym.</li></ol><p>These experiments comprehensively assess different innovations and support the notion that Qsym “scales to find real bugs in real-world applications”. However, I do have some questions concerning the experimental study, stated below.</p><h1 id="What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper"><a href="#What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper" class="headerlink" title="What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?"></a>What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?</h1><p>Qsym generates more relaxed (incomplete) forms of constraints that can be easily solved. Specifically how this is done is not clear.</p><p>Questions concerning the experimental study:</p><ol><li>The experiments “to highlight the effectiveness” and “to show the performance benefits of QSYM’s symbolic emulation” seem to be redundant.</li><li>To show how effectively our concolic executor can assist a fuzzer in discovering new code paths, we compared Qsym with AFM on libpng, because it contained various narrow-ranged checks. The benchmark appears to be cherry-picked. This is also the case with “to show the effect of basic block pruning”.</li><li>Why are completely different datasets used in different experiments?</li></ol><h1 id="Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper"><a href="#Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper" class="headerlink" title="Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper?"></a>Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper?</h1><p>The coverage-guided fuzzer used within Qsym is “vanilla” AFL. Other coverage-guided fuzzers exist that enhance AFL. How Qsym can complement these fuzzers can be a direction for future research.</p><p>Unlike other IR-based executors, QSYM cannot test programs targeting other architectures. We plan to overcome this limitation by improving QSYM to work with architecture specifications, rather than a specific architecture implementation. <strong>(Is taint analysis on IR+JIT also a possible solution?)</strong></p><p>QSYM currently supports only memory, arithmetic, bitwise, and vector instructions. Other instructions, including floating-point operations, remain to be supported.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Semantic Fuzzing with Zest</title>
    <link href="/2022/10/11/Paper-Review-Semantic-Fuzzing-with-Zest/"/>
    <url>/2022/10/11/Paper-Review-Semantic-Fuzzing-with-Zest/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/3293882.3330576">here</a>.</p><h1 id="What-is-the-problem-being-tackled"><a href="#What-is-the-problem-being-tackled" class="headerlink" title="What is the problem being tackled?"></a>What is the problem being tackled?</h1><p>The paper tackles the problem of generating random, syntactically valid inputs to exercise various code paths in the semantic analysis stages of programs and leveraging feedback to generate new inputs via mutations.</p><h1 id="How-was-it-addressed-by-prior-work"><a href="#How-was-it-addressed-by-prior-work" class="headerlink" title="How was it addressed by prior work?"></a>How was it addressed by prior work?</h1><p>On one hand, QuickCheck-like random-input generators allow generating random, syntactically valid inputs. On the other hand, coverage-guided fuzzing tools such as AFL and libFuzzer randomly mutate known byte sequences to produce new byte sequences, and if the mutated byte sequences lead to new code coverage in the test program, they are saved for subsequent mutation.</p><h1 id="What-are-the-innovation-s-proposed-in-this-paper"><a href="#What-are-the-innovation-s-proposed-in-this-paper" class="headerlink" title="What are the innovation(s) proposed in this paper?"></a>What are the innovation(s) proposed in this paper?</h1><p>The paper proposes Zest, a technique for automatically guiding QuickCheck-like random-input generators to exercise various code paths in the semantic analysis stages of programs. It first converts a QuickCheck-like random-input generator to a parametric generator, which can generate a syntactically valid input from a byte sequence. It then uses a coverage-guided fuzzing technique with the parametric generator in order to produce syntactically valid input that can increase code coverage in the semantic analysis stages.</p><h1 id="How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement"><a href="#How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement" class="headerlink" title="How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?"></a>How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?</h1><p>The authors integrated Zest into the open-source JQF framework and evaluated Zest on five real-world Java benchmarks, comparing it to QuickCheck and AFL. They evaluated the three techniques on two fronts:</p><ol><li>The amount of code coverage achieved in the semantic analysis stage after a fixed amount of time.</li><li>Their effectiveness in triggering bugs in the semantic analysis stage.</li></ol><p>QuickCheck and Zest make use of generators for synthesizing syntactically valid input, and do not exercise code paths corresponding to parse errors in the syntax analysis stage. In contrast, AFL performs mutations directly on raw input strings, and spends most of its time testing error paths within the syntax analysis stages.</p><p>The experimental results suggest that when given QuickCheck-like random-input generators, Zest excels at exercising semantic analyses and is very effective at discovering semantic bugs.</p><p>The paper’s evaluation matches well with the proposed problem statement, as the experimental design accurately assesses factors directly correlated with the problem of “generating random, syntactically valid inputs to exercise various code paths in the semantic analysis stages of programs and leveraging feedback to generate new inputs via mutations”, and the experimental results support the effectiveness of the proposed approach.</p><h1 id="Which-technical-innovations-are-most-compelling-to-you"><a href="#Which-technical-innovations-are-most-compelling-to-you" class="headerlink" title="Which technical innovations are most compelling to you?"></a>Which technical innovations are most compelling to you?</h1><p>The most compelling technical innovation is Zest’s design of generating a syntactically valid input from a byte sequence given a QuickCheck-like random-input generator, by using bytes from the byte sequence to “fill in” randomly generated primitive data types of various length (bool, char, int, etc.) required within the random-input generator. This allows bit-level mutations on byte sequences to correspond to high-level structural mutations in the space of syntactically valid inputs, enabling Zest to leverage the mature coverage-guided fuzzing algorithm originally designed for byte sequence inputs.</p><h1 id="What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper"><a href="#What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper" class="headerlink" title="What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?"></a>What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?</h1><p>The author states that the Zest algorithm “extends the CGF algorithm by keeping track of the coverage achieved by semantically valid inputs”, and that “we hypothesize that this biases the search towards generating even more valid inputs and in turn increases code coverage in the semantic analysis stage”. However, how semantically valid inputs are used is not stated in the description of the algorithm.</p><h1 id="Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper-If-so-how-could-these-barriers-be-overcome"><a href="#Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper-If-so-how-could-these-barriers-be-overcome" class="headerlink" title="Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper? If so, how could these barriers be overcome?"></a>Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper? If so, how could these barriers be overcome?</h1><p>Zest assumes the availability of QuickCheck-like random-input generators to exercise the semantic analysis classes and find semantic bugs, which may be unavailable for specialized data structures. There has also been some recent interest in automatically generating input grammars from existing inputs, using machine learning and language inference algorithms. These techniques are complementary to Zest - the grammars generated by these techniques could be transformed into parametric generators for Zest.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: How We Refactor, and How We Know It</title>
    <link href="/2022/10/10/Paper-Review-How-We-Refactor-and-How-We-Know-It/"/>
    <url>/2022/10/10/Paper-Review-How-We-Refactor-and-How-We-Know-It/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/TSE.2011.41">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward-How-was-the-work-validated"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward-How-was-the-work-validated" class="headerlink" title="What were the primary contributions of the paper as the author sees it? How does this work move the research forward? How was the work validated?"></a>What were the primary contributions of the paper as the author sees it? How does this work move the research forward? How was the work validated?</h1><p>In his book on refactoring, Fowler catalogs 72 different refactorings, ranging from localized changes to more global changes, and Fowler claims that refactoring produces significant benefits.</p><p>Although case studies have demonstrated that refactoring is a common practice and can improve code metrics, they tend to examine just a few software products.</p><p>To help put refactoring research on a sound scientific basis, we replicate the study in wider contexts and explore factors that previous authors may not have explored. We analyze four sets of Eclipse IDE usage data and apply different several different refactoring-detection strategies to them. We then use this data to test nine hypotheses about refactoring, casting doubt on several previously stated assumptions about how programmers refactor, while validating others.</p><ul><li>Refactoring behavior of refactoring tool developers differs from that of their users. Specifically, RENAMEs and MOVEs are more frequent among users.</li><li>About 40% of refactorings performed using a tool occur in batches (several refactorings of the same kind within a short time period).</li><li>About 90% of configuration defaults of refactoring tools remain unchanged when programmers use the tools.</li><li>messages written by programmers in commit logs do not reliably indicate the presence of refactoring.</li><li>Programmers frequently floss refactor (interleave refactoring with other types of programming activity).</li><li>About half of refactorings are not high-level, so refactoring detection tools that look exclusively for high-level<br>refactorings will not detect them.</li><li>Refactorings are performed frequently.</li><li>Almost 90% of refactorings are performed manually, and the kinds of refactorings performed with tools differ from the kinds performed manually.</li></ul><h1 id="How-could-this-research-be-extended-How-could-this-research-be-applied-in-practice"><a href="#How-could-this-research-be-extended-How-could-this-research-be-applied-in-practice" class="headerlink" title="How could this research be extended? How could this research be applied in practice?"></a>How could this research be extended? How could this research be applied in practice?</h1><p>For the toolsmith:</p><ul><li>Most kinds of refactorings will not be used as frequently as the toolsmiths hoped. Improving the under-used tools or their documentation may increase tool use.</li><li>Programmers often do not configure refactoring tools. Configuration-less refactoring tools, which have recently seen increasing support in Eclipse and other environments, will suit the majority of, but not all, refactoring situations.</li><li>30 refactorings did not have tool support, the most popular of these was MODIFY ENTITY PROPERTY, performed 8 times, which would allow developers to safely modify properties such as static or final.</li></ul><p>For researchers:</p><ul><li>Questions still remain to answer.<ul><li>Why is the RENAME refactoring tool so much more popular than other refactoring tools?</li><li>Why do some refactorings tend to be batched while others do not?</li></ul></li><li>Our experiments should be repeated in other projects and for other refactorings to validate our findings.</li></ul><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How does the work apply to you?"></a>What were the main contributions of the paper as you (the reader) see it? How does the work apply to you?</h1><p>Of particular interest to me is the inspiration for the hypothesis the authors verify - previous literature (frequently in other software engineering domains), personal experience, anecdotes from programmers, surveys. The benefit from this is twofold. First, it provides a source of inspiration for formulating hypotheses. Second, it endorses the validity of the hypotheses.</p><ul><li>We hypothesize refactoring behavior of refactoring tool developers differs from that of their users. Toleman and Welsh assume a variant of this hypothesis - that the designers of software tools erroneously consider themselves typical tool users - and argue that the usability of software tools should be objectively evaluated.</li><li>We hypothesize that programmers typically perform refactoring in batches. Based on personal experience and anecdotes from programmers, we suspect that programmers often refactor several pieces of code because several related program elements may need to be refactored in order to perform a composite refactoring. In previous research, Murphy-Hill and Black built a refactoring tool that supported refactoring several program elements at once, on the assumption that this is common.</li><li>We hypothesize that programmers do not often configure refactoring tools. We suspect this because tweaking code manually after the refactoring may be easier than configuring the tool. In the past, we have found some limited evidence that programmers perform only a small amount of configuration of refactoring tools. When we did a small survey in September 2007 at a Portland Java Users Group meeting, 8 programmers estimated that, on average, they supply configuration information only 25% of the time.</li><li>In Xing and Stroulia’s automated analysis of the Eclipse codebase, the authors conclude that “indeed refactoring is a frequent practice”. Although flawed, this becomes one of the authors’ hypotheses.</li></ul><p>Furthermore, some hypotheses are formed from a critique of previous literature, combined with domain expertise and&#x2F;or other literature.</p><ul><li>Several researchers have used messages attached to commits into a version control as indicators of refactoring activity. However, we hypothesize that this assumption is false, because refactoring may be an unconscious activity, and because the programmer may consider it subordinate to some other activity, such as adding a feature.</li><li>Past research has often drawn conclusions based on observations of high-level refactorings. We hypothesize that in practice programmers also perform many lower-level refactorings. We suspect this because lower-level refactorings will not change the program’s interface and thus programmers may feel more free to perform them.</li></ul><p>Additionally, much of the methodology presented in this paper can be borrowed.</p><ul><li>The fourth dataset used by the authors is Eclipse CVS, the version history of the Eclipse and JUnit code bases extracted from their Concurrent Versioning System (CVS) repositories. CVS does not maintain records showing which file revisions were committed as a single transaction. The standard approach for recovering transactions is to find revisions committed by the same developer with the same commit message within a small time window; we use a 60 second time window. In our experiments, we randomly sampled from about 3400 source file commits that correspond to the same time period, the same projects, and the same developers represented in Toolsmiths. Using these data, two of the authors inferred which refactorings were performed by comparing adjacent commits manually.</li><li>Ratzinger describes the most sophisticated strategy for finding refactoring messages: searching for the occurrence of keywords such as “move” and “rename”, and excluding “needs refactoring”. We replicated Ratzinger’s experiment for the Eclipse code base to nullify Ratzinger’s conclusions.</li><li>In order for refactoring activity to be defined as frequent, we seek to apply criteria that require refactoring to be habitual and occurring at regular intervals. First, we examined the Toolsmiths data to determine how refactoring activity was spread throughout development. Second, we examined the Users data to determine how often refactoring occurred within a programming session and whether there was significant variation among the population.</li><li>We hypothesize that programmers often do not use refactoring tools, because existing tools may not have a sufficiently usable user-interface. To validate this hypothesis, we correlated the refactorings that we observed by manually inspecting Eclipse CVS commits with the refactoring tool usages in the Toolsmiths data set.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: &quot;Cloning Considered Harmful: Considered Harmful</title>
    <link href="/2022/10/05/Paper-Review-Cloning-Considered-Harmful-Considered-Harmful/"/>
    <url>/2022/10/05/Paper-Review-Cloning-Considered-Harmful-Considered-Harmful/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/WCRE.2006.1">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-was-the-work-validated"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-was-the-work-validated" class="headerlink" title="What were the primary contributions of the paper as the author sees it? How was the work validated?"></a>What were the primary contributions of the paper as the author sees it? How was the work validated?</h1><p>Current literature on the topic of duplicated code in software systems often considers duplication harmful to the system quality, and the reasons commonly cited for duplicating code often have a negative connotation.</p><p>While these positions are sometimes correct, during our case studies we have found that this is not universally true, and we have found several situations where code duplication seems to be a reasonable or even beneficial design option.</p><p>This paper introduces eight cloning patterns that we have uncovered during case studies on large software systems, and discusses the advantages and disadvantages associated with using them.</p><ul><li>Forking, cloning used to bootstrap development of similar solutions, with the expectation that evolution of the code will occur somewhat independently<ul><li>Hardware variation</li><li>Platform variation</li><li>Experimental variation</li></ul></li><li>Templating, directly copy behavior of existing code but appropriate abstraction mechanisms are unavailable<ul><li>Boiler-plating due to language in-expressiveness</li><li>API&#x2F;Library protocols</li><li>General language or algorithmic idioms</li></ul></li><li>Customization, currently existing code does not adequately meet a<br>new set of requirements<ul><li>Bug workarounds</li><li>Replicate and specialize</li></ul></li></ul><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-this-work-move-the-research-forward-How-could-this-research-be-extended"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-this-work-move-the-research-forward-How-could-this-research-be-extended" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How does this work move the research forward? How could this research be extended?"></a>What were the main contributions of the paper as you (the reader) see it? How does this work move the research forward? How could this research be extended?</h1><p>This paper introduces the notion of categorizing high level patterns of cloning in a similar fashion to the cataloging of design patterns or anti-patterns. There are several benefits that can be gained from this characterization.</p><ol><li>It provides a flexible framework on top of which we can document our knowledge about how and why cloning occurs in software. This documentation crystallizes a vocabulary that researchers and practitioners can possibly use to communicate about cloning.</li><li>This categorization is a first step towards formally defining these patterns to aid in automated detection and classification. These classifications can then be used to define metrics concerning code quality and maintenance efforts. Automatic classifications will also provide us with better measures of code cloning in software systems and severity of the problem in general.</li></ol><h1 id="How-could-this-research-be-applied-in-practice"><a href="#How-could-this-research-be-applied-in-practice" class="headerlink" title="How could this research be applied in practice?"></a>How could this research be applied in practice?</h1><p>In each uncovered cloning pattern, the author describes its advantages, disadvantages, how it can be managed, issues to be aware of when deciding to use it as a long-term solution, as well as real examples in large software systems. These provide practical guidelines when considering a trade-off between code cloning and formulating abstractions for code reuse, as well as how to manage code cloning should it be used, when developing a software project.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Go To Statement Considered Harmful</title>
    <link href="/2022/10/04/Paper-Review-Go-To-Statement-Considered-Harmful/"/>
    <url>/2022/10/04/Paper-Review-Go-To-Statement-Considered-Harmful/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">here</a>.</p><p>The author has been familiar with the observation that the quality of programmers is a decreasing function of the density of go to statements in the programs they produce, and in this paper, he explains why the use of the go to statement has negative effects.</p><p>He first remarks that the process taking place under control of the program, instead of the program itself, is the true subject matter of a programmer’s activity, and it is this process whose behavior has to satisfy the desired specifications. He then argues that our intellectual powers can better master static relations than visualize processes evolving in time, for which reason we should shorten the conceptual gap between the static program and the dynamic progress. The author continues characterizing the progress of a progress, explaining that it can be uniquely characterized by a mixed sequence of textual and&#x2F;or dynamic indices, when conditionals, procedures, and repetition clauses are considered. However, the unbridled use of the go to statement has an immediate consequence that it becomes terribly hard to find a meaningful set of coordinates in which to describe the process progress, which will in turn “make a mess of one’s program”. </p><p>However, in my opinion, although the go to statement is considered harmful, abolishing the go to statement from all “higher level” programming languages is an overstatement. As the author himself stated:</p><ul><li>The exercise to translate an arbitrary flow diagram more or less mechanically into a jump-less one, is not to be recommended. Then the resulting flow diagram cannot be expected to be more transparent than the original one.</li></ul><p>There exist situations where an “arbitrary flow diagram” has to be implemented (especially when implementing Finite-State Machines in lexers, regex engines, and protocols), and in these situations, implementing the flow diagram using go to statements is much more direct, straightforward and easier to reason about (not to mention more efficient) than mashing up structured programming constructs.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: KLEE: unassisted and automatic generation of high-coverage tests for complex systems programs</title>
    <link href="/2022/10/04/Paper-Review-KLEE-unassisted-and-automatic-generation-of-high-coverage-tests-for-complex-systems-programs/"/>
    <url>/2022/10/04/Paper-Review-KLEE-unassisted-and-automatic-generation-of-high-coverage-tests-for-complex-systems-programs/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://www.usenix.org/legacy/event/osdi08/tech/full_papers/cadar/cadar.pdf">here</a>.</p><h1 id="What-is-the-problem-being-tackled-How-was-it-addressed-by-prior-work"><a href="#What-is-the-problem-being-tackled-How-was-it-addressed-by-prior-work" class="headerlink" title="What is the problem being tackled? How was it addressed by prior work?"></a>What is the problem being tackled? How was it addressed by prior work?</h1><p>Many classes of errors are difficult to find without executing a piece of code. The importance of such testing, combined with the difficulty and poor performance of random and manual approaches, has led to much work in <strong>using symbolic execution to automatically generate test inputs</strong>.</p><p>It has been an open question whether the approach has any hope of consistently achieving high coverage on real applications, facing the challenges in handling code that interacts with the environment, and the exponential number of paths through code.</p><p>Traditional symbolic execution systems either cannot handle programs interacting with the environment or require a complete working model. More recent work in test generation does allow external interactions, but forces them to use entirely concrete procedure call arguments, which limits the behaviors they can explore.</p><p>For the path explosion problem, search strategies proposed in the past include Best First Search, Generational Search, and Hybrid Concolic Testing. Orthogonal to search heuristics, researchers have addressed the path explosion problem by testing paths compositionally, and by tracking the values read and written by the program.</p><h1 id="What-are-the-innovation-s-proposed-in-this-paper-Which-technical-innovations-are-most-compelling-to-you"><a href="#What-are-the-innovation-s-proposed-in-this-paper-Which-technical-innovations-are-most-compelling-to-you" class="headerlink" title="What are the innovation(s) proposed in this paper? Which technical innovations are most compelling to you?"></a>What are the innovation(s) proposed in this paper? Which technical innovations are most compelling to you?</h1><p>KLEE interprets programs compiled to LLVM IR, and typically requires no source modification. It functions as a hybrid between an operating system for symbolic processes and an interpreter. Each symbolic process has a register file, stack, heap, program counter, and path condition. Unlike a normal process, storage locations for a symbolic process - registers, stack and heap objects - refer to expression trees instead of raw data values. The leaves of an expression are symbolic variables or constants, and the interior nodes come from LLVM IR operations.</p><p>Conditional branches take a boolean expression and alter the instruction pointer of the symbolic process based on whether the condition is true or false. KLEE queries the constraint solver to determine if the branch condition is either provably true or false along the current path. If so, the instruction pointer is updated to the appropriate location. Otherwise, both branches are possible. KLEE forks the symbolic process so that it can explore both paths.</p><p>The number of forked symbolic processs grows quite quickly in practice. KLEE implements the heap as an immutable map, and portions of the heap structure itself can also be shared amongst multiple symbolic processs. Additionally, this heap structure can be forked in constant time, which is important given the frequency of this operation.</p><p>Potentially dangerous operations implicitly generate branches that check if any input value exists that could cause an error. For example, a division instruction generates a branch that checks for a zero divisor. If so, KLEE solves the current path’s constraints to produce a test case that will follow the same path when rerun on an unmodified version of the checked program, and terminates the current symbolic process. KLEE will then continue execution on the false path, which adds the negation of the check as a constraint (e.g., making the divisor not zero).</p><p>The core of KLEE is an interpreter loop which selects a symbolic process to run and then symbolically executes a single instruction in the context of that symbolic process. Given more than one symbolic process, KLEE must pick which one to execute first. KLEE selects the symbolic process to run at each instruction by uses each strategy in a round robin fashion.</p><ul><li>Random Path Selection: Use a binary tree to record the program path followed for all active symbolic processs. A symbolic process is selected by traversing this tree from the root and randomly selecting the path to follow at branch points. This strategy has two important properties.<ul><li>Favors symbolic processs high in the branch tree. They have less constraints on their symbolic inputs and have greater freedom to reach uncovered code.</li><li>Avoids starvation when some part of the program is rapidly creating new symbolic processs (“fork bombing”) as it happens when a tight loop contains a symbolic condition.</li></ul></li><li>Coverage-Optimized Search: Select symbolic processs likely to cover new code in the immediate future using heuristics.</li></ul><p>This loop continues until there are no symbolic processs remaining, or a user-defined timeout is reached.</p><p>KLEE ensures that a symbolic process which frequently executes expensive instructions will not dominate execution time by running each symbolic process for a “time slice” defined by both a maximum number of instructions and a maximum amount of time.</p><p>KLEE uses STP as its constraint solver. KLEE maps every memory object in the checked code to a distinct STP array. This representation dramatically improves performance since it lets STP ignore all arrays not referenced by a given expression. Furthermore, there are tricks to simplify expressions and ideally eliminate queries before they reach STP, including:</p><ul><li>Expression Rewriting</li><li>Constraint Set Simplification</li><li>Implied Value Concretization</li><li>Constraint Independence</li><li>Counter-example Cache: Redundant queries are frequent, and a simple cache is effective at eliminating a large number of them. However, it is possible to build a more sophisticated cache due to the particular structure of constraint sets. The counter-example cache maps sets of constraints to counter-examples (i.e., variable assignments), along with a special sentinel used when a set of constraints has no solution. <strong>This mapping is stored in a custom data structure — derived from the UBTree structure of Hoffmann and Hoehler, which allows efficient searching for cache entries for both subsets and supersets of a constraint set.</strong> By storing the cache in this fashion, the counter-example cache gains three additional ways to eliminate queries.<ul><li>When a subset of a constraint set has no solution, then neither does the original constraint set.</li><li>When a superset of a constraint set has a solution, that solution also satisfies the original constraint set.</li><li>When a subset of a constraint set has a solution, it is likely that this is also a solution for the original set.</li></ul></li></ul><p>KLEE handles the environment by redirecting library calls to models that understand the semantics of the desired action well enough to generate the required constraints. The real environment can fail in unexpected ways. Such failures can often lead to unexpected and hard to diagnose bugs. To help catch such errors, KLEE will optionally simulate environmental failures by failing system calls in a controlled manner.</p><h1 id="How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement"><a href="#How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement" class="headerlink" title="How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?"></a>How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?</h1><p>Four sets of experiments are conducted.</p><ul><li>We do intensive runs to both get high coverage and find bugs on Coreutils and BusyBox tools, do a comparision with random tests and developer test suites, and discuss the bugs found.</li><li>To demonstrate KLEE’s applicability to bug finding, we used KLEE to check all 279 BusyBox tools and 84 MINIX tools in a series of short runs.</li><li>Thus far, we have focused on finding generic errors that do not require knowledge of a program’s intended behavior. We now show how to do much deeper checking, including verifying full functional correctness on a finite set of explored paths. We use KLEE to find deep correctness errors by cross-checking purportedly equivalent Coreutils and BusyBox tool implementations.</li><li>We have also applied KLEE to checking non-application code by using it to check the HiStar kernel.</li></ul><p>We chose line coverage as reported by gcov as a conservative measure of KLEE-produced test case effectiveness, because it is widely-understood and uncontroversial.</p><p>The results of the experiments are very positive, and convincingly prove the proposed problem statement.</p><h1 id="What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper"><a href="#What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper" class="headerlink" title="What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?"></a>What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?</h1><p>Coverage-Optimized Search tries to select symbolic processs likely to cover new code in the immediate future. It uses heuristics to compute a weight for each symbolic process and then randomly selects a symbolic process according to these weights. How these heuristics work, which is critical for performance, is not symbolic processd, and remains unclear.</p><p>KLEE ensures that a symbolic process which frequently executes expensive instructions will not dominate execution time by running each symbolic process for a “time slice” defined by both a maximum number of instructions and a maximum amount of time. Precisely how this “time slice” is calculated is also unclear.</p><p>KLEE handles the environment by redirecting library calls to models that understand the semantics of the desired action well enough to generate the required constraints. These models are written in normal C code which the user can readily customize, extend, or even replace without having to understand the internals of KLEE. However, what “understand the semantics of the desired action well enough” means is unclear.</p><h1 id="Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper"><a href="#Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper" class="headerlink" title="Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper?"></a>Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper?</h1><p>KLEE does not currently support symbolic floating point, longjmp, threads, and assembly code. Additionally, memory objects<br>are required to have concrete sizes. These block KLEE’s application towards floating point-heavy scientific computation and data science code, and may also limit KLEE to simple programming languages such as C, not supporting the numerous dynamics, including exception handling, within C++.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: CUTE: A Concolic Unit Testing Engine for C</title>
    <link href="/2022/10/02/Paper-Review-CUTE-A-Concolic-Unit-Testing-Engine-for-C/"/>
    <url>/2022/10/02/Paper-Review-CUTE-A-Concolic-Unit-Testing-Engine-for-C/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/1095430.1081750">here</a>.</p><p><strong>NOTE: I believe the paper to be written very obscurely, so I will explain the ideas of the paper in my own words.</strong></p><h1 id="What-is-the-problem-being-tackled-How-was-it-addressed-by-prior-work"><a href="#What-is-the-problem-being-tackled-How-was-it-addressed-by-prior-work" class="headerlink" title="What is the problem being tackled? How was it addressed by prior work?"></a>What is the problem being tackled? How was it addressed by prior work?</h1><p>Unit testing is a method for modular testing of a program’s functional behavior. Such testing requires specification of values for the inputs (or test inputs) to the unit. Manual specification of such values is labor intensive and cannot guarantee that all possible behaviors of the unit will be observed during the testing. </p><p>Several techniques have been proposed to automatically generate values for the inputs.</p><ul><li>Randomly choose the values over the domain of potential inputs<ul><li>Many values may lead to the same behavior and are redundant.</li><li>The probability of selecting inputs causing buggy behavior may be astronomically small.</li></ul></li><li>Symbolic Exection<ul><li>Addresses the problem of redundant executions and increases test coverage</li><li>For large or complex units, it is intractable to maintain and solve the constraints required for test generation</li></ul></li><li>Incrementally generating test inputs by combining concrete and symbolic execution<ul><li>During a concrete execution, a conjunction of symbolic constraints along the path of execution is generated. These constraints are modified and then solved to generate further test inputs to direct the program along alternative paths. If it is not feasible to solve, simply substitute random concrete values.</li><li>This problem is particularly complex for programs with dynamic data structures using pointer operations. Pointers may have aliases.</li></ul></li></ul><p>In this paper, we provide a method for representing and solving approximate pointer constraints to generate test inputs. Our method is thus applicable to a broad class of sequential programs.</p><h1 id="What-are-the-innovation-s-proposed-in-this-paper-Which-technical-innovations-are-most-compelling-to-you"><a href="#What-are-the-innovation-s-proposed-in-this-paper-Which-technical-innovations-are-most-compelling-to-you" class="headerlink" title="What are the innovation(s) proposed in this paper? Which technical innovations are most compelling to you?"></a>What are the innovation(s) proposed in this paper? Which technical innovations are most compelling to you?</h1><p>We consider the execution of a function to be determined by <strong>all the stack variables, global variables, and heap objects</strong> it exercises.</p><ul><li>Only primitive types and pointer types are taken into consideration.</li><li>For structures and arrays, each member is considered to be a separate variable.</li><li>External OS services are not modelled.</li></ul><p>We associate the following <strong>properties</strong> with each stack variable, global variable, and heap object.</p><ul><li>Concrete Value</li><li>Symbolic Value</li><li>Concrete Address</li><li>Symbolic Address</li></ul><p>The branches taken within an execution can be described with a predicate sequence called a <strong>path constraint</strong>.</p><ul><li>Each predicate is described using the aforementioned stack variables, global variables, and&#x2F;or heap objects.</li><li>Symbolic values are used when available, otherwise, concrete values are used.</li><li>Predicates involving primitive types are of the form $a_1 x_1 + \dots + a_n x_n + c<del>R</del>0, R \in {&lt;, &gt;, \le, \ge, &#x3D;, \ne}$, where $a_i, \dots, a_n, c$ are integer constants. (Essentially considers only linear combinations of primitive types)</li><li>Predicates involving pointers are of the form $x<del>R</del>y$ or $x<del>R</del>NULL$, $R \in {&#x3D;, \ne}$. (Essentially considers only being able to assign to a pointer NULL or another previously known address, and does not allow converting integers to pointers)</li></ul><p>Running process of CUTE.</p><ul><li><p>while True:</p><ul><li>Execute, in the process:<ul><li>When <strong>allocating</strong> a stack variable, global variable, or heap object <strong>without initialization</strong> (incl. function parameters):<ul><li>Modify “known stack variables, global variables, and heap objects” if needed.</li><li>If its concrete value has been stored, initialize it to its stored concrete value. Otherwise, generate a random concrete value for it.</li><li>Record its concrete value and concrete address.</li></ul></li><li>When <strong>allocating</strong> a stack variable, global variable, or heap object <strong>with initialization</strong>:<ul><li>Modify “known stack variables, global variables, and heap objects” if needed.</li><li>Record its concrete value and concrete address.</li><li>Record its symbolic value and symbolic address.</li></ul></li><li>When <strong>assigning</strong> an existing stack variable, global variable, or heap object:<ul><li>Update its concrete value.</li><li>Update its symbolic value.</li></ul></li><li>When <strong>taking a branch</strong>, add a new predicate to the path constraint.</li></ul></li><li>After execution, <strong>negate the last predicate within the path constraint</strong>, and <strong>solve for the concrete values of “stack variables, global variables, and heap objects allocated without initialization”</strong>. Update their recorded concrete values.<ul><li>Solving optimizations:<ul><li>Check if the last predicate is syntactically the negation of any preceding predicate</li><li>Identify and eliminate common arithmetic subconstraints.</li><li>Identify dependencies between predicates and exploit them. The path constraints from two consecutive concolic executions, $C$ and $C’$ differ only in a small number of predicates, and their respective solutions are similar. The solver collects all the predicates in C that are dependent on the negation of the last and solves for them. In practice, we have found that the size of this set is almost one eighth the size of $C$ on average.</li></ul></li></ul></li></ul></li><li><p>Generated random concrete values:</p><ul><li>Primitive Type: random number</li><li>Pointer Type: NULL</li></ul></li></ul><p>We next consider <strong>testing of functions that take data structures as inputs</strong>. We want to test such functions with valid inputs only. There are two main approaches to obtaining valid inputs:</p><ul><li>Generating inputs with call sequences</li><li><strong>Use the functions that check if an input is a valid data structure by solving them</strong>, i.e., generating input for which they return true. Previous techniques include a search that uses purely concrete execution and a search that uses symbolic execution for primitive data but concrete values for pointers. CUTE, in contrast, uses symbolic execution for both primitive data and pointers. This allows it to solve these functions asymptotically faster than the fastest previous techniques.</li></ul><h1 id="How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement"><a href="#How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement" class="headerlink" title="How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?"></a>How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?</h1><p>We illustrate two case studies that show how CUTE can detect errors.</p><ol><li>We applied CUTE to test its own data structures. Our goal in this case study was to detect memory leaks in addition to standard errors such as segmentation faults, assertion violation etc.</li><li>We also applied CUTE to unit test SGLIB version 1.0.1, a popular, open-source C library for generic data structures. We chose SGLIB as a case study primarily to measure the efficiency of CUTE. We found two bugs in SGLIB using CUTE.</li></ol><p>The case studies showcase the power of CUTE’s concolic unit testing approach, and match well with the proposed problem statement.</p><h1 id="What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper"><a href="#What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper" class="headerlink" title="What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?"></a>What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?</h1><p>After execution, negate the last predicate within the path constraint, and solve for the concrete values of “stack variables, global variables, and heap objects allocated without initialization”. A solving optimization that the author proposed is “identifing and eliminating common arithmetic subconstraints”. However, how this is done is not explained.</p><h1 id="Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper"><a href="#Which-problems-remain-unsolved-after-this-paper-Do-you-foresee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper" class="headerlink" title="Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper?"></a>Which problems remain unsolved after this paper? Do you foresee any barriers to the applicability of the technique proposed in the paper?</h1><ul><li>For structures and arrays, each member is considered to be a separate variable. Although this facilicates analysis, this could incur significant overhead and impede scalability.</li><li>External OS services are not modelled. </li><li>Predicates involving primitive types are of the form $a_1 x_1 + \dots + a_n x_n + c<del>R</del>0, R \in {&lt;, &gt;, \le, \ge, &#x3D;, \ne}$, where $a_i, \dots, a_n, c$ are integer constants. This essentially considers only linear combinations of primitive types.</li><li>The author shows preference to using the technique of “using the functions that check if an input is a valid data structure by solving them” to solve the problem of testing of functions that take data structures as inputs. However, such an approach may be impossible for object-oriented languages such as C++, in which data structures are encapsulated in classes, and the logic of validness is enforced with the constructor and public methods of the classes.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Selection and Presentation Practices for Code Example Summarization</title>
    <link href="/2022/09/28/Paper-Review-Selection-and-Presentation-Practices-for-Code-Example-Summarization/"/>
    <url>/2022/09/28/Paper-Review-Selection-and-Presentation-Practices-for-Code-Example-Summarization/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1145/2635868.2635877">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward-How-could-this-research-be-applied-in-practice"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward-How-could-this-research-be-applied-in-practice" class="headerlink" title="What were the primary contributions of the paper as the author sees it? How does this work move the research forward? How could this research be applied in practice?"></a>What were the primary contributions of the paper as the author sees it? How does this work move the research forward? How could this research be applied in practice?</h1><p>Code examples are important in modern software development. As part of the first steps toward automatic source-to-source summarization, the authors studied how humans summarize examples to understand how to automate the process, and propose empirically-supported hypotheses justifying the use of specific practices.</p><p>Selection Practices</p><ul><li>Practices Related to Language Constructs</li><li>Practices Based on Query Term</li><li>Practices Considering the Human Reader<br>Presentation Practices</li><li>Trimming a Line When Needed</li><li>Compressing a Large Amount of Code</li><li>Truncating Code</li><li>Formatting Code for Readability</li><li>Improving Code</li></ul><p>The results provide a grounded basis for the development of code example summarization and presentation technology.</p><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><p>We chose a well-defined corpus of programming documents, The Official Android API Guides, which contains a mix of natural-language text and code fragments.</p><p>We collected 156 pairs of code examples and their summaries from 16 participants, along with over 26 hours of think-aloud verbalizations detailing the decisions of the participants during their summarization activities. We analyzed common practices behind these decisions across the hand-generated representations, as well as the rationale behind the practices.</p><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it?"></a>What were the main contributions of the paper as you (the reader) see it?</h1><p>In my opinion, aside from the obvious contributions of the paper presented by the author, there is a lot to learn from the study set-up and the conceptual framework for interpreting the results.</p><ol><li>To understand the rationale behind the practices, we instructed the participants to verbalize their thought process using the think-aloud protocol.</li><li>We distinguished practices concerning the type of content selected and the way the content was presented in a summary, because even summaries with content associated with the same part of the original fragment could vary on how to present the summary.</li><li>To make hypotheses justifying the use of different practices, we relied on a quantitative analysis of the distribution of each practice across code fragments and participants. In-lined histograms presents the distribution of observations of a given practice for the participants over the code fragments. This provides a convenient and compact assessment of the amount of evidence for a practice.</li></ol><p>Furthermore, the authors have borrowed a lot from related domains of research, including natural language generation, natural language summarization of code, etc. Some examples:</p><ol><li>The separation of content selection from presentation is typical in a natural language generation system.</li><li>The comments demonstrated a number of different ways to abstract content, including aggregating lexically and aggregating semantically - natural language generation terminology.</li><li>Seven participants injected additional natural language into the code summaries. This motivates a novel type of transformations that mix code and text. The only work we know of in this area is the natural summaries generated by Rastkar et al.</li></ol><p>This gives revelations on exploiting knowledge from related domains when doing our own research.</p><h1 id="How-could-this-research-be-extended"><a href="#How-could-this-research-be-extended" class="headerlink" title="How could this research be extended?"></a>How could this research be extended?</h1><p>The goal of the study was to inform the design of concise representations of source code and automatic summarization algorithms. A natural future direction is to implement these representations and algorithms, and conduct empirical studies assessing their usefulness in summarizing source code.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Finding and Understanding Bugs in C Compilers</title>
    <link href="/2022/09/24/Paper-Review-Finding-and-Understanding-Bugs-in-C-Compilers/"/>
    <url>/2022/09/24/Paper-Review-Finding-and-Understanding-Bugs-in-C-Compilers/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/1993316.1993532">here</a>.</p><h2 id="What-is-the-problem-being-tackled"><a href="#What-is-the-problem-being-tackled" class="headerlink" title="What is the problem being tackled?"></a>What is the problem being tackled?</h2><p>Finding compiler bugs, especially bugs in the “middle end” of a compiler that performs transformations on an intermediate representation, to improve the quality of C compilers.</p><h2 id="How-was-it-addressed-by-prior-work"><a href="#How-was-it-addressed-by-prior-work" class="headerlink" title="How was it addressed by prior work?"></a>How was it addressed by prior work?</h2><p>Compilers have been tested using randomized methods for nearly 50 years.</p><p>In 1998, McKeeman coined the term “differential testing”. His work resulted in DDT, a family of program generators that conform to the C standard at various levels. However, DDT avoided only a small subset of all undefined behaviors, and only then during test-case reduction, not during normal testing. Thus, it is not a suitable basis for automatic bug-finding.</p><p>Lindig used randomly generated C programs to find several compiler bugs related to calling conventions. His tests are self-checking, but far less expressive than Csmith.</p><p>Sheridan also used a random generator to find bugs in C compilers. Sheridan’s tool produces self-checking tests. However, it is less expressive than Csmith and it fails to avoid undefined behavior such as signed overflow.</p><p>Zhao et al. created an automated program generator for testing an embedded C++ compiler, which allows a general test requirement, such as which optimization to test, to be specified.</p><h2 id="What-are-the-innovation-s-proposed-in-this-paper"><a href="#What-are-the-innovation-s-proposed-in-this-paper" class="headerlink" title="What are the innovation(s) proposed in this paper?"></a>What are the innovation(s) proposed in this paper?</h2><p>The paper proposes Csmith, a randomized test-case generation tool which generates programs that cover a large subset of C while avoiding the undefined and unspecified behaviors that would destroy its ability to automatically find wrong-code bugs. This advances the state of the art in compiler testing.</p><p>Csmith supports compiler bug-hunting using differential testing. Csmith generates a C program, a test harness then compiles the program using several compilers, runs the executables, and compares the outputs.</p><h2 id="How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement"><a href="#How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement" class="headerlink" title="How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?"></a>How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?</h2><p>The authors conducted five experiments.</p><ol><li>Finding and reporting bugs in a a variety of C compilers over a three-year period. They have found and reported more than 325 bugs in mainstream C compilers including GCC, LLVM, and commercial tools.</li><li>Compiling and running one million random programs using several years’ worth of versions of GCC and LLVM, to understand how their robustness is evolving over time.</li><li>Evaluating Csmith’s bug-finding power as a function of the size of the generated C programs.</li><li>Comparing Csmith’s bug-finding power to that of four<br>previous random C program generators.</li><li>Investigating the effect of testing random programs on branch, function, and line coverage of the GCC and LLVM source code.</li></ol><p>The experiments thoroughly evaluate and demonstrate Csmith’s bug-finding power and provide guidelines for using Csmith to find bugs.</p><h2 id="Which-technical-innovations-are-most-compelling-to-you"><a href="#Which-technical-innovations-are-most-compelling-to-you" class="headerlink" title="Which technical innovations are most compelling to you?"></a>Which technical innovations are most compelling to you?</h2><p>Csmith uses randomized differential testing. This has the advantage that no oracle for test results is needed. It exploits the idea that if one has multiple, deterministic implementations of the same specification, all implementations must produce the same result from the same valid input. When two implementations produce different outputs, one of them must be faulty. Given three or more implementations, a tester can use voting to heuristically determine which implementations are wrong.</p><p>How Csmith designs the results used for differential testing is also worthwhile. A Csmith-generated program prints a value summarizing the computation performed by the program, which is implemented as a checksum of the program’s non-pointer global variables at the end of the program’s execution. Thus, if changing the compiler or compiler options causes the checksum emitted by a Csmith-generated program to change, a compiler bug has been found.</p><p>Also compelling are the mechanisms that Csmith uses to avoid generating C programs that execute undefined behaviors or depend on unspecified behaviors, including performing incremental pointer and dataflow analysis in the process of generating programs.</p><h2 id="What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper"><a href="#What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper" class="headerlink" title="What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?"></a>What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper?</h2><p>In the process of randomly generating programs, Csmith randomly selects an allowable production from its grammar for the current program point. To make the choice, it consults a probability table and a filter function specific to the current point: there is a table&#x2F;filter pair for statements, another for expressions, and so on. The table assigns a probability to each of the alternatives, where the sum of the probabilities is one.</p><p>However, how this probability table is constructed and maintained, which obviously is critical to generating high-quality random programs, is not stated in the paper, and requires clarification.</p><h2 id="Do-you-forsee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper-If-so-how-could-these-barriers-be-overcome-Which-problems-remain-unsolved-after-this-paper"><a href="#Do-you-forsee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper-If-so-how-could-these-barriers-be-overcome-Which-problems-remain-unsolved-after-this-paper" class="headerlink" title="Do you forsee any barriers to the applicability of the technique proposed in the paper? If so, how could these barriers be overcome? Which problems remain unsolved after this paper?"></a>Do you forsee any barriers to the applicability of the technique proposed in the paper? If so, how could these barriers be overcome? Which problems remain unsolved after this paper?</h2><p>The most important language features not currently supported by Csmith are strings, dynamic memory allocation, floating-point types, unions, recursion, and function pointers. These are language features that are ubiquitous in real-world programs, thus, not supporting them is a serious barrier to the applicability of Csmith. The authors plan to add some of these features to future versions of our tool.</p><p>Although Csmith-generated programs allowed discovering bugs missed by compilers’ standard test suites, branch, function, and line coverage of the GCC and LLVM source code did not significantly improve compared to the compilers’ existing test suites. ‘Coverage-guided’ fuzzing may represent a future direction of research to discover more bugs lurking in unvisited sections of compiler source code.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges</title>
    <link href="/2022/09/22/Paper-Review-Do-Automatically-Generated-Unit-Tests-Find-Real-Faults-An-Empirical-Study-of-Effectiveness-and-Challenges/"/>
    <url>/2022/09/22/Paper-Review-Do-Automatically-Generated-Unit-Tests-Find-Real-Faults-An-Empirical-Study-of-Effectiveness-and-Challenges/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/ASE.2015.86">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-could-this-research-be-applied-in-practice"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-could-this-research-be-applied-in-practice" class="headerlink" title="What were the primary contributions of the paper as the author sees it? How could this research be applied in practice?"></a>What were the primary contributions of the paper as the author sees it? How could this research be applied in practice?</h1><p>The paper conducts an empirical study of the effectiveness and challenges of automatically generated unit tests at finding real faults, and derive insights to support the development of automated unit test generators that achieve a higher fault detection rate.</p><ol><li>Improving the obtained code coverage so that faulty statements are executed in the first instance.</li><li>A high code coverage ratio does not necessarily indicate that the bug was covered. Improving the propagation of faulty program states to an observable output, coupled with the generation of more sensitive assertions, is also required.</li><li>Improving the simulation of the execution environment to detect faults that are dependent on external factors such as date and time.</li></ol><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><p>The authors applied three state-of-the art unit test generation tools for Java (Randoop, EvoSuite, and Agitar) to the 357 real faults in the Defects4J dataset and investigated how well the generated test suites perform at detecting these faults.</p><ol><li>To account for randomness in test generation, we generated 10 test suites for each tool and fault.</li><li>Tools may generate flaky tests, which may also fail on the fixed version. They are automatically removed.</li><li>Even if a test is not flaky, it might still fail on the buggy version for reasons unrelated to the actual fault. Such false positives are identified.</li><li>For each executed test, we collected information on whether it passed or failed, and the reason of failure.</li><li>In order to study how code coverage relates to fault detection, we measured statement coverage, and also bug coverage - whether a fault was 1) fully covered (all modified statements covered), 2) partially covered (some modified statements covered), or 3) not covered.</li></ol><p>To gain insights on how to increase the fault detection rate of test generation tools, the authors did case studies on the challenges that prevent fault detection, and studied the root causes for flaky and false-positive tests.</p><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you-How-could-this-research-be-extended"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you-How-could-this-research-be-extended" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How does the work apply to you? How could this research be extended?"></a>What were the main contributions of the paper as you (the reader) see it? How does the work apply to you? How could this research be extended?</h1><p>The revelations from the case studies supporting the primary contributions of the paper as the author sees it are particularly important, as they identify specific challenges and provide plausible solutions for increasing the fault detection rate of test generation tools.</p><p>Creation of complex objects, such as a control flow graph, which often requires a certain sequence of prior method calls. Viable solutions include seeding objects observed at runtime, mining of common usage patterns of objects to guide object creation, or carving of complex object states from system tests.</p><p>Complex strings satisfying a certain syntax. Search-based tools are capable in principle of generating string inputs, but doing so can take very long. Symbolic approaches using string solvers or dedicated solvers for regular expressions are generally restricted to fixed length strings. If an input grammar is known, this can be used to generate test data more efficiently.</p><p>Complex conditions which randomly initialized inputs are unlikely to satisfy. Dynamic symbolic execution would not suffer from this problem.</p><p>Errors are not propagated. To some extent, this is the result of focusing on simple structural criteria such as branch coverage, rather than aiming to exercise more complex intra-class data flow dependencies.</p><p>Environmental dependencies and dependencies on the static state of the system under test resulting in flaky tests.</p><p>Aggressive mocking, which monitors and asserts on the internal state (e.g. the order of method calls) of the class under test, rather than testing the class on what its public method returns, and its side effects.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: The Art of Testing Less without Sacrificing Quality</title>
    <link href="/2022/09/21/Paper-Review-The-Art-of-Testing-Less-without-Sacrificing-Quality/"/>
    <url>/2022/09/21/Paper-Review-The-Art-of-Testing-Less-without-Sacrificing-Quality/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://www.microsoft.com/en-us/research/publication/the-art-of-testing-less-without-sacrificing-quality/">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward" class="headerlink" title="What were the primary contributions of the paper as the author sees it? How does this work move the research forward?"></a>What were the primary contributions of the paper as the author sees it? How does this work move the research forward?</h1><p>For large complex software products, there is a need to check that changes do not negatively impact other parts of the software and they comply with system constraints such as backward compatibility, performance, security etc. Ensuring these system constraints may require complex test procedures, but long tests conflict with strategic aims to shorten release cycles.</p><p>To accelerate test processes without sacrificing product quality, the paper develops a cost model for test executions based on historic test execution results that causes no test execution runtime overhead. The paper then presents a novel cost based test selection strategy, THEO, which skips test executions where the expected cost of running the test exceeds the expected cost of not running it, while ensuring that all tests will execute on all code changes at least once.</p><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><p>The paper replayed past development periods of Microsoft Windows, Office, and Dynamics with THEO. THEO would have reduced the number of test executions by up to 50%, cutting down test time by up to 47%. At the same time, product quality was not sacrificed as the process ensures that all tests are ran at least once on all code changes. Simulation shows that THEO produced an overall cost reduction of up to $2 million per development year, per product.</p><p>Furthermore, this paper have convinced an increasing number of Microsoft product teams to explore ways to integrate THEO into their actual live production test environments. This further endorses THEO’s effectiveness.</p><h1 id="How-could-this-research-be-extended"><a href="#How-could-this-research-be-extended" class="headerlink" title="How could this research be extended?"></a>How could this research be extended?</h1><p>The paper stated that through reducing the overall test time, THEO would also have other impacts on the product development process, such as increasing code velocity and developer satisfaction. An empirical study on the effects of cost based test selection strategies on these aspects would be a direction for extending this research.</p><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you-How-could-this-research-be-applied-in-practice"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you-How-could-this-research-be-applied-in-practice" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How does the work apply to you? How could this research be applied in practice?"></a>What were the main contributions of the paper as you (the reader) see it? How does the work apply to you? How could this research be applied in practice?</h1><p>In my opinion, the main contribution of this paper, and the aspect most able to be used as a reference in other projects, is the cost model where each test execution is considered an investment and the expected test result considered as return of investment.</p><p>Several factors are considered in the cost model, with their values easily derived from past observations.</p><ol><li>$p_{TP}$, the probability the combination of test and execution context will detect a defect (true positive).</li><li>$p_{FP}$, the probability the combination of test and execution context will report a false alarm (false positive).</li><li>$engineers$, the number of engineers whose code changes passed the current code branch.</li><li>$time_{delay}$, the average time span required to fix historic defects on the corresponding code branch.</li></ol><p>When a test is executed:</p><ol><li>$cost_{machine}$: the per-minute infrastructure cost of test execution.</li><li>$cost_{inspect}$: the average cost per test inspection, equal to inspection time times the salary of the engineer. For simplicity reasons, an average cost of test inspection is used.</li></ol><p>When a test is skipped:</p><ol><li>$cost_{escaped}$: the average cost of an escaped defect, per developer and hour of delay. Defect severity is not modeled, as it cannot be determined beforehand, and all defects causing development activity to freeze on the corresponding branch must be considered severe.</li></ol><p>After collecting these data, two cost functions are calculated: the expected cost of executing a test $cost_{exec} &#x3D; cost_{machine} + p_{FP} \times cost_{inspect}$, and the expected cost for not executing a test $cost_{skip} &#x3D; p_{TP} \times cost_{escaped} \times time_{delay} \times engineers$.</p><p>Through a reasonable and tested quantization like this, objective decisions can be made, boosting the efficiency of software development.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Boosting Fuzzer Eficiency: An Information Theoretic Perspective</title>
    <link href="/2022/09/20/Paper-Review-Boosting-Fuzzer-Eficiency-An-Information-Theoretic-Perspective/"/>
    <url>/2022/09/20/Paper-Review-Boosting-Fuzzer-Eficiency-An-Information-Theoretic-Perspective/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.6084/m9.figshare.12415622.v2">here</a>.</p><h2 id="What-is-the-problem-being-tackled"><a href="#What-is-the-problem-being-tackled" class="headerlink" title="What is the problem being tackled?"></a>What is the problem being tackled?</h2><p>Finding a solid theoretical foundation for fuzzing and using it to boost fuzzing efficiency is a direction of research of great practical value.</p><h2 id="How-was-it-addressed-by-prior-work"><a href="#How-was-it-addressed-by-prior-work" class="headerlink" title="How was it addressed by prior work?"></a>How was it addressed by prior work?</h2><p>Previous works have proposed various heuristics to boost fuzzing efficiency, such as assigning more energy to seeds that have previously been observed to crash, that maximize execution counts to discover algorithmic complexity vulnerabilities, that exercise low-probability paths, etc. Furthermore, there has also been prior research in theoretical aspects of fuzzing, such as conducting a probabilistic analysis on the efficiency of blackbox versus whitebox fuzzing, empirically investigating the scalability of non-deterministic black- and greybox fuzzing, etc. </p><h2 id="What-are-the-innovation-s-proposed-in-this-paper"><a href="#What-are-the-innovation-s-proposed-in-this-paper" class="headerlink" title="What are the innovation(s) proposed in this paper?"></a>What are the innovation(s) proposed in this paper?</h2><p>First, the paper develops an information-theoretic foundation for non-deterministic fuzzing.</p><h3 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions"></a>Assumptions</h3><p>Fuzzing Heuristics remain constant throughout the fuzzing process.</p><h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><dl><dt>Neighborhood</dt><dd>All inputs generated from mutating a seed.</dd></dl><dl><dt>Species</dt><dd>A branch within a program.</dd></dl><dl><dt>Species Discovery</dt><dd>Program execution traverses a previously untraversed branch when some input is provided to the program.</dd></dl><dl><dt>Incidence Frequency</dt><dd>The number of times a species is covered.</dd></dl><dl><dt>Energy</dt><dd>The probability the fuzzer chooses a seed for mutation.</dd></dl><dl><dt>Power Schedule</dt><dd>The procedure of assigning energy to a seed.</dd></dl><dl><dt>Local Species Distribution of a Seed</dt><dd>Given a seed, the probability of each species being covered, when an input generated by mutation from the seed is fed to the program.</dd></dl><h3 id="Entropy-in-the-Context-of-Fuzzing"><a href="#Entropy-in-the-Context-of-Fuzzing" class="headerlink" title="Entropy in the Context of Fuzzing"></a>Entropy in the Context of Fuzzing</h3><p>Using the metaphor of a “language” with “words” of varying frequencies, entropy in the context of fuzzing can be understood as:</p><ul><li>“Sentences” of the “language”: Program executions resulting from generated inputs.</li><li>“Words” of the “language”: Species.</li><li>Frequencies of the “words”: The frequencies of each species being traversed.</li></ul><p>Entropy can be calculated using the frequencies of the “words”, and represents the frequency distribution of the “words”. <strong>As high entropy implies that the species of the program have all been well covered, it can be used as a proxy for fuzzing efficiency.</strong></p><h3 id="Local-Entropy-of-a-Seed"><a href="#Local-Entropy-of-a-Seed" class="headerlink" title="Local Entropy of a Seed"></a>Local Entropy of a Seed</h3><p>Still using the metaphor of a “language” with “words” of varying frequencies, local entropy of a seed can be understood as:</p><ul><li>“Sentences” of the “language”: Program executions resulting from <strong>inputs within the seed’s neighborhood</strong>.</li><li>“Words” of the “language”: Species.</li><li>Frequencies of the “words”: The frequencies of each species being traversed.</li></ul><p><strong>The local entropy of a seed quantifies the information that feeding the inputs within the seed’s neighborhood into the program reveals about the species.</strong></p><p>Second, the paper presents the first entropy-based power schedule to boost the efficiency of greybox fuzzers. More energy is assigned to seeds that elicit more information about the program’s species. <strong>Thus, every time when randomly choosing a seed for mutation, each seed is assigned an energy proportional to its local entropy</strong>.</p><p>However, a new seed that has never been fuzzed will always be assigned zero energy, and they will never be chosen for mutation. To solve this problem, add-one smoothing is used for the frequency of the species.</p><p>Specifically, the frequency of species $i$ used to calculate local entropy of seed $t$:</p><p>$p_i^t &#x3D; \frac{Y_i^t + 1}{S + Y_1^t + \dots + Y_S^t}$</p><p>Where:</p><ul><li>$Y_i^t$ is the number of times species $i$ has been traversed by the neighborhood of $t$.</li><li>$S$ is the total number of species at the time of calculation.</li></ul><p>Furthermore, in the experiments, the authors noticed that the local entropies for different seeds were almost the same, because a small number of very abundant species had a huge impact on the local entropies. Thus, the authors defined an abundance threshold $\theta$ which is an upper bound for $Y_i^t$.</p><h2 id="How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement"><a href="#How-are-those-innovations-evaluated-How-does-the-paper’s-evaluation-match-with-the-proposed-problem-statement" class="headerlink" title="How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?"></a>How are those innovations evaluated? How does the paper’s evaluation match with the proposed problem statement?</h2><p>The paper provides an open-source implementation, Entropic, within LLVM libFuzzer, and presents a substantial empirical evaluation on over 250 widely-used, open-source C&#x2F;C++ programs producing over 2 CPU years worth of data.</p><p>Four research questions were asked to evaluate the hypothesis that increasing information per generated input increases fuzzer efficiency.</p><ol><li>What is the empirical coverage improvement over the baseline?</li><li>How much faster are bugs detected compared to the baseline?</li><li>How does the choice of abundance threshold influence the performance of our technique?</li><li>What is the cost of maintaining incidence frequencies?</li></ol><p>The answers to these research strongly support the hypothesis, thus the evaluation matches well with the proposed problem statement.</p><h1 id="Your-opinion-of-the-paper"><a href="#Your-opinion-of-the-paper" class="headerlink" title="Your opinion of the paper"></a>Your opinion of the paper</h1><h2 id="Which-technical-innovations-are-most-compelling-to-you"><a href="#Which-technical-innovations-are-most-compelling-to-you" class="headerlink" title="Which technical innovations are most compelling to you?"></a>Which technical innovations are most compelling to you?</h2><p>Developing an information-theoric foundation for non-deterministic fuzzing, in which entropy in the context of fuzzing is calculated using the probability distribution of species (branches). This is both intuitive and allows us to effectively use entropy, <a href="https://colah.github.io/posts/2015-09-Visual-Information/#conclusion">which has “really nice properties, and a principled origin” as a “convenient proxy”</a> for fuzzing efficiency.</p><h2 id="What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper-Which-problems-remain-unsolved-after-this-paper"><a href="#What-remains-unclear-after-reading-the-paper-Are-there-any-clarification-questions-whose-answers-would-substantially-change-your-opinion-of-the-paper-Which-problems-remain-unsolved-after-this-paper" class="headerlink" title="What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper? Which problems remain unsolved after this paper?"></a>What remains unclear after reading the paper? Are there any clarification questions whose answers would substantially change your opinion of the paper? Which problems remain unsolved after this paper?</h2><p>The paper develops an information-theoretic foundation for non-deterministic fuzzing, before presenting the first entropy-based power schedule to boost the efficiency of greybox fuzzers. I have questions regarding both aspects.</p><ol><li>Entropy is calculated using the probability distribution of species, which are branches. Is is possible to utilize a different definition of “species”?</li><li>The entropy-based power schedule assigns each seed with energy proportional to its local entropy. However, the authors noticed that the local entropies for different seeds were almost the same, because a small number of very abundant species had a huge impact on the local entropies. Thus, the authors defined an abundance threshold $\theta$ for $Y_i^t$, a task-relevant hyperparameter. Is there a better approach for calculating the local entropies?</li></ol><h2 id="Do-you-forsee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper-If-so-how-could-these-barriers-be-overcome"><a href="#Do-you-forsee-any-barriers-to-the-applicability-of-the-technique-proposed-in-the-paper-If-so-how-could-these-barriers-be-overcome" class="headerlink" title="Do you forsee any barriers to the applicability of the technique proposed in the paper? If so, how could these barriers be overcome?"></a>Do you forsee any barriers to the applicability of the technique proposed in the paper? If so, how could these barriers be overcome?</h2><p>As stated above, regarding the entropy-based power schedule.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: How Effective Developers Investigate Source Code: An Exploratory Study</title>
    <link href="/2022/09/19/Paper-Review-How-Effective-Developers-Investigate-Source-Code-An-Exploratory-Study/"/>
    <url>/2022/09/19/Paper-Review-How-Effective-Developers-Investigate-Source-Code-An-Exploratory-Study/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/TSE.2004.101">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward" class="headerlink" title="What were the primary contributions of the paper as the author sees it? How does this work move the research forward?"></a>What were the primary contributions of the paper as the author sees it? How does this work move the research forward?</h1><ol><li>The paper provides a set of detailed observations about the characteristics of effective program investigation. These observations are accompanies by hypotheses that can be validated by additional research and practical experience.</li><li>The paper’s results support the intuitive notion that developers should follow a general plan, perform focused searches in the context of this plan, and keep some form of record of their findings when investigating a program.</li><li>The paper describes a methodology and analysis technique for studying the behavior of software developers.</li></ol><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><p>The authors conducted a study of five developers undertaking an identical software change task on a medium-sized system, where understanding the existing software is a precursor to modification and validation.</p><p>They did a detailed qualitative analysis of a few replicated cases, rather than a statistical analysis of causality between dependent variables. Many previous studies were based on heavily abstracted characterizations of both developer behavior and success level. It involved a detailed study of the examined code, the methods used to navigate between different locations in the code, and the modified source code.</p><p>They contrasted the program investigation behavior of successful and unsuccessful developers, and isolated the factors associated with the behavior of a developer, rather than external factors (such as the influence of the workplace, the programming environment, etc.)</p><h1 id="How-could-this-research-be-applied-in-practice"><a href="#How-could-this-research-be-applied-in-practice" class="headerlink" title="How could this research be applied in practice?"></a>How could this research be applied in practice?</h1><p>Ensuring that developers in charge of modifying software systems investigate the code of the system effectively can yield important benefits such as decreasing the cost of performing software changes and increasing the quality of the change.</p><p>Understanding the nature of program investigation behavior that is associated with successful software modification tasks can help us improve the tool support and training programs offered to software developers.</p><h1 id="How-could-this-research-be-extended"><a href="#How-could-this-research-be-extended" class="headerlink" title="How could this research be extended?"></a>How could this research be extended?</h1><p>Researchers can reuse the authors’ strategy (stated in “How was the work validated?”) to help validate the hypotheses the authors’ proposed, or to study other aspects of programmer behavior.</p><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How does the work apply to you?"></a>What were the main contributions of the paper as you (the reader) see it? How does the work apply to you?</h1><p>In my opinion, the main contributions of the paper include the primary contributions of the paper as the author sees it, how the work was validated, and how this research could be applied in practice. However, what is most meaningful for me is how the work was validated. Such methodology is of great reference value for conducting studies on other aspects of programmer behavior. There are many technical details within that have left a deep impression on me.</p><ol><li>Each phase was described entirely through written instructions, and the subjects were given an Eclipse training phase and an investigation phase before the modification phrase.</li><li>To record the actions of a developer in the investigation and modification phases, they recorded the developers’ screens, and transcribed the recordings into a structured list of events. Each event contains the properties time, method, navigation, and modification. </li><li>To analyze the quality of change, the authors analyzed the source code to determine the characteristics of an ideal solution, and divided the task into five subtasks. The authors examined how each subject had implemented each subtask, and characterized its quality.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Asking and Answering Questions during a Programming Change Task</title>
    <link href="/2022/09/14/Paper-Review-Asking-and-Answering-Questions-during-a-Programming-Change-Task/"/>
    <url>/2022/09/14/Paper-Review-Asking-and-Answering-Questions-during-a-Programming-Change-Task/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/TSE.2008.26">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it" class="headerlink" title="What were the primary contributions of the paper as the author sees it?"></a>What were the primary contributions of the paper as the author sees it?</h1><ol><li>A catalog of 44 types of questions programmers ask during software evaluation tasks, organized into four categories based on the kind and scope of information needed to answer a question.</li></ol><ul><li>Finding a focus point</li><li>Expanding a focus point</li><li>Understanding a subgraph</li><li>Over groups of subgraphs</li></ul><ol start="2"><li>A description of the observed behavior around answering these questions.</li><li>A description of how existing deployed and proposed tools do, and do not, support answering programmers’ questions.</li></ol><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><p>The author interviewed participants in two studies.</p><ol><li>9 participants in academia worked on a code base that was new to them.</li><li>16 participants in industry worked on a code base for which they had responsibility.</li></ol><p>The two studies have allowed us to observe programmers in situations that vary along several dimensions:</p><ul><li>the programming tools</li><li>the type of change task</li><li>the system</li><li>paired versus individual programming</li><li>prior knowledge of the code base</li></ul><p>The differences have increased the authors’ ability to generate an extensive set of questions programmers ask.</p><p>They build rather than test theory and the specific result of this process is a theoretical understanding of the situation of interest grounded in the data collected.</p><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-does-the-work-apply-to-you" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How does the work apply to you?"></a>What were the main contributions of the paper as you (the reader) see it? How does the work apply to you?</h1><p>In my opinion, aside from the final results, three important considerations learned from this paper are:</p><ol><li>Interviewing participants in two very different groups.</li><li>Developing generic versions of the questions participants asked, which slightly abstract from the specifics of a particular situation and code base. </li><li>Compared the generic questions and categorized those questions into four categories based on the kind and scope of information needed to answer a question.</li></ol><p>This is an example of extracting generalized knowledge from specific case studies, which makes it a great example to study for conducting empirical studies.</p><h1 id="How-could-this-research-be-extended-How-could-this-research-be-applied-in-practice"><a href="#How-could-this-research-be-extended-How-could-this-research-be-applied-in-practice" class="headerlink" title="How could this research be extended? How could this research be applied in practice?"></a>How could this research be extended? How could this research be applied in practice?</h1><p>The research identified clear gaps of tool support in answering programmers’ questions. </p><ol><li>Support for more refined or precise questions.</li></ol><ul><li>Some questions can he seen as more refined versions of other questions.</li><li>A programmer’s questions also often have an explicit or implicit scope.</li><li>Due to limited tool support, programmers end up asking questions more globally than they intend, and, the result sets will include many irrelevant items.</li></ul><ol start="2"><li>Support for maintaining context.</li></ol><ul><li>A particular question is often part of a larger process involving multiple questions.</li><li>There are missed opportunities for tools to make use of the larger context to help programmers more efficiently scope their questions and to determine what is relevant to their higher level questions.</li></ul><ol start="3"><li>Support for piecing information together.</li></ol><ul><li>Many questions require considering multiple entities and relationships.</li><li>In these situations, the burden is on the programmer to assemble the information needed to answer their intended question.</li><li>Tool support is missing for bringing information together and building toward an answer.</li></ul><p>Improved tools and an assessment of these tools in answering these questions present directions for future research.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Qualitative Methods in Empirical Studies of Software Engineering</title>
    <link href="/2022/09/14/Paper-Review-Qualitative-Methods-in-Empirical-Studies-of-Software-Engineering/"/>
    <url>/2022/09/14/Paper-Review-Qualitative-Methods-in-Empirical-Studies-of-Software-Engineering/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/32.799955">here</a>.</p><h1 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it-How-does-this-work-move-the-research-forward" class="headerlink" title="What were the primary contributions of the paper as the author sees it? How does this work move the research forward?"></a>What were the primary contributions of the paper as the author sees it? How does this work move the research forward?</h1><p>With empirical studies of software engineering beginning to address the human aspects of software development, the author presents and reviews a number of different methods for the collection and analysis of qualitative data, and describes them in terms of how they might be incorporated into empirical studies of software engineering, in particular how they might be combines with quantitative methods.</p><ul><li>Collecting Qualitative Data<ul><li>Participant Observation</li><li>Interviewing</li></ul></li><li>Extracting Quantitative Values from Qualitative Data for Quantitative Analysis (Coding)</li><li>Analyzing Qualitative Data<ul><li>Theory Generation: extract from a set of field notes a statement or preposition that is supported in multiple ways by the data.</li><li>Theory Confirmation: confirming a preposition after it has been generated from the data.</li></ul></li></ul><h1 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-could-this-research-be-applied-in-practice"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-could-this-research-be-applied-in-practice" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How could this research be applied in practice?"></a>What were the main contributions of the paper as you (the reader) see it? How could this research be applied in practice?</h1><p>Aside from the primary contributions of the paper as the author sees it, in my opinion, another major contribution of the paper is identifying the four main categories of empirical studies, and explaining in detail how combinations of quantitative and qualitative methods can be designed for each category.</p><p>The four main categories of empirical studies:</p><ul><li>Blocked subject-project study:<ul><li>Several projects, several subjects.</li><li>Reduces bias, but increases the cost of the experiment.</li></ul></li><li>Replicated project study:<ul><li>One project, several subjects.</li><li>Isolates the effect of differences between subjects.</li></ul></li><li>Multiproject variation:<ul><li>Several projects, one subject.</li><li>Observes the performance of the subject on a project before some treatment is applied, and on a different project after that treatment is applied.</li></ul></li><li>Single project study:<ul><li>One project, one subject.</li><li>Similar to a case study.</li><li>Certain attributes are examined and possibly compared to some baseline.</li></ul></li></ul><p>How combinations of quantitative and qualitative methods can be designed for each category:</p><ul><li>Blocked subject-project study, Replicated project study:<ul><li>When testing hypotheses and finding casual relationships between variables, use qualitative data to illuminate the statistical results.</li></ul></li><li>Multiproject variation study:<ul><li>Qualitative analysis: revealing new issues and tracking changes relative to other issues.</li><li>Quantitative analysis: looking more closely at the issues suggested by the qualitative analysis.</li></ul></li><li>Single project study:<ul><li>First, data is collected qualitatively through interviews.</li><li>A taxonomy of the question under research is generated.</li><li>Part of the interview data is coded to yield quantitative variables.</li><li>Any relationships found between quantitative variables are checked against qualitative data.</li></ul></li></ul><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><p>Examples, interviews, quotes from experts, and paper citations are used to validate the points presented when reviewing a number of different methods for the collection and analysis of qualitative data, identifying the four main categories of empirical studies, and explaining in detail how combinations of quantitative and qualitative methods can be designed for each category.</p><h1 id="How-could-this-research-be-extended"><a href="#How-could-this-research-be-extended" class="headerlink" title="How could this research be extended?"></a>How could this research be extended?</h1><p>In the last paragraph, the author points out that “we must exploit to the fullest every opportunity we do have, by collecting and analyzing as much data of as many different types as possible”. Aside from the examples presented in the paper, what other types of data can be collected, and how they can be analyzed, is a future direction of research.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: No Silver Bullet Essence and Accidents of Software Engineering</title>
    <link href="/2022/09/12/Paper-Review-No-Silver-Bullet-Essence-and-Accidents-of-Software-Engineering/"/>
    <url>/2022/09/12/Paper-Review-No-Silver-Bullet-Essence-and-Accidents-of-Software-Engineering/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://doi.org/10.1109/MC.1987.1663532">here</a>.</p><h1 id="How-does-this-work-move-the-research-forward"><a href="#How-does-this-work-move-the-research-forward" class="headerlink" title="How does this work move the research forward?"></a>How does this work move the research forward?</h1><h2 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it" class="headerlink" title="What were the primary contributions of the paper as the author sees it?"></a>What were the primary contributions of the paper as the author sees it?</h2><p>The author concludes that there is no elixir or “silver bullet” to the problems software engineering is facing. Furthermore, the author also examines encouraging innovations, and shows that a disciplined, consistent effort to develop, propagate, and exploit them should alleviate the problem.</p><h2 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it?"></a>What were the main contributions of the paper as you (the reader) see it?</h2><p>In my opinion, what the paper is most remarkable at is shedding light upon the nature of the software problem and its implications.</p><ol><li>The essence of a software entity is a construct of interlocking concepts that cannot be accurately visualized. The complexity of software is an essential property, and it increases non-linearly with size. This has many implications.</li></ol><ul><li>Difficulty of design.</li><li>Hindrance of communication among team members, which leads to product flaws, cost overruns, schedule delays.</li><li>Hard to use programs.</li><li>Difficulty of extending to new functions without creating side effects.</li><li>Security trapdoors.</li><li>Personnel turnover incurs tremendous learning and understanding burden.</li></ul><ol start="2"><li>Software is constantly subject to pressure for change.</li></ol><p>The aforementioned points clarified by the paper illuminates research directions in software engineering aimed at ameliorating the software problem.</p><h2 id="How-could-this-research-be-extended"><a href="#How-could-this-research-be-extended" class="headerlink" title="How could this research be extended?"></a>How could this research be extended?</h2><p>In the last section of the paper, the author examines promising attacks on the essence of the software problem.</p><ul><li>Buying off-the-shelf software instead of building in-house software.</li><li>Rapid prototyping and iterative specification of requirements with client feedback.</li><li>Incremental development of software from a simple and incomplete, yet running, system.</li><li>Growing great designers who are the core of the development team.</li></ul><p>The effectiveness of these and other approaches in mitigating the software problem could be assessed in subsequent works.</p><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><ol><li>First, the author examines the nature of the software problem and its implications.</li><li>Further on, the author recalls the three steps in software technology that have been most fruitful in the past - high-level languages, time-sharing, and unified programming environments, concluding that they have their limits and the difficulties that they attacked are accidental, not essential.</li><li>The author continues to consider the technical developments that are most often advanced as potential silver bullets - high-level language advances, object-oriented programming, artificial intelligence, automatic programming, graphical programming, program verification, environments and tools, workstations - analyzing the problems they assess, their advantages, and their disadvantages.</li><li>Finally, the author presents promising attacks on the conceptual essence, explaining why they would be useful.</li></ol><h1 id="How-could-this-research-be-applied-in-practice"><a href="#How-could-this-research-be-applied-in-practice" class="headerlink" title="How could this research be applied in practice?"></a>How could this research be applied in practice?</h1><p>The lessons learned from this research are of great practical value.</p><ol><li>In shedding light upon the nature of the software problem and its implications, the author provides criteria for organizations to assess the effectiveness of their development practices.</li><li>In considering the technical developments that are most often advanced as potential silver bullets, the author examines their advantages, and their disadvantages, and provide insights into whether to, and how to adequately use them.</li><li>In presenting promising attacks on the conceptual essence, the author provides meaningful suggestions for organizations to improve their software development processes, and provides convincing rationale for doing so.</li></ol><p>As this is a classic paper, many promising attacks on the conceptual essence have already materialized and become mainstream.</p><ul><li>Rapid prototyping and incremental development have been manifested as “agile development” and have been widely adopted.</li><li>With the advent of the open-source revolution and code-hosting platforms such as GitHub, reusing off-the-shelf software instead of building in-house software has become ubiquitous.</li></ul><p>However, the call for organizations to “grow great designers who are the core of the development team” incurs significant requirements on corporate management competency, and sadly, hasn’t fully become reality.</p><h1 id="How-does-the-work-apply-to-you"><a href="#How-does-the-work-apply-to-you" class="headerlink" title="How does the work apply to you?"></a>How does the work apply to you?</h1><p>It sheds light upon the nature of the software problem and its implications, illuminates research directions in software engineering aimed at ameliorating the software problem, and provides a reference research methodology for problems within software engineering.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: Software&#39;s Chronic Crisis</title>
    <link href="/2022/09/12/Paper-Review-Software-s-Chronic-Crisis/"/>
    <url>/2022/09/12/Paper-Review-Software-s-Chronic-Crisis/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://github.com/ubccpsc/507/tree/2022sept">Advanced Software Engineering</a>. The original paper can be found <a href="https://www.cse.psu.edu/~gxt29/bug/localCopies/SoftwareCrisis.html">here</a>.</p><h1 id="How-does-this-work-move-the-research-forward"><a href="#How-does-this-work-move-the-research-forward" class="headerlink" title="How does this work move the research forward?"></a>How does this work move the research forward?</h1><h2 id="What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it"><a href="#What-were-the-primary-contributions-of-the-paper-as-the-author-sees-it" class="headerlink" title="What were the primary contributions of the paper as the author sees it?"></a>What were the primary contributions of the paper as the author sees it?</h2><p>The author identifies software’s chronic crisis and how it is exacerbated by current trends in software engineering.</p><p>The vast majority of code is handcrafted by artisans using techniques they neither measure nor are able to repeat consistently. The software industry remains short of the mature engineering discipline needed to meet the demands of an information-age society, including getting software right the first time in embedded environments, distributed systems and systems integration, rapid increasing system sizes, and systems becoming so complex that no manager can comprehend the entirety.</p><p>Later, the author analyzes proposed remedies to the aforementioned problems and points out directions for future work.</p><p>Remedies:</p><ul><li>Capability Maturity Model, which quantifies a developer’s software engineering and management excellence.</li><li>Consistent and quantitative measurement of development.</li><li>Strategies to avoid bugs or attack them early.<ul><li>Recognizing changing requirements</li><li>Growing software from rapid prototypes and customer feedback</li><li>Formal verification when necessary</li><li>Clean-room process</li><li>Cautious approach to technological innovations such as object-oriented analysis and programming</li></ul></li></ul><p>Directions for Future Work:</p><ul><li>An experimental branch of computer science to separate the general results from the accidental</li><li>Standard unit of measurement of developer productivity</li><li>Codified proven solutions for novices</li><li>Academic-industrial collaboration to gather data and try things</li><li>Generalized, reusable software components</li><li>Certifying software engineers</li><li>Outsourcing</li><li>More software development-oriented computer science curricula</li></ul><h2 id="What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-could-this-research-be-applied-in-practice"><a href="#What-were-the-main-contributions-of-the-paper-as-you-the-reader-see-it-How-could-this-research-be-applied-in-practice" class="headerlink" title="What were the main contributions of the paper as you (the reader) see it? How could this research be applied in practice?"></a>What were the main contributions of the paper as you (the reader) see it? How could this research be applied in practice?</h2><p><strong>Aside for the primary contributions of the paper as the author sees it</strong>, in my opinion, a major contribution of the paper in a practical sense are revelations for improving <strong>the culture within software developing organizations</strong>. For example,</p><ul><li>Focus on interchangeability.</li><li>Follow best practices.</li><li>Fix not just the bug but also the flaw in the testing process that allowed it to slip through.</li><li>Value verification in addition to innovation.</li><li>Pay attention to the difference in competence between employees.</li></ul><p>Furthermore, as a historical paper, many of its proposals have already materialized. For example, the open-source revolution and collaboration platforms such as GitHub have greatly facilitated gathering data and trying things for research, and has provided a wealth of generalized, reusable software components.</p><h2 id="How-could-this-research-be-extended"><a href="#How-could-this-research-be-extended" class="headerlink" title="How could this research be extended?"></a>How could this research be extended?</h2><p>Implementing and assessing the proposed directions for future work represents a natural extension of this research.</p><h1 id="How-was-the-work-validated"><a href="#How-was-the-work-validated" class="headerlink" title="How was the work validated?"></a>How was the work validated?</h1><p>The authors validate their arguments on software’s chronic crisis and base their proposals for remedies and future work by analyzing real cases in software engineering, as well as compiling the opinions of experts in the field, including university professors and corporate managers.</p><h1 id="How-does-the-work-apply-to-you"><a href="#How-does-the-work-apply-to-you" class="headerlink" title="How does the work apply to you?"></a>How does the work apply to you?</h1><ol><li>From a theoretical perspective, as a milestone paper in the domain of software engineering, this paper provides a model research methodology for practical problems within software engineering - analyzing real cases and compiling the opinions of experts.</li><li>From a practical perspective, this paper identifies core values and skills that us, as practitioners of software engineering, should firmly grasp.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Advanced Software Engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Paper Review: An empirical study of the reliability of UNIX utilities</title>
    <link href="/2022/09/10/Paper-Review-An-empirical-study-of-the-reliability-of-UNIX-utilities/"/>
    <url>/2022/09/10/Paper-Review-An-empirical-study-of-the-reliability-of-UNIX-utilities/</url>
    
    <content type="html"><![CDATA[<p>NOTE: This is a Paper Review for <a href="https://www.carolemieux.com/teaching/CPSC539L_2022w1.html">Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</a>. The original paper can be found <a href="https://doi.org/10.1145/96267.96279">here</a>.</p><p>“An empirical study of the reliability of UNIX utilities” is the work that spawned research into the domain of software fuzzing. It proposes a technique later known as <strong>random fuzzing</strong>, testing the reliability of UNIX utilities by feeding them a stream of randomly generated characters and checking whether the program crashed with a core dump or hangs.</p><p>Although the technique is simple and is not a substitute for formal verification or testing, it is <strong>inexpensive and easy to apply</strong>. Its <strong>effectiveness in identifying bugs and increasing overall system reliability</strong> has been proven in many ways.</p><ol><li>It crashed 25-33% of the utility programs considered to be “reliable” on each platform.</li><li><strong>It was able to find recurring security bugs resulting from bad programming practices that even the best static analysis tools have limited success in detecting</strong>, including:</li></ol><ul><li>Accessing outside the bounds of a buffer</li><li>Dereferencing a null pointer</li><li>Unintentionally overwriting data or code</li><li>Ignoring return codes, especially error-indicating return codes</li><li>Faulty communication with subprocesses</li><li>Unintended interaction between modules</li><li>Improper error handling</li><li>Signed characters</li><li>Race conditions during signal handling</li></ul><ol start="3"><li><strong>Its relevance has remained strong over the years.</strong> Subsequent studies using the same technique showed that similar problems also existed within other operating systems, such as Microsoft Windows. Even after thirty years, the utility programs in the modern Unix distributions of Linux, macOS, and FreeBSD are still crashing at a noticeable rate and not getting better, as evidenced in “The Relevance of Classic Fuzz Testing: Have We Solved This One?”</li></ol><p>The contributions of this work is <strong>multi-fold</strong>.</p><ol><li>As mentioned before, it proposed random fuzzing, an inexpensive, easy to apply, and time-proven way of finding security bugs which is complimentary with formal verification and testing.</li><li>It spawned research into the domain of software fuzzing. New fuzz tools usually take a gray- or white-box approach, diving deeper into a program’s control flow, and they have been applied to many new contexts. However, they often require more advanced specification of the input and&#x2F;or long execution times to explore the input and program control-flow space.</li><li>It provides revelations for software engineering: good design, good education, ongoing training, testing integrated into the development cycle, and most importantly, a culture that promotes and rewards reliability.</li></ol><p>Some personal thoughts after reading the paper.</p><ol><li><strong>Given the source code of a program and an input, what is the mechanism through which the researchers determine the position where the program crashes and hangs when given the input?</strong> This is mentioned in neither “An empirical study of the reliability of UNIX utilities” nor its sequel “The Relevance of Classic Fuzz Testing: Have We Solved This One?”, but is of great practical value.</li><li><strong>There is a surprising number of security bugs stemming from language defects such as not checking array bounds and dereferencing null pointers, as well as ad-hoc, hacky solutions to recurring problems such as lexical analysis, syntax analysis, structured error handling, as well as graph algorithms including cycle detection, topological sort, etc.</strong> Personally, this is not my style of coding. I make extensive a lot of “safe” language constructs such as null coalescing, heavily exploit performant and well-tested algorithms within standard libraries and widely-adapted third-party libraries (such as boost in C++ and networkx in Python), and use theoretically sound tools (such as automatically generated LALR parsers for syntax analysis) in software projects. <strong>The efficiency, effectiveness, and practical value of these and other solutions, as well as how they can be improved, is an interesting question that comes to my mind after reading this paper.</strong></li></ol>]]></content>
    
    
    <categories>
      
      <category>Paper Review</category>
      
      <category>Topics in Programming Languages: Automated Testing, Bug Detection, and Program Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
